{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import numpy as np\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# device and cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([1])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([1], device='cuda:0')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()\n",
    "torch.cuda.current_device()\n",
    "torch.tensor([1])\n",
    "torch.tensor([1]).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([1], device='cuda:2')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.set_device(2)\n",
    "torch.cuda.current_device()\n",
    "x = torch.tensor([1]).cuda()\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1], device='cuda:1')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function to is often used\n",
    "device = torch.device('cuda:1')\n",
    "x.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.nn.Module is the constructed model\n",
    "# device can also be given a number like device = 2\n",
    "torch.nn.Module.cuda(device = device )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.randn(2,device = device)\n",
    "\n",
    "\n",
    "# tensor.cuda return a copy and the same as tensor.to\n",
    "tensor = torch.randn(2)\n",
    "tensor = tensor.cuda(device = device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if has known tensors data(array like)\n",
    "torch.tensor([1,2,3])\n",
    "torch.tensor([1,2.1,3])\n",
    "torch.tensor([1,2,3],dtype=torch.int)\n",
    "torch.IntTensor([1,2,3])\n",
    "torch.FloatTensor([1,2,3])\n",
    "torch.Tensor([1,2,])\n",
    "# from numpy\n",
    "a = np.array([1,2,3])\n",
    "torch.from_numpy(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we don't want data \n",
    "torch.zeros(2,3)\n",
    "a = torch.zeros((2,3),dtype=torch.int)\n",
    "a\n",
    "torch.zeros_like(a,dtype=torch.float)\n",
    "# the same for torch.ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.full((2,3),3.1415)\n",
    "torch.full_like(a,3.1415)\n",
    "torch.rand((2,3))\n",
    "torch.rand_like(a,dtype=torch.float)\n",
    "# 正太分布，零均值 方差为1\n",
    "torch.randn((2,3))\n",
    "torch.randn_like(a,dtype=torch.float)\n",
    "# 限定范围随机\n",
    "torch.randint(2,8,(2,3))\n",
    "torch.randint_like(a,2,8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# joining slicing demention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### advanced indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0., 82., 51.],\n",
       "          [64., 33., 28.],\n",
       "          [48., 43., 16.],\n",
       "          [34., 92., 99.]],\n",
       " \n",
       "         [[78.,  2.,  1.],\n",
       "          [51., 61., 68.],\n",
       "          [62., 59.,  4.],\n",
       "          [11., 43., 30.]],\n",
       " \n",
       "         [[90., 10.,  7.],\n",
       "          [26., 92., 91.],\n",
       "          [75., 32., 32.],\n",
       "          [47., 30.,  5.]],\n",
       " \n",
       "         [[28., 61., 80.],\n",
       "          [81., 42., 20.],\n",
       "          [ 0., 68., 82.],\n",
       "          [58., 79., 98.]],\n",
       " \n",
       "         [[14.,  7.,  7.],\n",
       "          [ 2., 11., 41.],\n",
       "          [19., 45., 32.],\n",
       "          [39., 39., 31.]]]), tensor([2, 1, 2, 1, 1]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[64., 33., 28.],\n",
       "        [78.,  2.,  1.],\n",
       "        [26., 92., 91.],\n",
       "        [28., 61., 80.],\n",
       "        [14.,  7.,  7.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for lstm variable length input to select the last output of lstm according to the input length\n",
    "\n",
    "x = torch.randint(0,100,(5,4,3))\n",
    "length = torch.tensor([2,1,2,1,1],dtype=torch.long)\n",
    "x,length\n",
    "x[torch.arange(x.size(0)),length -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get mask by input length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2, 3],\n",
       "        [0, 1, 2, 3],\n",
       "        [0, 1, 2, 3],\n",
       "        [0, 1, 2, 3],\n",
       "        [0, 1, 2, 3]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 0, 0],\n",
       "        [1, 0, 0, 0],\n",
       "        [1, 1, 0, 0],\n",
       "        [1, 0, 0, 0],\n",
       "        [1, 0, 0, 0]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0., 82., 51.],\n",
       "          [64., 33., 28.],\n",
       "          [48., 43., 16.],\n",
       "          [34., 92., 99.]],\n",
       " \n",
       "         [[78.,  2.,  1.],\n",
       "          [51., 61., 68.],\n",
       "          [62., 59.,  4.],\n",
       "          [11., 43., 30.]],\n",
       " \n",
       "         [[90., 10.,  7.],\n",
       "          [26., 92., 91.],\n",
       "          [75., 32., 32.],\n",
       "          [47., 30.,  5.]],\n",
       " \n",
       "         [[28., 61., 80.],\n",
       "          [81., 42., 20.],\n",
       "          [ 0., 68., 82.],\n",
       "          [58., 79., 98.]],\n",
       " \n",
       "         [[14.,  7.,  7.],\n",
       "          [ 2., 11., 41.],\n",
       "          [19., 45., 32.],\n",
       "          [39., 39., 31.]]]), tensor([[[ 0., 82., 51.],\n",
       "          [64., 33., 28.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.]],\n",
       " \n",
       "         [[78.,  2.,  1.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.]],\n",
       " \n",
       "         [[90., 10.,  7.],\n",
       "          [26., 92., 91.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.]],\n",
       " \n",
       "         [[28., 61., 80.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.]],\n",
       " \n",
       "         [[14.,  7.,  7.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.]]]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(4)\n",
    "torch.arange(4).expand(*length.shape,4)\n",
    "mask = torch.arange(4).expand(*length.shape,4)< length.unsqueeze(1)\n",
    "mask\n",
    "x,torch.mul(x,mask.float().unsqueeze(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reverse input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size, seq_len, word_dim = x.size()\n",
    "inv_idx = torch.arange(seq_len - 1, -1, -1).long()\n",
    "inv_idx = inv_idx.unsqueeze(0).unsqueeze(-1).expand_as(x)\n",
    "inv_idx\n",
    "'--------------------'\n",
    "shift_idx = torch.arange(0, seq_len).long()\n",
    "shift_idx = shift_idx.unsqueeze(0).unsqueeze(-1).expand_as(x)\n",
    "shift = (seq_len + (-1 * length)).unsqueeze(-1).unsqueeze(-1).expand_as(x)\n",
    "shift_idx = shift_idx + shift\n",
    "shift_idx = shift_idx.clamp(0, seq_len - 1)\n",
    "shift_idx\n",
    "\n",
    "x.gather(1, inv_idx)\n",
    "x.gather(1, inv_idx).gather(1, shift_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## merger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.range(1,6).view(2,3)\n",
    "y = torch.range(6,11).view(2,3)\n",
    "x\n",
    "y\n",
    "torch.cat((x,y),0)\n",
    "torch.cat((x,y),1)\n",
    "\n",
    "\n",
    "\n",
    "torch.stack((x,y),0)\n",
    "torch.stack((x,y),1)\n",
    "torch.stack((x,y),2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## change demention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.range(0,11)\n",
    "a\n",
    "a.reshape(4,3)\n",
    "# view 在操作不连续的tensor之前需要先 continues(),而reshape 是不需要的，reshape 是后来版本新实现的，建议用reshape\n",
    "'b:'\n",
    "b = a.view(6,2)\n",
    "b\n",
    "\n",
    "# repeat 这个函数比较复杂\n",
    "'#########repeat###########'\n",
    "x = torch.randn(2,3)\n",
    "x,x.shape\n",
    "x.repeat(2,1).shape\n",
    "x.repeat(1,2).shape\n",
    "x.repeat(2,2).shape\n",
    "x.repeat(5,2,2).shape   # 如果repeat的参数比tensor的shape多，则将参数中的个数从后面减去tensor的shape个数，\n",
    "                        # 将tensor视为一个整体，复制参数中剩余的位数（位数从右向左看）\n",
    "x.repeat(6,5,1,1).shape\n",
    "\n",
    "x = torch.randn((32,50))\n",
    "x.repeat(20,1,1) == x.unsqueeze(0).repeat(20,1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 转置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn((2,4,6))\n",
    "a.shape\n",
    "a.transpose(0,1).shape\n",
    "a.permute(1,2,0).shape   # 新的从旧的中获取"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## squeeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn((2,1,4))\n",
    "a.shape\n",
    "a.squeeze(1).shape\n",
    "a.unsqueeze(1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# math operation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.range(0,2)\n",
    "b = torch.range(3,5)\n",
    "a,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a + b\n",
    "a - b\n",
    "a * b\n",
    "a / b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# for nn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bilinear to calculate h^t * W * h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.line1 = nn.Linear(20, 10)# submodule: Conv2d\n",
    "        self.conv1 = nn.Conv1d(20, 20, 5)\n",
    "        self.rnn = nn.LSTM(300,300)\n",
    "\n",
    "    def forward(self, x):\n",
    "       x = F.relu(self.conv1(x))\n",
    "       return F.relu(self.conv1(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 查看模型总的参数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 0\n",
    "for i in m.parameters():\n",
    "    total += i.numel()\n",
    "total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型参数拷贝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model parameters \n",
    "m.state_dict()\n",
    "\n",
    "m2 = Model()\n",
    "m2.load_state_dict(m.state_dict())\n",
    "# now m and m2 have the same parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nn.module模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m\n",
    "m.line1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m.modules()\n",
    "'#############################'\n",
    "for i in m.modules():\n",
    "    print(i)\n",
    "'---------------------------------------'\n",
    "for i in m.named_modules():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in m.children():\n",
    "    print(i)\n",
    "'-------------------------------'\n",
    "for i in m.named_children():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in m.parameters():\n",
    "    print(i.shape,'\\t',type(i),'\\t',type(i.data))\n",
    "'--------------------------------------------'\n",
    "for i in m.named_parameters():\n",
    "    print(type(i),'\\t',i[0],'\\t',i[1].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.state_dict()\n",
    "'---------------------------'\n",
    "m.state_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "B = nn.Bilinear(2, 2, 1)\n",
    "x_ones = torch.ones(2)\n",
    "x_zeros = torch.zeros(2)\n",
    "B(x_ones, x_zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = nn.Bilinear(10, 20, 40)\n",
    "c.weight.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cnn\n",
    "out channel is the number of kenels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## linear convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "oc = torch.nn.Conv1d(300,2,3)\n",
    "\n",
    "oc\n",
    "oc.state_dict().keys()\n",
    "oc.weight.shape\n",
    "\n",
    "x = torch.randn((32,300,23))\n",
    "y = oc(x)\n",
    "\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mx = torch.nn.MaxPool1d(21)\n",
    "z = mx(y)\n",
    "z.shape\n",
    "z = z.squeeze(2)\n",
    "z.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2d convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tc = torch.nn.Conv2d(1,2,3,padding=1)\n",
    "x = torch.randn(32,23,300).unsqueeze(1)\n",
    "x.shape\n",
    "y = tc(x)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.Tensor(3, 5)\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_idx = torch.arange(x.size(0)-1, -1, -1).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_tensor = x.index_select(0, inv_idx)\n",
    "inv_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### usage\n",
    "实现了变长的lstm，验证了与原生的lstm的一致性\n",
    "注： c_n 不一样，没有特殊处理，没关注c_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = nn.LSTM(2,1,num_layers=2,batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.randn(4,5,2)\n",
    "length = torch.tensor([5,4,3,2]).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_x_pack = torch.nn.utils.rnn.pack_padded_sequence(inputs,length,batch_first=True)\n",
    "packed,(h_n,c_n) = lstm(batch_x_pack)\n",
    "lstm_out,out_len = torch.nn.utils.rnn.pad_packed_sequence(packed,batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_Mask(nn.Module):\n",
    "    def __init__(self,input_size,hidden_size,num_layers=1,batch_first=False):\n",
    "        super(LSTM_Mask,self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.batch_first = batch_first\n",
    "        self.lstm = nn.LSTM(input_size,hidden_size,num_layers,batch_first=True)\n",
    "    \n",
    "    def get_mask(self,length,max_len):\n",
    "        # length torch.tensor or torch.cuda.tensor [*,b]\n",
    "        if length.is_cuda:\n",
    "            mask = torch.arange(max_len).expand(*length.shape,max_len).to(length.device) < length.unsqueeze(1)\n",
    "        else:\n",
    "            mask = torch.arange(max_len).expand(*length.shape,max_len) < length.unsqueeze(1)\n",
    "        mask = mask.float()\n",
    "        return mask\n",
    "    \n",
    "    def forward(self,inputs,length):\n",
    "        # inputs [b,s,dim] or [s,b,dim]\n",
    "        # length [b,l] \n",
    "        if self.batch_first is False:\n",
    "            inputs = inputs.transpose(0,1)\n",
    "        lstm_out, (h_n,c_n) = self.lstm(inputs)\n",
    "        mask = self.get_mask(length,lstm_out.size(1))\n",
    "        lstm_out_masked = torch.mul(lstm_out,mask.unsqueeze(-1))\n",
    "        h_n_temp = []\n",
    "        \n",
    "        h_n_temp = lstm_out_masked[torch.arange(lstm_out_masked.size(0)).to(lstm_out_masked.device),length-1]\n",
    "#         for i,data in enumerate(lstm_out_masked):\n",
    "#             h_n_temp.append(data[length[i]-1])\n",
    "#         h_n_temp = torch.stack(h_n_temp)\n",
    "        h_n = h_n_temp\n",
    "        if self.batch_first is False:\n",
    "            lstm_out_masked = lstm_out_masked.transpose(0,1)\n",
    "        h_n = h_n.unsqueeze(0)\n",
    "        return lstm_out_masked, (h_n,c_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_self = LSTM_Mask(2,1,num_layers=2,batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_self.lstm.load_state_dict(lstm.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_self,(h_s,c_s) = lstm_self(inputs,length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.equal(out_self,lstm_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实现了双向lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class biLSTM_Mask(nn.Module):\n",
    "    def __init__(self,input_size,hidden_size,num_layers=1,batch_first=False):\n",
    "        super(biLSTM_Mask,self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.batch_first = batch_first\n",
    "        self.fd_lstm = nn.LSTM(input_size,hidden_size,num_layers,batch_first=True)\n",
    "        self.bd_lstm = nn.LSTM(input_size,hidden_size,num_layers,batch_first=True)\n",
    "    \n",
    "    def get_mask(self,length,max_len):\n",
    "        # length torch.tensor or torch.cuda.tensor [*,b]\n",
    "        \n",
    "        if length.is_cuda:\n",
    "            mask = torch.arange(max_len).expand(*length.shape,max_len).to(length.device) < length.unsqueeze(1)\n",
    "        else:\n",
    "            mask = torch.arange(max_len).expand(*length.shape,max_len) < length.unsqueeze(1)\n",
    "        mask = mask.float()\n",
    "        return mask\n",
    "    \n",
    "    def reverse_sequence(self, x, x_lens):\n",
    "        batch_size, seq_len, word_dim = x.size()\n",
    "\n",
    "        inv_idx = torch.arange(seq_len - 1, -1, -1).long()\n",
    "        shift_idx = torch.arange(0, seq_len).long()\n",
    "\n",
    "        if x.is_cuda:\n",
    "            inv_idx = inv_idx.cuda(x.get_device())\n",
    "            shift_idx = shift_idx.cuda(x.get_device())\n",
    "\n",
    "        inv_idx = inv_idx.unsqueeze(0).unsqueeze(-1).expand_as(x)\n",
    "        shift_idx = shift_idx.unsqueeze(0).unsqueeze(-1).expand_as(x)\n",
    "        shift = (seq_len + (-1 * x_lens)).unsqueeze(-1).unsqueeze(-1).expand_as(x)\n",
    "        shift_idx = shift_idx + shift\n",
    "        shift_idx = shift_idx.clamp(0, seq_len - 1)\n",
    "\n",
    "        x = x.gather(1, inv_idx)\n",
    "        x = x.gather(1, shift_idx)\n",
    "\n",
    "        return x \n",
    "    \n",
    "    \n",
    "    def forward(self,inputs,length):\n",
    "        # inputs [b,s,dim] or [s,b,dim]\n",
    "        # length [b] \n",
    "        if self.batch_first is False:\n",
    "            inputs = inputs.transpose(0,1)\n",
    "        ivs_inputs = inputs\n",
    "        ivs_inputs = self.reverse_sequence(inputs,length)\n",
    "        \n",
    "        fd_lstm_out, (fd_h_n,fd_c_n) = self.fd_lstm(inputs)\n",
    "        bd_lstm_out, (bd_h_n,bd_c_n) = self.bd_lstm(ivs_inputs)\n",
    "        fd_mask = self.get_mask(length,fd_lstm_out.size(1))\n",
    "        bd_mask = self.get_mask(length,bd_lstm_out.size(1))\n",
    "        \n",
    "        fd_lstm_out_masked = torch.mul(fd_lstm_out,fd_mask.unsqueeze(-1))\n",
    "        bd_lstm_out = self.reverse_sequence(bd_lstm_out,length)\n",
    "        bd_lstm_out_masked = torch.mul(bd_lstm_out,bd_mask.unsqueeze(-1))\n",
    "        \n",
    "        \n",
    "        \n",
    "        full_out = torch.cat((fd_lstm_out_masked,bd_lstm_out_masked),dim=2)\n",
    "        \n",
    "        \n",
    "#         h_n_f = []\n",
    "#         for i,data in enumerate(fd_lstm_out_masked):\n",
    "#             h_n_f.append(data[length[i]-1])\n",
    "#         h_n_f = torch.stack(h_n_f)\n",
    "        \n",
    "        h_n_f = fd_lstm_out_masked[torch.arange(fd_lstm_out_masked.size(0)).to(fd_lstm_out_masked.device),length-1]\n",
    "        \n",
    "        \n",
    "#         h_n_b = []\n",
    "#         for i,data in enumerate(bd_lstm_out_masked):\n",
    "#             h_n_b.append(data[0])\n",
    "#         h_n_b = torch.stack(h_n_b)\n",
    "        h_n_b = bd_lstm_out_masked[torch.arange(bd_lstm_out_masked.size(0)).to(bd_lstm_out_masked.device),0]\n",
    "        \n",
    "        \n",
    "        \n",
    "        h_n = torch.stack((h_n_f,h_n_b))\n",
    "        \n",
    "\n",
    "        if self.batch_first is False:\n",
    "            full_out = full_out.transpose(0,1)\n",
    "        return full_out, (h_n,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bilstm = nn.LSTM(2,1,batch_first=True,bidirectional=True)\n",
    "bilstm_self = biLSTM_Mask(2,1,batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in bilstm.named_parameters():\n",
    "    print(type(i),'\\t',i[0],'\\t',i[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bilstm_self.fd_lstm.weight_ih_l0 = bilstm.weight_ih_l0\n",
    "bilstm_self.fd_lstm.weight_hh_l0 = bilstm.weight_hh_l0\n",
    "bilstm_self.fd_lstm.bias_ih_l0 = bilstm.bias_ih_l0\n",
    "bilstm_self.fd_lstm.bias_hh_l0 = bilstm.bias_hh_l0\n",
    "\n",
    "bilstm_self.bd_lstm.weight_ih_l0 = bilstm.weight_ih_l0_reverse\n",
    "bilstm_self.bd_lstm.weight_hh_l0 = bilstm.weight_hh_l0_reverse\n",
    "bilstm_self.bd_lstm.bias_ih_l0 = bilstm.bias_ih_l0_reverse\n",
    "bilstm_self.bd_lstm.bias_hh_l0 = bilstm.bias_hh_l0_reverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bibatch_x_pack = torch.nn.utils.rnn.pack_padded_sequence(inputs,length,batch_first=True)\n",
    "bipacked,(h_n,c_n) = bilstm(bibatch_x_pack)\n",
    "bilstm_out,out_len = torch.nn.utils.rnn.pad_packed_sequence(bipacked,batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biout_self,(h_s,c_s) = bilstm_self(inputs,length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.equal(biout_self,bilstm_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.equal(h_n,h_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在有pad长度的attention时候，虽然乘出来是0，但是0经过softmax之后并不是0\n",
    "# 针对这个现象，要做mask，做法很简单，就是在需要mask的地方加上一个很小的负数，不mask的地方加0就行\n",
    "import torch.nn.functional as F\n",
    "temp = torch.tensor([1,2,3,0,0,0]).float()\n",
    "mask = torch.tensor([0,0,0,-100000,-100000,-100000]).float()\n",
    "temp_mask = temp + mask\n",
    "F.softmax(temp)\n",
    "F.softmax(temp_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### shuffle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 5, 0, 3, 6, 1, 7, 4, 9, 8])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r=torch.randperm(10)\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## masked attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "class Attention_masked(nn.Module):\n",
    "    def __init__(self, embed_dim, hidden_dim=None, out_dim=None, n_head=1, score_function='dot_product', dropout=0):\n",
    "        ''' Attention Mechanism\n",
    "        :param embed_dim:\n",
    "        :param hidden_dim:\n",
    "        :param out_dim:\n",
    "        :param n_head: num of head (Multi-Head Attention)\n",
    "        :param score_function: scaled_dot_product / mlp (concat) / bi_linear (general dot)\n",
    "        :return (?, q_len, out_dim,)\n",
    "        '''\n",
    "        super(Attention_masked, self).__init__()\n",
    "        if hidden_dim is None:\n",
    "            hidden_dim = embed_dim // n_head\n",
    "        if out_dim is None:\n",
    "            out_dim = embed_dim\n",
    "        self.embed_dim = embed_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_head = n_head\n",
    "        self.score_function = score_function\n",
    "        self.w_k = nn.Linear(embed_dim, n_head * hidden_dim)\n",
    "        self.w_q = nn.Linear(embed_dim, n_head * hidden_dim)\n",
    "        self.proj = nn.Linear(n_head * hidden_dim, out_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        if score_function == 'mlp':\n",
    "            self.weight = nn.Parameter(torch.Tensor(hidden_dim*2))\n",
    "        elif self.score_function == 'bi_linear':\n",
    "            self.weight = nn.Parameter(torch.Tensor(hidden_dim, hidden_dim))\n",
    "        else:  # dot_product / scaled_dot_product\n",
    "            self.register_parameter('weight', None)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        stdv = 1. / math.sqrt(self.hidden_dim)\n",
    "        if self.weight is not None:\n",
    "            self.weight.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, k, q,k_step,q_step):\n",
    "        '''\n",
    "        k: context\n",
    "        q: target\n",
    "        k_len: k length, shape [batch] (one dementional vector )，tensor\n",
    "        q_len: q length, shape [batch] (one dementional vector), tensor\n",
    "        '''\n",
    "        if len(q.shape) == 2:  # q_len missing\n",
    "            q = torch.unsqueeze(q, dim=1)\n",
    "        if len(k.shape) == 2:  # k_len missing\n",
    "            k = torch.unsqueeze(k, dim=1)\n",
    "        mb_size = k.shape[0]  # ?\n",
    "        k_len = k.shape[1]\n",
    "        q_len = q.shape[1]\n",
    "        mask = torch.tensor([[0]*step + [-10000]*(k_len-step) for step in k_step.numpy()],dtype=torch.float ).unsqueeze(1)\n",
    "        mask = torch.cat([mask for _ in range(self.n_head)],dim=0)\n",
    "        # k: (?, k_len, embed_dim,)\n",
    "        # q: (?, q_len, embed_dim,)\n",
    "        # kx: (n_head*?, k_len, hidden_dim)\n",
    "        # qx: (n_head*?, q_len, hidden_dim)\n",
    "        # score: (n_head*?, q_len, k_len,)\n",
    "        # output: (?, q_len, out_dim,)\n",
    "        kx = self.w_k(k).view(mb_size, k_len, self.n_head, self.hidden_dim)\n",
    "        kx = kx.permute(2, 0, 1, 3).contiguous().view(-1, k_len, self.hidden_dim)\n",
    "        qx = self.w_q(q).view(mb_size, q_len, self.n_head, self.hidden_dim)\n",
    "        qx = qx.permute(2, 0, 1, 3).contiguous().view(-1, q_len, self.hidden_dim)\n",
    "        if self.score_function == 'dot_product':\n",
    "            kt = kx.permute(0, 2, 1)\n",
    "            score = torch.bmm(qx, kt)\n",
    "        elif self.score_function == 'scaled_dot_product':\n",
    "            kt = kx.permute(0, 2, 1)\n",
    "            qkt = torch.bmm(qx, kt)\n",
    "            score = torch.div(qkt, math.sqrt(self.hidden_dim))\n",
    "        elif self.score_function == 'mlp':\n",
    "            kxx = torch.unsqueeze(kx, dim=1).expand(-1, q_len, -1, -1)\n",
    "            qxx = torch.unsqueeze(qx, dim=2).expand(-1, -1, k_len, -1)\n",
    "            kq = torch.cat((kxx, qxx), dim=-1)  # (n_head*?, q_len, k_len, hidden_dim*2)\n",
    "            # kq = torch.unsqueeze(kx, dim=1) + torch.unsqueeze(qx, dim=2)\n",
    "            score = F.tanh(torch.matmul(kq, self.weight))\n",
    "        elif self.score_function == 'bi_linear':\n",
    "            qw = torch.matmul(qx, self.weight)\n",
    "            kt = kx.permute(0, 2, 1)\n",
    "            score = torch.bmm(qw, kt)\n",
    "        else:\n",
    "            raise RuntimeError('invalid score_function')\n",
    "        score = score + mask\n",
    "        score = F.softmax(score, dim=-1)\n",
    "        output = torch.bmm(score, kx)  # (n_head*?, q_len, hidden_dim)\n",
    "        output = torch.cat(torch.split(output, mb_size, dim=0), dim=-1)  # (?, q_len, n_head*hidden_dim)\n",
    "        output = self.proj(output)  # (?, q_len, out_dim)\n",
    "        output = self.dropout(output)\n",
    "        return output, score\n",
    "\n",
    "k = torch.randn((32,23,300))\n",
    "# q = torch.randn((32,300)) is also right\n",
    "q = torch.randn((32,3,300))\n",
    "k_step = torch.randint(0,23,(32,),dtype=torch.int)\n",
    "q_step = torch.full((32,),1,dtype=torch.int)\n",
    "k_len = 23\n",
    "\n",
    "output,score  =  att(k,q,k_step,q_step)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py3_4.0]",
   "language": "python",
   "name": "conda-env-py3_4.0-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
