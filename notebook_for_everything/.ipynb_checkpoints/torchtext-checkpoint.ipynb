{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# this note book is for torchtext tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext import data\n",
    "from torchtext import vocab\n",
    "from torchtext.data import Dataset\n",
    "from torchtext.data import Field\n",
    "from torchtext.data.example import  Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## field "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "主要功能\n",
    "- tokenization(创建Example时): \"hello world.\" --> [\"hello\", \"world\", \".\"]\n",
    "- 构建 Vocab\n",
    "- pad(创建Batch时): [\"hello\", \"world\", \".\"] --> [\"hello\", \"world\", \".\", \"<pad>\", \"<pad>\"]因为每个 Example 的长度不一定相等, 需要 pad 成相同长度才可以 batch 起来.\n",
    "- neumericalize(pad之后的操作, 需要有Vocab介入): [\"hello\", \"world\", \".\", \"<pad>\", \"<pad>\"] --> [2, 3, 4, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_field = Field(sequential=True,include_lengths=True,use_vocab=True,batch_first=True)    # sequential 表明 是否是连续文本\n",
    "label_field = Field(sequential=False,use_vocab=True,pad_token=None,unk_token=None,batch_first=True)\n",
    "#如果标签的 use_vocab=false 则 data（[‘text’，label]）中的lable为数字，如果use_vocab=true，则lable为字符串\n",
    "\n",
    "# for Example.fromlist to get example\n",
    "train_fields_list  = [('text',txt_field),('label',label_field)]\n",
    "test_fields_list  = [('text',txt_field)]\n",
    "\n",
    "# for Example.fromdict to get example\n",
    "train_fields_dict = {'text':('text',txt_field),'label':('label',label_field)}\n",
    "test_fields_dic = {'text':('text',txt_field)}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "example 对象 是只有属性的简单对象\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "例如 对象只有 example.text example.label 两个属性"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "example 的构建需要输入 数据（一条） 和 对应的field\n",
    "同时需要将数据处理成与example.fromXXX相对应的格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for Example.fromlist and it should be corresponding to the fields_list\n",
    "data_list_train = ['this is an example','1']\n",
    "data_list_test = ['this is for test']\n",
    "\n",
    "# for Example.fromdict and it should be corresponding to the fields_dic\n",
    "data_dict_train = {'text':'this is an example for dict','label':'1'}\n",
    "data_dict_test = {'text':'this is test for dict'}\n",
    "\n",
    "# construct example from Example.fromlist\n",
    "example_train_list = Example.fromlist(data_list_train,train_fields_list)\n",
    "example_test_list = Example.fromlist(data_list_test,test_fields_list)\n",
    "\n",
    "# construct example from Example.fromdict\n",
    "example_train_dict = Example.fromdict(data_dict_train,train_fields_dict)\n",
    "example_text_dict = Example.fromdict(data_dict_test,test_fields_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['this', 'is', 'an', 'example'] ['this', 'is', 'an', 'example', 'for', 'dict']\n",
      "<torchtext.data.example.Example object at 0x7fa60b1f1438>\n"
     ]
    }
   ],
   "source": [
    "print(example_train_list.text,example_train_dict.text)\n",
    "print(example_test_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get example list to construct dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_examples = [Example.fromlist(i,train_fields) for i in train_data]\n",
    "test_examples = [Example.fromlist(i,test_fields) for i in test_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainSet = Dataset(train_examples,train_fields)\n",
    "valSet = Dataset(val_examples,train_fields)\n",
    "testSet = Dataset(test_examples,test_fields)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataset construction -- vector and vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vector\n",
    "attribute :\n",
    "- itos\n",
    "- stoi\n",
    "- dim\n",
    "- vectors\n",
    "\n",
    "vector 对象用来加载已经预训练过的vector，对象会加载vector文件中所有单词，建立映射，如果内存不够，则将max_vectors 赋值，限制整个加载的预训练的单词数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = vocab.Vectors('cc.zh.300.vec',r'/home/yinrongdi/vector',\n",
    "                    unk_init=torch.nn.init.xavier_uniform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vocab \n",
    "vocab 对象是field对象的一个属性，vocab对象使用field.build_vocab构建，\n",
    "- stoi\n",
    "- itos\n",
    "- freqs\n",
    "- vetcors\n",
    "\n",
    "vocab 对象用来构建field下一系列dataset的词表，以及词表对应的预训练vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_field.build_vocab(trainSet,testSet,valSet, min_freq = 1,vectors = vec )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## batch and iterator\n",
    "构建batch之后，产生iterator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### batch\n",
    "Create a Batch from a list of examples\n",
    "__init__(self, data=None, dataset=None, device=None) 将data（list（example））中所有的数据打包成batch，同时进行pad 和 numerical 操作。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "batch 的生成，是在声明iterator之后，内部自动构建的，所以无需进行特殊操作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## iterator\n",
    "- sort: \n",
    "            Whether to sort examples according to self.sort_key.\n",
    "            Note that shuffle and sort default to train and (not train).\n",
    "- sort_within_batch: \n",
    "            Whether to sort (in descending order according to\n",
    "            self.sort_key) within each batch. If None, defaults to self.sort.\n",
    "            If self.sort is True and this is False, the batch is left in the\n",
    "            original (ascending) sorted order.\n",
    "- device (str or `torch.device`): \n",
    "            A string or instance of `torch.device`\n",
    "            specifying which device the Variables are going to be created on.\n",
    "            If left as default, the tensors will be created on cpu. Default: None.\n",
    "将构建好的batch 通过generator的形式进行返回，从而构建好了迭代器，如果要指定gup，直接在这里指定就行了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDl = data.Iterator(trainSet,shuffle=True,batch_size = 64,sort_key=lambda x: len(x.text),sort_within_batch=True,repeat=False,sort=True)\n",
    "valDl = data.Iterator(valSet,shuffle=False,batch_size = 1,sort_key=lambda x: len(x.text),sort_within_batch=True,repeat=False,sort=True)\n",
    "#sort = True\n",
    "testDl = data.Iterator(testSet,shuffle=False,batch_size = 1,sort_key=lambda x: len(x.text),sort_within_batch=True,repeat=False,sort=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 至此，所有的前期处理工作完成，后续就是搭建模型进行处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# for pytorch defalt dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "import collections\n",
    "\n",
    "da = [[torch.tensor([1]),\n",
    "       torch.tensor([2,2]),\n",
    "       torch.tensor([3,3,3]),\n",
    "       torch.tensor([4,4,4,4]),\n",
    "       torch.tensor([5,5,5,5,5])],[1,2,3,4,5]]\n",
    "\n",
    "def collate_fn_rand(batch):\n",
    "    '''\n",
    "    :param batch: batch[0] is tensor by defalt\n",
    "    :return:\n",
    "    '''\n",
    "    if isinstance(batch[0],collections.Sequence):\n",
    "        transposed = zip(*batch)\n",
    "        return [collate_fn_rand(samples) for samples in transposed]\n",
    "    elif torch.is_tensor(batch[0]):\n",
    "        # 如果是标量，对应数据的label\n",
    "        if batch[0].shape == torch.Size([]):\n",
    "            return torch.stack(batch)\n",
    "\n",
    "        max_len = max([len(i) for i in batch])\n",
    "        pad_batch = [torch.tensor(i.numpy().tolist()+[0]*(max_len - len(i))).long()for i in batch]\n",
    "        pad_batch = torch.stack(pad_batch)\n",
    "        return pad_batch\n",
    "    elif isinstance(batch[0],int):\n",
    "        return torch.tensor(batch).long()\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "class myds(data.Dataset):\n",
    "    def __init__(self,da,sort=False):\n",
    "        self.context = da[0]\n",
    "        self.label = da[1]\n",
    "        if sort:\n",
    "            self.sort_data()\n",
    "    def sort_data(self):\n",
    "        data_len = [len(data) for data in self.context]\n",
    "        sort_index = torch.sort(torch.tensor(data_len),descending=True)[1].long()]\n",
    "        self.context = [self.contex[i] for i in sort_index]\n",
    "        self.label = [self.label[i] for i in sort_index]\n",
    "    def __len__(self):\n",
    "        return len(self.data[0])\n",
    "    def __getitem__(self, index):\n",
    "        return self.context[index] , self.label[index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 0, 0],\n",
      "        [3, 3, 3],\n",
      "        [2, 2, 0]]) tensor([1, 3, 2])\n",
      "\n",
      "tensor([[5, 5, 5, 5, 5],\n",
      "        [4, 4, 4, 4, 0]]) tensor([5, 4])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# for random select and pad\n",
    "mydata = myds(da)\n",
    "myloader = data.DataLoader(dataset=mydata,batch_size=3,shuffle=True,collate_fn=collate_fn_rand)\n",
    "for data ,label in myloader:\n",
    "    print(data,label)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for less pad"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py3_4.0]",
   "language": "python",
   "name": "conda-env-py3_4.0-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
