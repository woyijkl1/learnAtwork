{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-29T04:17:53.110645Z",
     "start_time": "2021-07-29T04:17:50.069218Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2959 - accuracy: 0.9139\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1412 - accuracy: 0.9588\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1077 - accuracy: 0.9678\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0851 - accuracy: 0.9731\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0755 - accuracy: 0.9772\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff71a8341d0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 0s - loss: 0.0750 - accuracy: 0.9773\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07500936836004257, 0.9772999882698059]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test,  y_test, verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tf-datasets/titanic/train.csv\n",
      "32768/30874 [===============================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tf-datasets/titanic/eval.csv\n",
      "16384/13049 [=====================================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "TRAIN_DATA_URL = \"https://storage.googleapis.com/tf-datasets/titanic/train.csv\"\n",
    "TEST_DATA_URL = \"https://storage.googleapis.com/tf-datasets/titanic/eval.csv\"\n",
    "\n",
    "train_file_path = tf.keras.utils.get_file(\"train.csv\", TRAIN_DATA_URL)\n",
    "test_file_path = tf.keras.utils.get_file(\"eval.csv\", TEST_DATA_URL)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=3, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_COLUMN = 'survived'\n",
    "LABELS = [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(file_path):\n",
    "  dataset = tf.data.experimental.make_csv_dataset(\n",
    "      file_path,\n",
    "      batch_size=12, # 为了示例更容易展示，手动设置较小的值\n",
    "      label_name=LABEL_COLUMN,\n",
    "      na_value=\"?\",\n",
    "      num_epochs=1,\n",
    "      ignore_errors=True)\n",
    "  return dataset\n",
    "\n",
    "raw_train_data = get_dataset(train_file_path)\n",
    "raw_test_data = get_dataset(test_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXAMPLES: \n",
      " OrderedDict([('sex', <tf.Tensor: shape=(12,), dtype=string, numpy=\n",
      "array([b'male', b'male', b'female', b'female', b'female', b'male',\n",
      "       b'female', b'female', b'male', b'male', b'male', b'female'],\n",
      "      dtype=object)>), ('age', <tf.Tensor: shape=(12,), dtype=float32, numpy=\n",
      "array([28., 33., 27., 32.,  2., 64., 14.,  9., 28., 21.,  4., 44.],\n",
      "      dtype=float32)>), ('n_siblings_spouses', <tf.Tensor: shape=(12,), dtype=int32, numpy=array([0, 0, 0, 0, 1, 1, 0, 3, 0, 0, 4, 0], dtype=int32)>), ('parch', <tf.Tensor: shape=(12,), dtype=int32, numpy=array([0, 0, 2, 0, 1, 4, 0, 2, 0, 0, 2, 1], dtype=int32)>), ('fare', <tf.Tensor: shape=(12,), dtype=float32, numpy=\n",
      "array([  7.75 ,   8.654,  11.133,  13.   ,  26.   , 263.   ,   7.854,\n",
      "        27.9  ,  31.   ,   8.433,  31.275,  57.979], dtype=float32)>), ('class', <tf.Tensor: shape=(12,), dtype=string, numpy=\n",
      "array([b'Third', b'Third', b'Third', b'Second', b'Second', b'First',\n",
      "       b'Third', b'Third', b'First', b'Third', b'Third', b'First'],\n",
      "      dtype=object)>), ('deck', <tf.Tensor: shape=(12,), dtype=string, numpy=\n",
      "array([b'unknown', b'unknown', b'unknown', b'unknown', b'unknown', b'C',\n",
      "       b'unknown', b'unknown', b'unknown', b'unknown', b'unknown', b'B'],\n",
      "      dtype=object)>), ('embark_town', <tf.Tensor: shape=(12,), dtype=string, numpy=\n",
      "array([b'Queenstown', b'Southampton', b'Southampton', b'Southampton',\n",
      "       b'Southampton', b'Southampton', b'Southampton', b'Southampton',\n",
      "       b'Southampton', b'Southampton', b'Southampton', b'Cherbourg'],\n",
      "      dtype=object)>), ('alone', <tf.Tensor: shape=(12,), dtype=string, numpy=\n",
      "array([b'y', b'y', b'n', b'y', b'n', b'n', b'y', b'n', b'y', b'y', b'n',\n",
      "       b'n'], dtype=object)>)]) \n",
      "\n",
      "LABELS: \n",
      " tf.Tensor([0 0 1 1 1 0 0 0 0 0 0 1], shape=(12,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "examples, labels = next(iter(raw_train_data)) # 第一个批次\n",
    "print(\"EXAMPLES: \\n\", examples, \"\\n\")\n",
    "print(\"LABELS: \\n\", labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORIES = {\n",
    "    'sex': ['male', 'female'],\n",
    "    'class' : ['First', 'Second', 'Third'],\n",
    "    'deck' : ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J'],\n",
    "    'embark_town' : ['Cherbourg', 'Southhampton', 'Queenstown'],\n",
    "    'alone' : ['y', 'n']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = []\n",
    "for feature, vocab in CATEGORIES.items():\n",
    "  cat_col = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "        key=feature, vocabulary_list=vocab)\n",
    "  categorical_columns.append(tf.feature_column.indicator_column(cat_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.feature_column.feature_column_v2.IndicatorColumn"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(categorical_columns[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_continuous_data(mean, data):\n",
    "  # 标准化数据\n",
    "  data = tf.cast(data, tf.float32) * 1/(2*mean)\n",
    "  return tf.reshape(data, [-1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "MEANS = {\n",
    "    'age' : 29.631308,\n",
    "    'n_siblings_spouses' : 0.545455,\n",
    "    'parch' : 0.379585,\n",
    "    'fare' : 34.385399\n",
    "}\n",
    "\n",
    "numerical_columns = []\n",
    "\n",
    "for feature in MEANS.keys():\n",
    "  num_col = tf.feature_column.numeric_column(feature, normalizer_fn=functools.partial(process_continuous_data, MEANS[feature]))\n",
    "  numerical_columns.append(num_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[NumericColumn(key='age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=functools.partial(<function process_continuous_data at 0x7ff61c466510>, 29.631308)),\n",
       " NumericColumn(key='n_siblings_spouses', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=functools.partial(<function process_continuous_data at 0x7ff61c466510>, 0.545455)),\n",
       " NumericColumn(key='parch', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=functools.partial(<function process_continuous_data at 0x7ff61c466510>, 0.379585)),\n",
       " NumericColumn(key='fare', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=functools.partial(<function process_continuous_data at 0x7ff61c466510>, 34.385399))]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_layer = tf.keras.layers.DenseFeatures(categorical_columns+numerical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "  preprocessing_layer,\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(1, activation='sigmoid'),\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = raw_train_data.shuffle(500)\n",
    "test_data = raw_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'collections.OrderedDict'> input: OrderedDict([('sex', <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=string>), ('age', <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float32>), ('n_siblings_spouses', <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=int32>), ('parch', <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=int32>), ('fare', <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float32>), ('class', <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=string>), ('deck', <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=string>), ('embark_town', <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=string>), ('alone', <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=string>)])\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'collections.OrderedDict'> input: OrderedDict([('sex', <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=string>), ('age', <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float32>), ('n_siblings_spouses', <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=int32>), ('parch', <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=int32>), ('fare', <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float32>), ('class', <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=string>), ('deck', <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=string>), ('embark_town', <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=string>), ('alone', <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=string>)])\n",
      "Consider rewriting this model with the Functional API.\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.5596 - accuracy: 0.7448\n",
      "Epoch 2/20\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.4483 - accuracy: 0.8070\n",
      "Epoch 3/20\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.4375 - accuracy: 0.8086\n",
      "Epoch 4/20\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.4125 - accuracy: 0.8293\n",
      "Epoch 5/20\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.4071 - accuracy: 0.8198\n",
      "Epoch 6/20\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.4024 - accuracy: 0.8293\n",
      "Epoch 7/20\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.3874 - accuracy: 0.8341\n",
      "Epoch 8/20\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.3861 - accuracy: 0.8325\n",
      "Epoch 9/20\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.3748 - accuracy: 0.8325\n",
      "Epoch 10/20\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.3862 - accuracy: 0.8325\n",
      "Epoch 11/20\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.3754 - accuracy: 0.8421\n",
      "Epoch 12/20\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.3678 - accuracy: 0.8357\n",
      "Epoch 13/20\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.3601 - accuracy: 0.8437\n",
      "Epoch 14/20\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.3612 - accuracy: 0.8373\n",
      "Epoch 15/20\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.3525 - accuracy: 0.8453\n",
      "Epoch 16/20\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.3530 - accuracy: 0.8453\n",
      "Epoch 17/20\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.3485 - accuracy: 0.8549\n",
      "Epoch 18/20\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.3494 - accuracy: 0.8501\n",
      "Epoch 19/20\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.3445 - accuracy: 0.8501\n",
      "Epoch 20/20\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.3384 - accuracy: 0.8565\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff5fc62e1d0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_data, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'collections.OrderedDict'> input: OrderedDict([('sex', <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=string>), ('age', <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float32>), ('n_siblings_spouses', <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=int32>), ('parch', <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=int32>), ('fare', <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float32>), ('class', <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=string>), ('deck', <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=string>), ('embark_town', <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=string>), ('alone', <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=string>)])\n",
      "Consider rewriting this model with the Functional API.\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.4354 - accuracy: 0.8295\n",
      "\n",
      "\n",
      "Test Loss 0.4353879690170288, Test Accuracy 0.8295454382896423\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_data)\n",
    "\n",
    "print('\\n\\nTest Loss {}, Test Accuracy {}'.format(test_loss, test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'collections.OrderedDict'> input: OrderedDict([('sex', <tf.Tensor 'ExpandDims_8:0' shape=(None, 1) dtype=string>), ('age', <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float32>), ('n_siblings_spouses', <tf.Tensor 'ExpandDims_6:0' shape=(None, 1) dtype=int32>), ('parch', <tf.Tensor 'ExpandDims_7:0' shape=(None, 1) dtype=int32>), ('fare', <tf.Tensor 'ExpandDims_5:0' shape=(None, 1) dtype=float32>), ('class', <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=string>), ('deck', <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=string>), ('embark_town', <tf.Tensor 'ExpandDims_4:0' shape=(None, 1) dtype=string>), ('alone', <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=string>)])\n",
      "Consider rewriting this model with the Functional API.\n",
      "Predicted survival: 6.11%  | Actual outcome:  DIED\n",
      "Predicted survival: 7.53%  | Actual outcome:  SURVIVED\n",
      "Predicted survival: 34.53%  | Actual outcome:  SURVIVED\n",
      "Predicted survival: 17.09%  | Actual outcome:  DIED\n",
      "Predicted survival: 27.22%  | Actual outcome:  DIED\n",
      "Predicted survival: 55.60%  | Actual outcome:  SURVIVED\n",
      "Predicted survival: 5.39%  | Actual outcome:  DIED\n",
      "Predicted survival: 7.38%  | Actual outcome:  DIED\n",
      "Predicted survival: 10.85%  | Actual outcome:  DIED\n",
      "Predicted survival: 54.94%  | Actual outcome:  SURVIVED\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_data)\n",
    "\n",
    "# 显示部分结果\n",
    "for prediction, survived in zip(predictions[:10], list(test_data)[0][1][:10]):\n",
    "  print(\"Predicted survival: {:.2%}\".format(prediction[0]),\n",
    "        \" | Actual outcome: \",\n",
    "        (\"SURVIVED\" if bool(survived) else \"DIED\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### question about tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorflow 如何利用gpu加速计算  如何在cpu和gpu之间计算梯度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### from simple tensorflow // tf.wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTLoader():\n",
    "    def __init__(self):\n",
    "        mnist = tf.keras.datasets.mnist\n",
    "        (self.train_data, self.train_label), (self.test_data, self.test_label) = mnist.load_data()\n",
    "        # MNIST中的图像默认为uint8（0-255的数字）。以下代码将其归一化到0-1之间的浮点数，并在最后增加一维作为颜色通道\n",
    "        self.train_data = np.expand_dims(self.train_data.astype(np.float32) / 255.0, axis=-1)      # [60000, 28, 28, 1]\n",
    "        self.test_data = np.expand_dims(self.test_data.astype(np.float32) / 255.0, axis=-1)        # [10000, 28, 28, 1]\n",
    "        self.train_label = self.train_label.astype(np.int32)    # [60000]\n",
    "        self.test_label = self.test_label.astype(np.int32)      # [10000]\n",
    "        self.num_train_data, self.num_test_data = self.train_data.shape[0], self.test_data.shape[0]\n",
    "\n",
    "    def get_batch(self, batch_size):\n",
    "        # 从数据集中随机取出batch_size个元素并返回\n",
    "        index = np.random.randint(0, self.num_train_data, batch_size)\n",
    "        return self.train_data[index, :], self.train_label[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = tf.keras.layers.Flatten()    # Flatten层将除第一维（batch_size）以外的维度展平\n",
    "        self.dense1 = tf.keras.layers.Dense(units=100, activation=tf.nn.relu)\n",
    "        self.dense2 = tf.keras.layers.Dense(units=10)\n",
    "\n",
    "    def call(self, inputs):         # [batch_size, 28, 28, 1]\n",
    "        x = self.flatten(inputs)    # [batch_size, 784]\n",
    "        x = self.dense1(x)          # [batch_size, 100]\n",
    "        x = self.dense2(x)          # [batch_size, 10]\n",
    "        output = tf.nn.softmax(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "batch_size = 50\n",
    "learning_rate = 0.001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP()\n",
    "data_loader = MNISTLoader()\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m<ipython-input-14-fe9ac746167e>\u001b[0m(4)\u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m      2 \u001b[0;31m\u001b[0;32mfor\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      3 \u001b[0;31m    \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m----> 4 \u001b[0;31m    \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      5 \u001b[0;31m    \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      6 \u001b[0;31m        \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m<ipython-input-14-fe9ac746167e>\u001b[0m(5)\u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m      3 \u001b[0;31m    \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      4 \u001b[0;31m    \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m----> 5 \u001b[0;31m    \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      6 \u001b[0;31m        \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      7 \u001b[0;31m        \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse_categorical_crossentropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> type(X)\n",
      "<class 'numpy.ndarray'>\n",
      "ipdb> X.shape\n",
      "(50, 28, 28, 1)\n",
      "ipdb> q\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-fe9ac746167e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse_categorical_crossentropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-fe9ac746167e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse_categorical_crossentropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;31m# None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'line'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_batches = int(data_loader.num_train_data // batch_size * num_epochs)\n",
    "for batch_index in range(num_batches):\n",
    "    pdb.set_trace()\n",
    "    X, y = data_loader.get_batch(batch_size)\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = model(X)\n",
    "        loss = tf.keras.losses.sparse_categorical_crossentropy(y_true=y, y_pred=y_pred)\n",
    "        loss = tf.reduce_mean(loss)\n",
    "        print(\"batch %d: loss %f\" % (batch_index, loss.numpy()))\n",
    "    grads = tape.gradient(loss, model.variables)\n",
    "    optimizer.apply_gradients(grads_and_vars=zip(grads, model.variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tensorflow api learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-29T14:45:06.616677Z",
     "start_time": "2021-07-29T14:45:06.613611Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.3'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#查看版本号\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-29T04:17:57.876391Z",
     "start_time": "2021-07-29T04:17:57.776912Z"
    }
   },
   "outputs": [],
   "source": [
    "t=[[[1,1,1],[2,2,2]],[[3,3,3],[4,4,4]],[[5,5,5],[6,6,6]]]\n",
    "s1=tf.slice(t,[1,0,0],[1,1,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-29T04:20:13.232593Z",
     "start_time": "2021-07-29T04:20:13.228715Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[1, 1, 1], [2, 2, 2]], [[3, 3, 3], [4, 4, 4]], [[5, 5, 5], [6, 6, 6]]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-29T04:27:05.448737Z",
     "start_time": "2021-07-29T04:27:05.445450Z"
    }
   },
   "outputs": [],
   "source": [
    "t1 = tf.constant([0, 1, 2, 3, 4, 5, 6, 7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-29T04:27:12.332286Z",
     "start_time": "2021-07-29T04:27:12.328078Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1 2 3], shape=(3,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(tf.slice(t1,\n",
    "               begin=[1],\n",
    "               size=[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-29T07:33:29.146529Z",
     "start_time": "2021-07-29T07:33:29.144473Z"
    }
   },
   "outputs": [],
   "source": [
    "# loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-29T07:41:35.705111Z",
     "start_time": "2021-07-29T07:41:35.702287Z"
    }
   },
   "outputs": [],
   "source": [
    "y_true = [[0, 1], [0, 0]]\n",
    "y_pred = [[-18.6, 0.51], [2.94, -12.8]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-29T07:41:36.471556Z",
     "start_time": "2021-07-29T07:41:36.468300Z"
    }
   },
   "outputs": [],
   "source": [
    "bce = tf.keras.losses.BinaryCrossentropy(from_logits=True, reduction=tf.keras.losses.Reduction.NONE)\n",
    "bce1 = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-29T07:42:06.359949Z",
     "start_time": "2021-07-29T07:42:06.354965Z"
    }
   },
   "outputs": [],
   "source": [
    "x = bce(y_true, y_pred)\n",
    "x1 = bce1(y_true,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-29T07:42:12.008779Z",
     "start_time": "2021-07-29T07:42:12.004591Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([0.23515666, 1.4957594 ], dtype=float32)>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-29T07:42:12.658164Z",
     "start_time": "2021-07-29T07:42:12.654424Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.865458>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-29T07:55:56.494120Z",
     "start_time": "2021-07-29T07:55:56.490288Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.865458>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2 = tf.nn.compute_average_loss(x,global_batch_size=2)\n",
    "x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-30T11:07:53.804116Z",
     "start_time": "2021-07-30T11:07:53.801414Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow.keras import Model #与tensorflow.python.keras\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-30T11:08:02.343061Z",
     "start_time": "2021-07-30T11:08:02.222891Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracing with tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "Tracing with Tensor(\"input_1:0\", shape=(), dtype=float32)\n",
      "Tracing with Tensor(\"input_1:0\", shape=(), dtype=float32)\n",
      "INFO:tensorflow:Assets written to: ./module_no_signatures_model_nopython/assets\n",
      "tf.Tensor(3.0, shape=(), dtype=float32)\n",
      "None\n",
      "tf.Tensor(6.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 用keras.Model 则不需要用 @tf.function\n",
    "class CustomModule(Model):\n",
    "\n",
    "  def __init__(self):\n",
    "    super(CustomModule, self).__init__()\n",
    "    self.v = tf.Variable(1.)\n",
    "\n",
    "  def call(self, x):\n",
    "    print('Tracing with', x)\n",
    "    return x * self.v\n",
    "\n",
    "  @tf.function(input_signature=[tf.TensorSpec([], tf.float32)])\n",
    "  def mutate(self, new_v):\n",
    "    self.v.assign(new_v)\n",
    "\n",
    "module = CustomModule()\n",
    "\n",
    "module_no_signatures_path = os.path.join('./', 'module_no_signatures_model_nopython')\n",
    "\n",
    "print(module(tf.constant(0.)) )\n",
    "\n",
    "tf.saved_model.save(module, module_no_signatures_path) \n",
    "\n",
    "imported = tf.saved_model.load(module_no_signatures_path)\n",
    "\n",
    "print(imported(tf.constant(3.)) )\n",
    "\n",
    "print(imported.mutate(tf.constant(2.)) )\n",
    "\n",
    "print(imported(tf.constant(3.)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-30T09:42:06.492177Z",
     "start_time": "2021-07-30T09:42:06.354560Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracing with Tensor(\"x:0\", shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "Tracing with Tensor(\"x:0\", shape=(), dtype=float32)\n",
      "INFO:tensorflow:Assets written to: ./module_no_signatures_module_temp/assets\n",
      "None\n",
      "tf.Tensor(6.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 使用tf.Module则需要 @tf.function\n",
    "class CustomModule(tf.Module):\n",
    "\n",
    "  def __init__(self):\n",
    "    super(CustomModule, self).__init__()\n",
    "    self.v = tf.Variable(1.)\n",
    "\n",
    "  @tf.function  # ruguo 这里删除@tf.function则29行报错\n",
    "  def __call__(self, x):\n",
    "    print('Tracing with', x)\n",
    "    return x * self.v\n",
    "\n",
    "  @tf.function(input_signature=[tf.TensorSpec([], tf.float32)])\n",
    "  def mutate(self, new_v):\n",
    "    self.v.assign(new_v)\n",
    "\n",
    "module = CustomModule()\n",
    "\n",
    "module_no_signatures_path = os.path.join('./', 'module_no_signatures_module_temp')\n",
    "\n",
    "print(module(tf.constant(0.)) )\n",
    "\n",
    "tf.saved_model.save(module, module_no_signatures_path) \n",
    "\n",
    "imported = tf.saved_model.load(module_no_signatures_path)\n",
    "\n",
    "print(imported.mutate(tf.constant(2.0)) )\n",
    "\n",
    "print(imported(tf.constant(3.)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-30T09:57:05.540573Z",
     "start_time": "2021-07-30T09:57:05.448317Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracing with tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "Tracing with Tensor(\"input_1:0\", shape=(), dtype=float32)\n",
      "Tracing with Tensor(\"input_1:0\", shape=(), dtype=float32)\n",
      "INFO:tensorflow:Assets written to: ./module_no_signatures_model_keras/assets\n"
     ]
    }
   ],
   "source": [
    "# keras 保存方式\n",
    "class CustomModule(Model):\n",
    "\n",
    "  def __init__(self):\n",
    "    super(CustomModule, self).__init__()\n",
    "    self.v = tf.Variable(1.)\n",
    "\n",
    "  def call(self, x):\n",
    "    print('Tracing with', x)\n",
    "    return x * self.v\n",
    "\n",
    "  @tf.function(input_signature=[tf.TensorSpec([], tf.float32)])\n",
    "  def mutate(self, new_v):\n",
    "    self.v.assign(new_v)\n",
    "\n",
    "module = CustomModule()\n",
    "\n",
    "module_no_signatures_path = os.path.join('./', 'module_no_signatures_model_keras')\n",
    "\n",
    "print(module(tf.constant(0.)) )\n",
    "\n",
    "module.save(module_no_signatures_path)\n",
    "\n",
    "\n",
    "imported = keras.models.load_model(module_no_signatures_path)\n",
    "\n",
    "print(imported.mutate(tf.constant(2.0)) )\n",
    "\n",
    "print(imported(tf.constant(3.)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-30T10:52:59.610178Z",
     "start_time": "2021-07-30T10:52:59.606591Z"
    }
   },
   "outputs": [],
   "source": [
    "# check-point\n",
    "# 设置断点\n",
    "checkpoint = tf.train.Checkpoint(module=module)\n",
    "manager = tf.train.CheckpointManager(\n",
    "    checkpoint, directory=\"./module_no_signatures_model_checkpoint\", max_to_keep=2)\n",
    "\n",
    "\n",
    "# 保存断点\n",
    "manager.save()\n",
    "\n",
    "manager.save()\n",
    "\n",
    "manager.save()\n",
    "\n",
    "module.mutate(5.0)\n",
    "\n",
    "print(module(1.0))\n",
    "\n",
    "# 加载最新的断点，会去更新checkpoint里面的参数\n",
    "status = checkpoint.restore(manager.latest_checkpoint)\n",
    "\n",
    "print(module(1.0))\n",
    "\n",
    "# 访问ckpt成员\n",
    "checkpoint.step\n",
    "\n",
    "# todo check if iterator can be restored by checkpoint.restore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-02T08:33:56.334628Z",
     "start_time": "2021-08-02T08:33:56.311296Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(), dtype=float64, numpy=0.1>, <tf.Tensor: shape=(), dtype=int64, numpy=0>)\n",
      "(<tf.Tensor: shape=(), dtype=float64, numpy=0.2>, <tf.Tensor: shape=(), dtype=int64, numpy=0>)\n",
      "(<tf.Tensor: shape=(), dtype=float64, numpy=0.3>, <tf.Tensor: shape=(), dtype=int64, numpy=1>)\n",
      "(<tf.Tensor: shape=(), dtype=float64, numpy=0.4>, <tf.Tensor: shape=(), dtype=int64, numpy=0>)\n",
      "(<tf.Tensor: shape=(), dtype=float64, numpy=0.5>, <tf.Tensor: shape=(), dtype=int64, numpy=1>)\n",
      "(<tf.Tensor: shape=(), dtype=float64, numpy=0.6>, <tf.Tensor: shape=(), dtype=int64, numpy=1>)\n",
      "---------------\n",
      "(<tf.Tensor: shape=(), dtype=float64, numpy=0.8>, <tf.Tensor: shape=(), dtype=int64, numpy=1>)\n",
      "(<tf.Tensor: shape=(), dtype=float64, numpy=0.9>, <tf.Tensor: shape=(), dtype=int64, numpy=0>)\n",
      "(<tf.Tensor: shape=(), dtype=float64, numpy=1.0>, <tf.Tensor: shape=(), dtype=int64, numpy=0>)\n",
      "-------------\n",
      "---------------\n",
      "restored\n",
      "(<tf.Tensor: shape=(), dtype=float64, numpy=0.8>, <tf.Tensor: shape=(), dtype=int64, numpy=1>)\n",
      "(<tf.Tensor: shape=(), dtype=float64, numpy=0.9>, <tf.Tensor: shape=(), dtype=int64, numpy=0>)\n",
      "(<tf.Tensor: shape=(), dtype=float64, numpy=1.0>, <tf.Tensor: shape=(), dtype=int64, numpy=0>)\n"
     ]
    }
   ],
   "source": [
    "#iterator can be saved as follows\n",
    "data = np.array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0])\n",
    "label = np.array([0, 0, 1, 0, 1, 1, 0, 1, 0, 0])\n",
    "dataset = tf.data.Dataset.from_tensor_slices((data, label))\n",
    "it = iter(dataset)\n",
    "checkpoint = tf.train.Checkpoint(iterator=it)\n",
    "manager = tf.train.CheckpointManager(\n",
    "    checkpoint, directory=\"./module_no_signatures_iterator\", max_to_keep=1)\n",
    "\n",
    "\n",
    "step = 0\n",
    "for i in it:\n",
    "    if step >5:\n",
    "        break\n",
    "    step +=1\n",
    "    print(i)\n",
    "\n",
    "print('---------------')\n",
    "manager.save()\n",
    "\n",
    "for i in it:\n",
    "    print(i)\n",
    "\n",
    "print('-------------')\n",
    "for i in it:\n",
    "    print(i)\n",
    "print('---------------')\n",
    "print('restored')\n",
    "status = checkpoint.restore(manager.latest_checkpoint)\n",
    "for i in it:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-31T10:14:11.663351Z",
     "start_time": "2021-07-31T10:14:11.345255Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/fsns-20160927/testdata/fsns-00000-of-00001\n",
      "7905280/7904079 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "fsns_test_file = tf.keras.utils.get_file(\"fsns.tfrec\", \"https://storage.googleapis.com/download.tensorflow.org/data/fsns-20160927/testdata/fsns-00000-of-00001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-31T10:14:25.399849Z",
     "start_time": "2021-07-31T10:14:25.375901Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TFRecordDatasetV2 shapes: (), types: tf.string>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = tf.data.TFRecordDataset(filenames = [fsns_test_file])\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-31T10:14:48.409154Z",
     "start_time": "2021-07-31T10:14:48.396452Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bytes_list {\n",
       "  value: \"Rue Perreyon\"\n",
       "}"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_example = next(iter(dataset))\n",
    "parsed = tf.train.Example.FromString(raw_example.numpy())\n",
    "\n",
    "parsed.features.feature['image/text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-31T10:16:35.699952Z",
     "start_time": "2021-07-31T10:16:35.696683Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "google.protobuf.pyext._message.MessageMapContainer"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(parsed.features.feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T09:03:13.538259Z",
     "start_time": "2021-08-01T09:03:13.534551Z"
    }
   },
   "outputs": [],
   "source": [
    "filenames = [[\"/var/data/file1.txt\", \"/var/data/file2.txt\",\n",
    "             \"/var/data/file3.txt\", \"/var/data/file4.txt\"],\n",
    "             [\"/var/data/file1.txt\", \"/var/data/file2.txt\",\n",
    "             \"/var/data/file3.txt\", \"/var/data/file4.txt\"],\n",
    "             [\"/var/data/file1.txt\", \"/var/data/file2.txt\",\n",
    "             \"/var/data/file3.txt\", \"/var/data/file4.txt\"],\n",
    "             [\"/var/data/file1.txt\", \"/var/data/file2.txt\",\n",
    "             \"/var/data/file3.txt\", \"/var/data/file4.txt\"]\n",
    "            ]\n",
    "dataset = tf.data.Dataset.from_tensor_slices(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T09:03:14.135293Z",
     "start_time": "2021-08-01T09:03:14.132084Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset shapes: (4,), types: tf.string>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T09:03:14.574465Z",
     "start_time": "2021-08-01T09:03:14.567952Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[b'/var/data/file1.txt' b'/var/data/file2.txt' b'/var/data/file3.txt'\n",
      " b'/var/data/file4.txt'], shape=(4,), dtype=string)\n",
      "tf.Tensor(\n",
      "[b'/var/data/file1.txt' b'/var/data/file2.txt' b'/var/data/file3.txt'\n",
      " b'/var/data/file4.txt'], shape=(4,), dtype=string)\n",
      "tf.Tensor(\n",
      "[b'/var/data/file1.txt' b'/var/data/file2.txt' b'/var/data/file3.txt'\n",
      " b'/var/data/file4.txt'], shape=(4,), dtype=string)\n",
      "tf.Tensor(\n",
      "[b'/var/data/file1.txt' b'/var/data/file2.txt' b'/var/data/file3.txt'\n",
      " b'/var/data/file4.txt'], shape=(4,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "for i in dataset:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### example of reading and writing a picture to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-02T03:00:28.112773Z",
     "start_time": "2021-08-02T03:00:26.553825Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/download.tensorflow.org/example_images/320px-Felis_catus-cat_on_snow.jpg\n",
      "24576/17858 [=========================================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/download.tensorflow.org/example_images/194px-New_East_River_Bridge_from_Brooklyn_det.4a09796u.jpg\n",
      "16384/15477 [===============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# get file\n",
    "cat_in_snow  = tf.keras.utils.get_file('320px-Felis_catus-cat_on_snow.jpg', 'https://storage.googleapis.com/download.tensorflow.org/example_images/320px-Felis_catus-cat_on_snow.jpg')\n",
    "williamsburg_bridge = tf.keras.utils.get_file('194px-New_East_River_Bridge_from_Brooklyn_det.4a09796u.jpg','https://storage.googleapis.com/download.tensorflow.org/example_images/194px-New_East_River_Bridge_from_Brooklyn_det.4a09796u.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-02T03:01:17.604790Z",
     "start_time": "2021-08-02T03:01:17.602399Z"
    }
   },
   "outputs": [],
   "source": [
    "import IPython.display as display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-02T03:01:57.568004Z",
     "start_time": "2021-08-02T03:01:57.562861Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/jpeg": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Image cc-by: &lt;a \"href=https://commons.wikimedia.org/wiki/File:Felis_catus-cat_on_snow.jpg\"&gt;Von.grzanka&lt;/a&gt;"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display.display(display.Image(filename=cat_in_snow))\n",
    "display.display(display.HTML('Image cc-by: &lt;a \"href=https://commons.wikimedia.org/wiki/File:Felis_catus-cat_on_snow.jpg\"&gt;Von.grzanka&lt;/a&gt;'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-02T03:02:34.412338Z",
     "start_time": "2021-08-02T03:02:34.409350Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jovyan/.keras/datasets/320px-Felis_catus-cat_on_snow.jpg'"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_in_snow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-02T03:07:10.319612Z",
     "start_time": "2021-08-02T03:07:10.314335Z"
    }
   },
   "outputs": [],
   "source": [
    "# ready to write images to a file with tfrecord format\n",
    "\n",
    "# The following functions can be used to convert a value to a type compatible\n",
    "# with tf.Example.\n",
    "\n",
    "def _bytes_feature(value):\n",
    "  \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "  if isinstance(value, type(tf.constant(0))):\n",
    "    value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
    "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _float_feature(value):\n",
    "  \"\"\"Returns a float_list from a float / double.\"\"\"\n",
    "  return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "  \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-02T03:08:43.677750Z",
     "start_time": "2021-08-02T03:08:43.670356Z"
    }
   },
   "outputs": [],
   "source": [
    "# write image to tfrecord\n",
    "image_string = open(cat_in_snow, 'rb').read()\n",
    "label = 1\n",
    "\n",
    "def image_example(image_string, label):\n",
    "  image_shape = tf.image.decode_jpeg(image_string).shape\n",
    "  feature = {\n",
    "      'height': _int64_feature(image_shape[0]),\n",
    "      'width': _int64_feature(image_shape[1]),\n",
    "      'depth': _int64_feature(image_shape[2]),\n",
    "      'label': _int64_feature(label),\n",
    "      'image_raw': _bytes_feature(image_string),\n",
    "  }\n",
    "  return tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "\n",
    "ie = image_example(image_string,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-02T03:09:04.783245Z",
     "start_time": "2021-08-02T03:09:04.779024Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "feature {\n",
       "  key: \"depth\"\n",
       "  value {\n",
       "    int64_list {\n",
       "      value: 3\n",
       "    }\n",
       "  }\n",
       "}\n",
       "feature {\n",
       "  key: \"height\"\n",
       "  value {\n",
       "    int64_list {\n",
       "      value: 213\n",
       "    }\n",
       "  }\n",
       "}\n",
       "feature {\n",
       "  key: \"image_raw\"\n",
       "  value {\n",
       "    bytes_list {\n",
       "      value: \"\\377\\330\\377\\340\\000\\020JFIF\\000\\001\\001\\001\\000H\\000H\\000\\000\\377\\333\\000C\\000\\006\\004\\005\\006\\005\\004\\006\\006\\005\\006\\007\\007\\006\\010\\n\\020\\n\\n\\t\\t\\n\\024\\016\\017\\014\\020\\027\\024\\030\\030\\027\\024\\026\\026\\032\\035%\\037\\032\\033#\\034\\026\\026 , #&\\')*)\\031\\037-0-(0%()(\\377\\333\\000C\\001\\007\\007\\007\\n\\010\\n\\023\\n\\n\\023(\\032\\026\\032((((((((((((((((((((((((((((((((((((((((((((((((((\\377\\300\\000\\021\\010\\000\\325\\001@\\003\\001\\021\\000\\002\\021\\001\\003\\021\\001\\377\\304\\000\\034\\000\\000\\002\\002\\003\\001\\001\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\003\\004\\002\\005\\001\\006\\007\\010\\000\\377\\304\\000?\\020\\000\\002\\001\\003\\003\\002\\005\\001\\005\\006\\005\\002\\006\\003\\000\\000\\001\\002\\003\\000\\004\\021\\005\\022!1A\\006\\023\\\"Qaq\\007\\0242\\201\\221\\010#B\\241\\261\\360\\025R\\301\\321\\361b\\341\\026$3Cr\\2024S\\262\\377\\304\\000\\032\\001\\000\\003\\001\\001\\001\\001\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\001\\002\\003\\004\\005\\006\\377\\304\\000\\'\\021\\000\\002\\002\\002\\002\\002\\002\\003\\001\\001\\000\\003\\000\\000\\000\\000\\000\\001\\002\\021!1\\003\\022AQ\\004a\\023\\\"2q#3\\201\\261\\377\\332\\000\\014\\003\\001\\000\\002\\021\\003\\021\\000?\\000\\355,\\270\\351]G9\\025M\\306\\200\\010\\000QH`\\346\\220t\\246\\220\\230\\262\\372\\232\\230\\211\\343\\'\\024\\000h\\227\\035)\\r\\014\\007\\n9\\245C\\027\\232\\347\\004\\201M!6W\\313)f\\253H\\213>\\013\\273\\2550\\010\\221w\\251\\261\\320U\\210\\036\\264\\254tg\\035\\205\\000\\025\\027\\002\\220\\004\\010\\177*,t\\0228\\200\\346\\223cH3\\220\\027\\035\\351\\014\\200 \\034\\236h\\021\\t\\\\\\221\\354=\\250H\\030\\214\\210\\255\\317AVK\\021\\271\\375\\331\\312w\\253Y%\\340\\024\\021\\357r\\317M\\261$5\\002\\341\\210^\\225,\\244?\\016\\024f\\241\\224\\203\\226\\334\\265%l\\257\\231\\331d\\370\\255\\022!\\230\\004\\267&\\201\\004Q\\221\\355Hd\\\\\\205\\030\\316M\\000S_\\241\\221\\370\\025\\254L\\332\\'g\\016\\016$\\024\\244\\306\\220\\324\\266\\321\\236\\202\\2451\\365*\\256\\241\\n\\306\\264L\\206\\204\\202\\203(\\252\\022Ad\\220\\250\\300\\242\\200\\214Cs\\214\\322c6[1\\373\\265\\n:VR5C\\033\\275Dg\\245H\\304\\265IW\\312\\300\\353W\\005\\2239\\262\\354\\200:\\326F\\304\\013\\0054\\010\\204\\217\\3051\\nI\\311\\252B\\t\\022\\340\\322`\\202\\220)\\014\\370>\\007Z\\000\\004\\223\\021\\220\\rU\\n\\305\\330\\226\\346\\230\\214\\244t6\\001\\322?\\214R\\261\\320tN:T\\214\\316\\312\\000\\211\\030a\\212b\\030\\215:f\\245\\262\\220\\306\\320\\026\\220\\301\\023\\203@\\031 \\260\\342\\200$\\027\\003\\232\\000\\004\\344\\016\\264\\320\\231]3\\022}5h\\206\\rT?\\342\\344\\323\\n&\\321\\002\\234R\\260\\242)\\2258\\246\\301\\016G\\302\\363\\326\\244\\242\\001\\310n\\274P\\000.$\\006\\251\\\"Y(\\2108\\315&4Jc\\216\\027\\212\\020\\330\\253\\253\\034\\220j\\221\\0007e\\260i\\200\\315\\262\\207$\\021R\\306\\206\\304ca\\036\\3256U\\024\\232\\222\\035\\344\\001Z\\300\\312E$\\342D\\233 \\032\\262S\\'\\234\\214\\232aa\\255\\206\\346\\030\\251cF\\311k H@\\357X\\264j\\211J@\\365\\003\\311\\244\\201\\210^Y\\3159\\312\\251\\301\\025jI\\020\\342\\331\\2601\\346\\2625\\005#`S\\006\\005\\230\\232b>\\013\\232\\004\\024\\020\\242\\220\\301\\264\\202\\235\\000\\006r\\335)\\210\\300B\\324X\\250CY\\325b\\322\\345\\266\\200\\304f\\236pYP8L(\\3439?<b\\262\\344\\345P\\3735\\207\\037b\\313M\\271\\206\\366\\001,\\r\\307FV\\352\\247\\330\\321\\016H\\362+B\\224\\034\\0351\\355\\253\\356*\\254TKr(\\374B\\200\\\"f\\213\\037\\210P\\000\\036\\352 p\\r<\\206\\204o|Icc\\'\\227!\\221\\334~1\\032\\202\\023\\352I\\037\\240\\311\\254y9\\241\\306\\352O&\\260\\342\\224\\225\\242\\303\\357\\352T\\020w\\0022\\010\\356+Z3\\\"oT\\236\\224P\\006K\\306\\340*\\322\\0316\\225\\344>\\201\\322\\200\\023\\231\\235\\233\\025H\\226}\\034\\'\\275\\026\\024\\021`\\002\\225\\215#>Z/,x\\243 \\001\\344\\215Ni\\323\\014\\0307\\036\\223\\264\\022\\007\\260\\242\\202\\321(\\242\\236q\\220\\230\\007\\336\\213\\241U\\223{#\\030%\\316i\\366\\261u#e\\017\\234\\341;\\223C`\\221~\\232\\n\\264|\\365\\254\\273\\227\\324\\207\\376\\034\\335\\237V\\005\\037\\220]\\000I\\341l\\034\\253\\237\\326\\232\\346\\027\\343\\026}!\\3552Kf\\253\\275\\207Z3\\035\\233\\270\\312\\203\\212,t\\002\\347F\\221\\324\\310\\017?4\\327%\\022\\340k\\367vL\\t\\014\\000\\\"\\266S3q\\020\\216\\334\\264\\301\\000\\3175NX\\022\\216M\\236-*8\\342C\\267\\325\\212\\301\\315\\233tH*Y\\347\\322\\243\\024\\254(z\\333JH\\360\\316K\\037\\232\\227!\\2446\\0225S\\200\\005!\\2259\\311\\353VI\\007\\300\\352h\\006\\017*;\\323\\025\\0213\\001\\322\\200 \\222\\211\\033\\232L\\021\\364\\312\\002\\345\\0174&6\\205[\\317#\\3229\\252\\262hb!\\\"\\257\\253\\255\\\"\\221\\243x\\301\\330x\\221%\\230\\376\\352\\030\\321\\177\\026\\002\\203\\236s\\\\|\\257\\376\\225\\364t\\301\\177\\316\\327\\260\\272~\\245%\\205\\334\\217\\036%\\211\\206N\\3269\\332\\007\\'\\24628\\357\\315d\\356\\017\\264vR\\251.\\2626h/\\205\\324),2\\226F\\031\\006\\273\\370\\247\\036X\\366\\211\\3138\\270>\\254.\\347\\177\\342&\\264\\244E\\262A8\\3474\\200\\247\\325\\265E\\201\\276\\355fC\\334\\267V^B\\017\\177\\357\\247\\326\\271\\276G\\310\\351\\372C\\372\\377\\000\\341\\277\\017\\017o\\332Z(\\257\\343_\\360IK&fb0\\t\\344g\\276:\\342\\270\\253\\026\\316\\244\\377\\000b\\377\\000\\303\\237x\\270\\321lKg\\002=\\271?\\007\\037\\351^\\217\\306w\\304\\254\\343\\371\\n\\271ZE\\364\\021\\204$\\023\\270\\326\\254\\3111\\250\\\\\\002\\024\\216MKE&Z[F\\2123\\236MC(\\214\\226\\241\\211+E\\205\\n\\270\\330H\\352j\\205DN\\343\\320\\034\\373P\\000g\\265\\232O\\201M4\\204\\321Xm\\246\\232\\350F\\237\\204\\036Mii+#6m\\032m\\214B-\\205r{\\223XJF\\251\\r\\274i\\022q\\320R\\273\\031]s\\033N\\001\\\\\\342\\251:%\\2531\\246\\333\\230\\257\\320\\036\\224\\344\\355\\004VM\\3210Tb\\271\\331\\2512\\005!\\221lP\\005&\\255\\033H\\340/J\\322&l\\206~\\357l\\t\\035\\005=\\261\\350\\246\\276\\324\\333\\004\\'\\025\\254`e)\\032\\315\\354\\355#\\234\\234\\346\\266Q\\243;\\263:r\\003r\\247\\330\\322\\226\\212\\216\\315\\342\\030D\\261\\250\\035q\\\\\\315\\321\\265\\n\\272\\210e\\347\\003\\024\\300h\\312<\\274\\216\\224\\250\\n\\273\\353\\344\\210`r\\337\\025j-\\222\\344\\221Y\\206\\377\\0005:\\002\\005[<\\261\\240,\\306\\321\\236\\244\\323\\021\\366\\320?\\204\\232,D\\302\\023\\333\\024\\254(\\220LP2\\\\P\\007\\307\\216M\\000i\\2764\\267[\\233\\357*2\\014\\215j\\036El\\000\\312\\034\\250\\301?\\304\\017j\\342\\371MG\\222-\\372;>?\\355\\306\\321\\250\\303|_O\\204,\\314]_j+\\266X\\363\\214p9\\317Ls\\355Q6\\t\\024\\037\\342\\227\\360\\351\\363ZEq\\3671\\035\\321d\\232)\\n\\252\\246\\342\\031y\\353\\364\\354q\\\\\\312R\\343}\\240\\315iMSF\\270u\\377\\000\\023\\332\\265\\254\\226\\036&\\276\\232\\336l\\254,_$\\216\\300\\344`\\034\\0223\\360MuG\\236^^Le\\306\\213\\373Mw\\305z\\204\\211\\036\\267\\255\\315\\344,\\344J\\226j\\210\\346%\\301a\\271@9\\311\\nH\\3503\\365\\251\\344\\371\\222J\\2428\\360-\\263m\\320%I\\340\\271\\272\\211\\312\\241\\220\\005X\\307\\n\\200`\\016\\204~G\\025\\311\\307\\'y:\\245\\025I\\\"\\343T\\235\\232<,XuB\\301N\\000\\013\\324\\261\\307\\353\\201\\326\\264\\224\\325d\\\\|y7]*\\004\\266\\320\\264\\344\\211\\231\\223\\356\\310\\301\\230`\\266FrGl\\346\\275^\\005\\326\\t\\036g3\\3559?\\2636\\362\\2178\\356?\\235l\\326\\014\\226\\302+\\027\\270\\036_ u4\\274\\007\\222\\342\\000\\\\\\212\\206h\\213(#\\302\\020\\335\\352\\031H\\210\\263]\\344\\221\\223E\\212\\211\\210\\023xP\\006h\\261\\321\\033\\364\\t\\031U\\374X\\242,L\\255\\262\\214\\\"1#\\324MSbH\\260\\205\\304\\026\\354\\304\\362j^G\\242\\255n\\332{\\275\\231\\364U\\325\\\"n\\331s\\204\\021\\355A\\223PY+;<J%\\223\\257\\265\\'/\\000\\221y\\017N+6Z\\013\\234u\\2442\\022\\021\\260\\320\\005L\\304\\344\\226\\253D\\013_\\2172\\334\\201W\\0341KF\\241v\\033\\314*A\\025\\320\\231\\203Ed\\310w\\020kD\\3111n\\3469\\005L\\212\\211\\271\\350W\\241\\220d\\364\\256i\\243x\\260z\\272M+\\231!\\\\\\255\\021\\300\\244\\\"\\367\\322-\\271\\210\\251\\017V\\243d\\266!\\\"\\205Q$\\215\\226\\255\\021\\r\\014C\\024\\227\\004\\224\\034Vm\\321h\\222\\330\\312\\315\\202h\\260h\\265\\265\\322\\225T\\026\\344\\3249\\025C\\006\\316$\\352\\242\\225\\201Q~\\300I\\2620*\\322%\\272%i\\017\\377\\000\\262\\206\\010a-Q\\344\\317jC%s\\004j\\230\\003\\232C4?\\265Fm+\\302\\362^*)_\\301\\270\\256J\\223\\2229\\375k\\227\\345\\361\\271\\365~\\216\\237\\213\\310\\270\\3338\\216\\215q\\017\\335\\005\\334\\266\\376d\\322\\026\\001\\317\\001S\\270\\0318\\'<\\201\\305D\\265A~K\\233\\200\\232\\214S\\231\\0222\\004F\\t|\\306c\\352 \\225\\003\\216\\247\\030\\343\\222W>\\365\\204\\221\\244^J\\335&\\336]?P\\320\\364\\323\\032\\'\\335\\344{\\031\\220\\037\\335\\t\\320\\357\\3347t\\014\\215\\223\\234\\362\\276\\304TI\\335\\262\\222\\322.<?o\\036\\373\\355A-\\021\\022\\372\\341\\356\\355\\374\\303\\312D\\352\\010c\\236\\214y8\\035\\210\\254\\336\\177\\364i\\376\\033\\206\\234\\320\\315i\\025\\245\\315\\273-\\2437\\230R\\006\\333\\220zp?\\027\\267\\345P\\2352\\264\\260k\\263M$Z\\371\\323\\241o[JWf1\\225\\'\\203\\3601\\323\\332\\255\\256\\310\\323\\362t\\312;5\\374\\213\\014q\\302\\237\\373h\\023\\256z\\014W\\275\\307\\032I3\\303\\234\\255\\225@\\273I\\205\\'&\\2662/\\254`\\021D7\\016Mc\\'f\\261T[Z \\353P\\312C\\305\\200^\\265%\\030\\232\\345!\\204\\226#4\\000\\226\\233z\\222\\3347\\230\\330#\\2459!&XN\\242l\\355\\365RCd\\037O\\013\\026\\345\\353G`\\242\\232\\350\\310ABH\\025h\\226\\002\\3156L\\030\\216)\\267`\\221\\261\\333M\\016\\001\\030\\254\\235\\226\\2509\\224\\037Rv\\2441\\273)\\325\\3063\\315KCC2\\266\\0004\\206\\310;zy<P\\\"\\247Q\\231U\\225W\\361V\\221D\\262(\\245\\300\\317<S`!\\250Y\\304y\\340\\032\\250\\311\\222\\342\\215gP\\2065c\\206\\034V\\361\\221\\224\\221T\\010\\334s\\322\\255\\222\\213\\275\\t\\035\\361\\311\\013YN\\215`m\\350?t\\020\\216+\\006hW_Y#\\202B\\376uI\\222\\321\\254\\337\\3338\\r\\206\\317\\260\\255\\342\\354\\306I\\227\\272n\\321l\\252\\275qX\\313f\\261\\321e\\0149\\301\\305Kc\\241\\360\\270\\210\\340T\\331Bs\\214\\2414\\320\\215u\\310\\373\\321-\\320V\\253Foc\\261\\r\\343\\323\\322\\245\\224\\231ci\\017\\247\\232\\226\\306\\205n\\2273\\005\\307zh\\031\\316\\276\\336\\346d\\360Lp)>T\\267q\\254\\330#\\005@\\'i\\357\\202B\\364\\254\\371_\\352_\\032\\311\\303\\254\\256b\\267\\264\\216\\352ft\\267\\215v\\314`]\\356\\2708U\\000t>\\337Z\\345n\\360\\315\\222\\362m63\\351\\227B\\r\\\"u\\324\\254\\247[\\330n\\207\\336\\342\\t\\0332\\222\\004{\\224\\235\\245\\217\\003=H\\307^\\234\\352\\337\\362j\\351,\\371#\\251h\\360k\\372\\224wn\\205U\\345\\225\\256b$\\214\\3461\\031\\335\\216\\230\\003\\257Z\\316M\\301\\264\\315\\025IZ6\\317\\021\\351\\353o\\367\\013\\200\\336\\\\\\017`\\366\\361@\\261\\031\\031\\362\\312\\003*\\016J\\250\\004\\014\\340g\\025\\222\\344Q\\314\\212\\352\\336\\021_\\245\\311\\022+Z\\301%\\312\\335[\\310\\253=\\235\\304-\\013\\205\\177\\302\\3000\\345Olw\\244\\3745\\246R\\315\\231\\325\\320\\256\\2513mCul\\177s \\345\\324\\014\\266>A$\\360jc\\310\\342\\321N\\t\\243y\\322\\365\\025\\325\\354\\341\\272\\215\\201\\363\\024\\026\\301\\034\\036\\377\\000\\316\\276\\232\\023RV\\217\\016qqt]\\351\\326Y\\235Y\\201\\002\\234\\247\\201F%\\255\\353\\305m\\030vu\\nzs\\326\\262\\263Z+d\\361V\\225e\\034\\255w\\250ZC\\034X\\334\\322J\\000\\035\\35164\\231\\317\\374G\\366\\365\\341\\373\\\"\\321h\\261\\\\j\\367#\\200#\\033#\\037%\\217o\\240<T9\\244R\\203f\\235\\253}\\276^\\311\\377\\000\\341\\350{\\320\\034\\t\\032C\\207=\\310\\003\\240\\316x\\353K\\362\\217\\361\\224K\\366\\351\\256\\254\\333\\277\\301\\355\\004`r\\004\\215\\223\\236\\337_~(\\374\\254:#a\\320\\277ik\\2336\\003Q\\360\\332\\315\\037\\361<7$\\037\\240\\005\\177\\236hs\\260QGD\\260\\375\\244<\\017w\\032\\245\\340\\325,d*\\013\\027\\265\\336\\200\\236\\300\\203\\237\\314\\201I1\\365F\\371\\240\\353:?\\210\\340[\\255\\036\\366\\013\\313g<<N\\017?N\\265\\245\\340\\207\\032,\\306\\234\\255!\\301\\364\\322\\261Q9,\\242\\267M\\345\\260(V\\302\\250\\214\\023\\253HD\\177\\207\\035i\\270\\202a\\354e\\0171\\t\\305&\\206\\231m\\\"\\201\\037^j\\n\\004\\300\\224\\'4\\301\\224\\273\\032K\\303\\232\\323H\\217#\\356R\\010\\211$g\\025;\\033\\301\\247j\\26772L\\333w\\005\\256\\210EQ\\204\\244\\315z\\356V\\334C\\022\\017\\315n\\242\\214\\354\\205\\204O4\\207\\251QR\\360Trn\\232\\r\\276\\322\\243\\336\\260\\2337\\21269#\\330\\001\\366\\254l\\260\\027\\004\\030\\216\\0054&k^O\\237t\\373\\370T\\255n\\221\\235X-.\\343l\\330=(\\222\\024Y\\262E2\\261\\001k*4\\262\\305W\\323\\317J\\221\\225\\367\\274\\002\\007J\\244&k\\323@\\306bH\\342\\264O\\006md\\262\\265\\217dC5-\\224\\220\\355\\254\\352\\006;\\324\\264Rg\\327\\261\\000\\236e\\t\\2039\\177\\332\\235\\274\\232\\257\\206/\\242\\206@\\222\\240\\022\\306H\\312\\356S\\236G\\265T\\343pb\\204\\252G\\034\\360\\375\\265\\236\\217\\005\\306\\235\\253D\\322i\\272\\224F\\t\\356\\021\\200drC\\007S\\331\\201\\nF\\177\\313\\371W\\233\\310\\233\\312\\331\\331\\006\\274\\203\\361\\366\\235\\253\\r*\\013\\366\\325\\264[\\250L\\350\\255qj\\222,\\3636Cnd#j\\221\\216pH\\311\\342\\262\\340P\\214\\235]\\227\\311\\332I^\\215\\303\\3037\\026\\367s^]\\220R)\\256\\032Gbx\\311<\\257\\344z\\366\\254\\376O*\\354i\\303\\306\\350gYMkY\\361\\227\\210\\256\\255--\\257\\264]\\220X\\2542\\335\\255\\273\\306!\\007i\\214\\277\\244\\202\\314\\344\\256G,\\rc\\'\\016H\\245t\\321n.\\037i\\207\\232\\322K\\313K\\337\\361\\370\\242\\232\\357Sx\\221!\\206}\\351o\\034`\\355Q  \\274\\214Y\\213\\021\\351\\340\\014\\322iF*)\\330E\\276\\327\\241Y\\3743\\177\\241\\351n\\006\\244\\251\\246\\004i\\324;\\0234}w&\\377\\000\\362\\374\\3434\\357\\263M\\241\\345`\\342:\\177\\214\\365=7V{\\315:}\\261D\\010\\212)\\016S?\\346\\307\\275z\\260n\\t#\\212iI\\266^O\\366\\231\\343\\013\\310\\000}D\\306\\247\\007)\\030U\\035\\272\\373u\\246\\371_\\261(*\\321S\\250\\353z\\326\\240\\253q}\\250\\336M\\274c\\231HUO\\240\\340\\036\\237\\312\\247\\3626\\3667\\004j\\267\\277\\277\\230+9\\220\\261\\306\\347bI$\\365\\377\\000\\275h\\231\\235\\0261\\021\\004\\006\\326 C\\020N\\340O\\037?\\337\\275d\\362\\354\\321`-\\314\\271X\\241M\\301\\200\\300\\013\\324\\016\\377\\000\\326\\232@\\337\\241i\\342[I\\002\\236v\\214\\267\\253$\\037l\\323\\273\\026\\206\\014Q\\274;\\244\\001\\027\\034\\014\\362jm\\242\\2511!b\\276Iq\\224\\\\\\365c\\311\\025}\\310\\3505\\243\\335j\\376\\032\\277]GC\\274\\270\\263\\272N\\217\\0362F9\\312\\234\\202>\\242\\232\\344L\\034$\\216\\365\\366Q\\373A[\\\"\\213?\\036Mr\\223\\036\\026\\373f\\344$\\377\\000\\230(\\310\\03785\\257b)3\\272\\275\\364Z\\315\\224Wv\\0271Og&\\031$\\215\\262\\256>\\017z\\3264\\214\\244\\237\\221\\305)\\367m\\260\\214694\\274\\207\\200iq\\367`\\2419n\\364\\352\\303E\\210\\274a\\026\\351\\017\\345S\\324\\2533\\035\\347\\232\\247o4u\\013\\027\\232S\\030,\\027\\232i\\022V\\315+\\35423\\223\\361W@\\301+\\tx#\\325\\364\\247\\241l\\245\\325tY\\234\\227\\204\\362{V\\221\\344\\366e.7\\340\\006\\217cy\\001q\\\"\\000\\271\\242rLpM\\033E\\224\\236I\\016x\\332:V/&\\251\\216\\256\\242eB1\\232\\236\\243\\261[\\215C\\313\\215\\213\\340\\n\\245\\033\\023tVi\\327^u\\311g\\030\\\\\\364\\253q\\244L]\\201\\373\\271P\\0353\\232,\\232-4\\271\\031@g\\316~j$\\212\\213.\\305\\342\\224\\301\\340\\326}M,\\004\\233d\\3478\\024\\364!y\\325|\\242\\000\\346\\250@\\013\\021o\\214z\\250\\021\\2351\\03092w4H\\021c\\251\\020m\\016=\\252\\026\\313z4;\\244Y7\\244\\203*\\331\\004\\021]5h\\303G(\\3617\\205\\346\\260\\275\\201\\r\\352C\\243H\\371\\330S\\007\\035v\\026\\372\\364\\310\\256\\016^.\\262\\372:\\341\\311\\331}\\211]xie\\324?\\303\\301\\270h\\234y\\221M&=9\\347\\247\\307\\034\\342\\263|t\\351\\025\\337\\026\\312\\r.}J\\301\\027\\303\\237q\\225u\\204\\230\\301\\344c\\016\\304\\214\\206\\301\\352\\247\\256\\354\\364\\256.o\\217|\\231=\\016.T\\270{\\331\\332m\\374\\037%\\225\\274:}\\344\\217%\\324\\221 \\231\\225K(\\220\\250\\033\\213|c\\036\\307\\025\\316\\270\\345\\007\\324R\\344S]\\200\\352\\372\\016\\245\\242\\\\\\307&\\231}g,\\241v\\277\\336ca\\275\\261\\311@\\271\\376C&\\256\\\\}H\\214\\323\\3324o\\265]x\\351\\232\\023\\253N\\247Q\\2363\\024k\\020*\\023=H\\317O\\317\\336\\253\\212\\027$\\023\\226\\016\\017\\014^}\\304\\021N\\025\\244o\\304\\371\\301?\\374\\276\\177\\237\\025\\334\\345\\206\\316e\\035#d\\324 U\\202\\030P\\220\\271U\\311\\0041\\377\\000\\216k\\236.\\335\\235\\022X\\003\\256F\\246\\335`\\207\\205\\300\\014A\\301\\000\\014\\376y\\030\\253\\343y\\\"k\\006\\252\\025B\\307#\\023\\235\\306F\\030\\374 q\\217\\223]G1d\\262\\261\\267\\014\\253\\265I\\034\\3678\\366\\377\\000\\265J\\216F\\330;\\\"\\\"\\230\\027\\031\\221\\206\\346?\\364\\373U1!\\303\\\"\\274\\036g\\226\\244\\260\\0001\\\\\\340\\003\\355\\357R\\220\\354\\034\\260\\306\\366\\342IL\\204\\021\\270\\236\\324\\274\\320\\374Y\\031%UU\\333\\030\\334\\010\\316\\007\\364\\245\\325\\262\\224\\222\\033\\200}\\352\\000\\305O=0\\244\\326m\\3654\\256\\310\\251\\324,\\225\\016\\3542\\221\\320\\343 \\376u\\254y,\\312\\\\tl\\237g\\337h:\\367\\202\\356\\207\\334\\256d\\222\\304\\267\\357\\254\\335\\201I\\007\\307\\034\\036\\235+U.\\272\\\"\\273a\\236\\277\\360W\\2134\\237\\024x}5\\035\\032\\345&\\000\\0014c!\\241|r\\254\\010\\343\\375kt\\324\\264e(\\270\\354~\\336O6g`sV\\325\\\"\\026C\\266\\371\\234\\003\\322\\220\\313\\213\\010\\225\\\" \\216qQ&R*\\356\\2573raA\\232\\264\\260M\\231[p\\370-\\372QaA\\241\\267\\001\\317\\024\\233\\000\\306 \\001\\315+\\035\\013\\303\\033>N8\\006\\235\\201\\233\\270T\\306q\\303b\\204\\304SE9\\204\\262\\177\\025]Y)\\211\\352\\227@\\306T\\237VzU\\3029&l\\026\\230\\305F\\363\\320ULQ6\\370\\354TF\\245\\205sv5\\242.\\212\\252v\\200\\000\\240\\004\\336R\\331\\003\\250\\252\\02187\\273\\014\\347\\024\\230\\017\\274XL\\322\\261\\200A\\271\\360q\\212`\\026B\\221\\256GZ@$\\363\\263d7\\341\\252\\240\\021KT\\232\\343%x\\025WH\\212\\266X\\317\\244\\333\\335Y\\2742\\306\\0326\\034\\251\\367\\355Y\\266ZG2\\325\\364\\223\\341\\353\\225\\202W-\\t\\'\\312pI`;\\222O\\311\\351\\361Y\\177&\\233\\022\\323\\264\\305:\\374\\032\\335\\276\\254\\303P\\202\\335\\255\\320H\\212G\\226[v\\017~\\2775\\234\\251\\344\\245f\\353\\026\\273\\025\\322fb\\217r\\237\\213`8\\343\\256\\t\\353\\357\\212\\347\\222\\215\\331\\252n\\250\\325|S\\342\\013}?\\315\\226gQu\\300\\216C\\312\\266\\356\\234{c\\333\\237\\322\\271f\\325\\235\\020N\\216\\025\\343{\\231u=P\\233\\363\\266PwJ\\204\\360\\240\\016\\010=\\306:U\\361\\343#\\2325\\313xe\\270\\277\\363\\\"\\214\\345\\216J\\343\\267c\\216\\365\\254\\235G&qV\\307\\257\\244Y\\002\\215\\373\\020L\\025I9\\007\\347\\363\\346\\263\\212.L\\016\\255/\\356\\256\\021O\\341\\034\\263s\\270\\236\\177\\276\\325\\254\\021\\234\\336\\n\\033\\333m\\266\\221\\250U%\\266\\252m>\\335Et&s\\264\\034)[\\253x\\200\\003j\\344\\340pi\\200\\013\\210\\212<\\322\\016\\000\\\\\\005\\351\\217\\367\\372\\320\\007\\314\\034A\\034a\\211f\\000\\261\\310$\\017l~\\2374\\010\\027\\337\\034\\211\\\"a\\225\\030\\n\\247\\371\\177?\\351Ey\\013,,QDr\\231\\316\\320\\247k0=Op>=\\361\\375*95\\203N5\\354\\275\\322\\341_\\271\\t\\245B\\211\\277h\\\\\\021\\307N\\277\\353\\375+\\222wgTj\\212\\375Q\\230\\\\4\\031\\004\\023\\223\\223\\337\\353ZA\\342\\310\\226pk\\367P,r\\260\\200\\204\\224d\\201\\236\\016{\\017\\177\\316\\267R\\366a(\\3726\\017\\004x\\236\\373D\\325V\\363M\\270\\373\\274\\330\\304\\213\\270\\205q\\307\\014:\\034\\366\\246\\233\\206PbJ\\231\\353\\277\\002j\\320k\\332LZ\\215\\244\\252\\361\\277\\016\\007T~\\352Go\\316\\273T\\324\\225\\243\\225\\305\\305\\321\\270\\244A#\\017\\216jlf.n\\274\\250\\331\\263\\216(H\\033\\242\\272\\312#\\3464\\217\\31379\\253~\\211Hp8\\004\\202y\\251\\030\\365\\272\\222\\231\\003\\232\\226R\\030x\\324/\\315+\\035\\025\\346O-\\231A\\364\\325\\023b\\3170\\223\\205<\\323\\240)\\'WI\\336F\\030\\000qZ\\255Q\\223)\\331Zi\\213\\036W5\\256\\221\\231qi\\010\\221\\006\\337\\302\\265\\224\\231\\252F\\330\\362\\2201\\332\\271\\315D\\344}\\300\\212\\262E\\242\\214\\231\\t\\305\\026!\\353`3\\201I\\214\\235\\314\\230\\302-\\t\\r\\213\\347i\\3151\\003b]\\276(\\002\\022\\216@\\240C6P\\r\\373\\217JM\\215!\\331\\247\\2161\\205\\352\\005JVU\\321\\251x\\306\\315\\357\\364\\271\\214q\\211&\\217\\367\\210\\277\\346\\307j%\\033\\215 \\213\\247\\223\\237\\351\\263\\306\\245\\2462\\251nwzq\\214\\016\\203\\343\\257\\353\\\\M\\373:\\n\\253\\377\\000\\021\\'\\370\\243\\333Z\\222\\003a\\003\\234\\024\\365\\014\\003\\362A\\307\\351\\217j\\344\\234\\255\\322:#\\014[5MN\\363\\357\\3234\\0238+f\\373\\223y\\335\\2726\\356~\\207\\037#q\\254\\3743U\\264i\\363\\313\\025\\344\\357+\\021\\345!\\362\\301c\\327\\003!A\\376u\\252N)\\\"\\033\\273`l\\340X\\330\\226_/\\316^I\\343*\\017\\037\\251\\350)\\312V\\tP)\\020y\\033\\013\\0171\\037v\\030\\343\\234\\366\\376\\372S[\\006U_\\313\\272Ec\\265\\231\\262\\0163\\236\\007_\\255t\\305Q\\315\\'`lB\\312-\\243`\\n\\250.21\\223\\305Y\\004\\343\\n$\\226c\\214\\261\\343\\214\\361\\216\\274\\177\\245\\000\\301C\\260\\305!a\\2703\\226PFs\\216\\237\\353\\361LB(\\300y\\205\\311\\303\\020\\240\\001\\223\\237e\\366\\377\\000zb\\t\\014A\\032H\\333o\\230\\300\\035\\334\\235\\240\\203\\333\\256\\3560>\\2646\\010\\260\\206\\332\\0331$s91\\306\\371r\\311\\3136yU\\031\\347\\370s\\317\\372\\326m\\331\\244p](\\312!m\\253\\205\\300\\3008E9\\300\\036\\374t\\372W<\\221\\274_\\2007\\021Ak\\t\\310\\315\\300\\354\\313\\273\\347\\007\\373\\367\\2429\\034\\231A\\251\\241y\\026}\\240\\355\\345\\024\\236\\030{\\216\\375s\\333\\337\\351[\\305\\342\\214d\\263b\\323Z\\305\\'\\2525\\221_\\034\\253\\034s\\327\\277=*\\223hM\\'\\224o\\337c>3\\223\\302\\376)\\202+\\231Bi\\367dE6\\356\\231\\354N{\\363\\326\\265\\343\\227VD\\227eL\\366@\\273W\\201@\\307#\\216kz0\\261+\\230\\314\\205O;A\\252N\\2043\\220\\233Tw\\244\\000\\246C\\033\\356\\367\\242\\300\\264\\264\\230,<\\365\\251h\\264\\310]\\334\\021\\026\\345?\\235\\t\\t\\262\\257\\314%I\\374Y\\357WD\\203\\267\\205\\226Fu\\347\\343\\332\\233`\\214j0\\371\\360\\025\\035h\\213\\246)+E%\\255\\254\\211!G\\007nz\\326\\256Fj,\\274\\266\\205R-\\253X\\267f\\251R\\036\\022\\023\\301\\251\\241\\202\\307\\3573LA\\207\\035)\\001\\220\\333O\\024\\001\\2068m\\306\\200\\006\\307q\\310\\346\\230\\031Q\\310\\240\\014\\316\\230\\003\\024\\223\\003+6\\027\\003\\212(\\010\\023\\222I\\246\\000\\345\\334\\330\\\\q@\\216S\\343\\330-\\374=\\255D#\\221aK\\320^\\\"G\\n\\300\\372\\207\\320g5\\311\\317\\004\\262tq6\\315\\002]V\\312I\\225RH\\331\\222@\\376\\216\\000\\333\\311$\\376C\\347\\365\\257=\\3076v\\'\\2125\\273\\213\\231\\226\\307P\\272*<\\273\\222\\312\\0160@\\334\\010\\034t\\374?\\255\\021\\215\\262\\244\\351\\025Q\\301$\\266\\350\\0342\\305\\235\\354I\\310s\\362{w\\342\\255\\322d,\\242\\336[(cM\\357&eU\\312\\347\\221\\203\\323\\351\\364\\254\\323\\263G\\203[\\327\\014\\220\\207h\\230\\355b=>\\377\\000\\227\\265tq\\244\\331\\217$\\232E\\022I\\277s2\\253\\001\\234\\000>?\\257\\373WM\\034\\367e\\214{c\\232W\\300\\302C\\221\\221\\333\\277\\374\\324\\357\\003$ d\\264X\\307\\342\\307\\254\\367\\000\\363\\201\\363\\376\\324X\\210\\310\\241Y\\224\\005\\t\\020\\365\\347\\267\\035*\\220\\205%\\001m\\326F\\210o?\\372i\\306\\000\\372{\\323\\n\\030\\232\\017\\272\\033{\\262\\321\\253B\\252\\333I\\307Q\\306~x\\351Sv4\\022\\325.o. \\004\\200\\210\\013\\340\\250!\\027=\\000\\351\\222?ZO\\010\\244lV\\026\\320\\275\\303\\312\\\\\\250RY\\025\\262\\003c\\003\\034\\221\\327\\363\\300\\307\\034\\340s\\312\\331\\274i\\025\\227\\221\\213\\351RC$i\\000!\\213\\261\\031\\3167\\021\\214\\343=\\261\\327\\200\\005TUl\\231;amb\\373\\302\\306\\320Eo\\024Y#\\221\\301RI\\353\\216\\301\\260\\030v52\\225\\025\\030\\331U48\\235we\\266\\005G\\357\\214\\223\\301\\307\\26695JV\\202\\251\\213$qy\\221\\211\\2402E o\\335G(F\\016A\\000d\\202:\\340\\343\\034\\2168\\316kX\\2639#\\323\\277`>\\\"\\237\\\\\\360\\334v\\032\\205\\321\\232\\357N\\304l\\322\\037[\\'\\360\\223\\357\\216\\231\\256\\276)\\366\\211\\315\\311\\032vvc\\014m\\017\\000|S\\262h\\252\\324<\\310\\246\\213j\\223\\236\\005Z%\\215\\266\\022\\023$\\374`R\\006k\\346\\356\\346\\352\\353lGd9\\353\\361ZR\\212!6\\331r\\367(`\\373\\264~\\243\\374F\\242\\263f\\227\\340\\025\\302\\030\\342P\\276\\221\\336\\204!\\2159\\014\\303\\021\\216=\\350\\226\\006\\262\\031\\255\\030\\312Ct\\0256\\024a\\255\\221\\001\\33494X\\0001\\010\\324\\262\\236\\224\\304B%=Z\\200\\r\\264\\260\\310\\342\\200&\\035\\021\\016\\352@&\\367\\037\\275\\370\\252\\241Y&f\\224\\341z{\\322\\030UC\\032\\375h\\000\\221\\225\\003\\236\\264\\001\\364\\216\\030\\020\\0074\\250\\000$L\\315\\226<{S\\020s\\n\\343\\256)\\014R[\\202%\\362\\200\\316;\\325P\\257\\301\\314\\276\\327,V\\377\\000\\\\\\261\\212\\3413\\017\\335\\310V\\317B[\\232\\347\\345Vk\\007H\\347r\\370SL\\201\\010\\200\\313\\014rd\\022\\244\\227n\\tc\\374\\200\\372\\232\\363\\371\\035l\\354\\206tk\\336%*\\302\\r>%\\362\\366\\r\\244\\347\\240\\317\\342?\\312\\210c#z\\242\\272\\331L\\262-\\242\\206G\\335\\200[\\270\\003\\236\\237\\031\\375iK\\013\\260\\343\\234\\023\\325\\035d\\267\\005AC\\010\\301\\344\\343\\217q\\333\\212\\2365\\222\\246\\351\\032\\265\\335\\330}\\342C\\301l\\014\\377\\000C\\307\\367\\315vF4r\\312VWY\\270\\373\\314\\312\\255\\205e\\'\\201\\324w\\310\\376\\372V\\214\\204\\\\\\332F\\246<\\3120YP\\020\\016\\356\\247\\223\\365\\250(r\\350\\2370\\252\\344\\225\\301\\334:q\\300\\007\\3374\\2200\\0271\\002\\253nB\\256\\007\\231)\\007\\206#\\266\\177\\277\\212v!O4\\254\\371\\221Wt\\217\\2718\\3161\\336\\230\\ri\\261}\\356\\317u\\312\\205\\2108*\\2079 d\\205\\007\\277N\\237LT\\266R\\017\\252F\\306\\314\\306\\\"\\303\\014d\\2259|\\214\\214\\362{c\\277\\275\\010\\006\\240T\\0267\\266k$\\223L\\321\\251\\217\\016\\034\\214\\225\\003\\216\\271# {T4Z`\\'\\333\\367\\013m\\207\\3671\\023\\220\\027\\033\\244\\034\\220\\0169\\007\\333\\340\\366\\305=\\005\\333,~\\3635\\235\\2232I\\\"\\372\\204j\\2507\\230\\324\\216NOl\\356?\\226\\005d\\325\\263D\\360-,A\\230\\262\\241.YR<.\\346\\221\\207B{\\340\\221\\3178\\344{R\\241\\330\\225\\345\\231\\010\\032\\033v\\007\\216\\013\\035\\340\\344\\340\\003\\362A\\353\\320\\n\\270\\343dK\\'A\\373\\006\\326\\r\\227\\211b\\267\\230\\037&\\345\\014\\003qR\\321\\2619\\034\\361\\221\\236\\017\\324WO\\004\\252U\\354\\313\\221\\\\l\\364\\362\\314\\366\\354\\253?\\244\\036\\200\\232\\352\\336\\216b\\312E\\023\\300\\214\\240nZ\\2351\\354\\024\\211\\025\\314\\016\\222t\\350h\\312`\\325\\232\\275\\352\\255\\264\\204D\\304(8\\305m\\027{2x-,\\032%\\204\\020=G\\271\\250n\\331\\242Cq\\371R\\332\\312%\\301~\\302\\225\\206\\321\\0339\\005\\274>\\243\\267\\035\\250y\\000\\337{\\0147)\\311\\245A`\\346\\270\\203\\310\\022O0\\037\\000\\323\\257@\\312\\345\\325\\222R\\320\\307\\003\\235\\335\\034\\2161E;\\017\\005\\212\\250Rwu\\024\\254@\\244\\234n\\332\\247\\024\\300Z\\342N\\200t\\246\\204\\310:\\206\\000\\221\\300\\243A\\261\\230\\031D}pi\\014\\231\\2202\\362h\\0019\\'h\\344 \\002E4\\211d~\\366\\331\\340\\037\\316\\212\\035\\230\\216\\362L\\373\\375(\\003\\351.d\\231\\266&A\\241*\\013\\260\\213o\\\"E\\346\\036I\\375hl*\\262k\\376/\\322d\\324\\254\\004\\352\\255\\347\\333z\\220\\374w\\376U2V\\212\\2139n\\243,\\226\\350$\\2160\\034zT\\236B\\257|\\223\\337\\034\\361\\361^w,\\035\\235|r9\\365\\304\\027.&\\274\\222Eap\\345\\303\\201\\200\\006\\354\\001\\216\\334\\n\\315c\\006\\2179$v\\303v\\036\\025m\\373O\\226\\017\\351\\376\\225/*\\212\\216\\035\\224\\227\\372\\234\\245A\\2258-\\205\\347\\337\\351[q\\361\\321\\224\\347e-\\354K\\367i\\014\\005\\214\\221\\214\\360s\\221\\361\\364\\255\\321\\211S\\246\\310\\277~P1\\345\\234\\256OA\\237zrX\\022\\331}\\007\\244\\313\\023a0\\001F<pN1\\375*<\\026\\307\\333pS33\\022X\\001\\200\\016O\\365\\343\\256h\\020\\265\\3017VR\\260P\\031\\330\\250v=@\\357\\372\\177Z4\\014\\304on\\307\\3579FQ\\'\\225\\033\\021\\235\\3308\\031\\037A\\237\\313\\024\\350,\\003\\265\\305\\327\\237\\r\\261\\333\\030!\\024\\354\\352\\177\\323\\270\\300\\242\\274\\205\\370\\037\\260\\270\\337\\035\\300\\363\\035]dX}X\\335 *q\\361\\214\\201\\317c\\212\\032\\310-\\031\\267\\213\\311\\226I\\225\\031g\\233\\312}\\243\\322\\004c;\\217L\\374g\\344\\367\\305&5\\222\\302\\326\\325\\r\\215\\345\\235\\276\\334\\301\\020u\\233\\323\\220\\240~\\020GNO\\3175\\214\\245y6\\212\\240\\245#\\236wG\\n\\311j\\200\\230\\3661\\022rN\\001\\352@\\033\\217@p\\r\\000\\nu\\271p\\222\\026db\\024\\244\\334\\2661\\2029\\355\\216\\230\\036\\347\\216\\246\\244\\241\\033\\330\\035\\354\\315\\305\\274\\263\\333O\\024\\230d\\332@\\3679\\355\\330\\036\\277Jq\\264\\353\\300\\2355c\\036\\032\\234\\307\\253}\\352K_\\273\\024\\307\\223 \\375\\340F\\004p:\\036G|\\234\\034{\\346\\255\\376\\265L\\224z\\343N\\326_T\\323\\354\\356n\\\"-# bOs\\216\\265\\350\\307*\\321\\305,0\\353{p\\322\\260/\\345\\250\\376\\021UH\\233aM\\333\\210\\202\\347h\\'\\363\\245C+.\\3403^\\253\\026;\\007Z\\244\\351Q-[\\262\\306Y\\321\\243\\021\\304\\270U\\035k5\\032v\\313n\\364\\n+\\301\\023m\\004\\346\\252\\254@o/\\241\\260Sw\\252\\\\\\307\\025\\247\\273\\266\\000\\244\\332H\\022\\311\\255?\\332_\\205\\274\\330\\321uX\\225em\\250\\2709o\\237\\201\\362i)\\242\\272\\262\\356\\305\\355\\365I|\\330.Q\\355\\227\\274m\\220kK\\306\\010\\352\\357%\\227\\231\\036BD2O\\002\\222@\\036\\345\\346\\316\\321\\370\\215B\\031\\233h\\230\\220%\\340\\367\\246\\300gQ\\222\\325B\\001\\200GZ\\230\\330\\335\\t\\371\\210S9\\312\\325\\010\\371\\347\\215\\323\\013\\324Q@/0\\223`e<{P\\001PJ#2I\\264(\\355@\\013\\301+]O\\261S\\nO-T\\343D\\251[\\033\\272\\215 \\\\DF{\\322Y+G\\326\\020\\220\\276l\\370\\333\\332\\206$\\031\\356\\320\\235\\250\\255\\267\\336\\225\\016\\310]\\356\\362=\\036\\242\\177\\204P\\201\\232\\'\\212|2\\327q=\\325\\262\\256\\360\\013<g\\243\\177~\\325\\237\\'\\032\\226\\212\\204\\350\\345\\336\\'Xm,\\'\\363\\237a#!BmU\\370\\0378\\342\\270g\\ngT%g<\\270\\325\\016RD\\211\\304\\321\\246\\325e\\004\\206\\305\\n\\003r\\306\\005VT\\324\\\"C+0\\235}j;\\344|\\376\\237\\312\\264\\2523\\273+\\'\\027\\366\\322\\264\\315\\016\\345v\\365\\n\\321Q\\005u\\260\\363/dp\\271\\215\\206q\\234w\\307\\345\\3157\\240F\\311\\247\\206\\222|\\243\\006\\214\\214\\251\\3328<rA\\355\\323\\371T\\024[M\\n\\371R\\211\\016\\021\\001Q\\264z\\271\\352\\007\\2714\\230\\025F\\t\\256\\257\\312\\027\\333\\034h\\027j\\203\\261A\\034\\214\\367n\\231\\354:\\374S\\272\\r\\213Jl\\340\\036lQOt\\3618\\033\\201\\000\\004\\366\\000q\\327\\2774\\223ltM\\356&\\212\\376\\331\\010\\215#BK\\261\\310\\'\\031 \\020:v\\317\\271\\037\\025v@G\\n\\322\\204\\221ZK6\\221$\\013\\363\\216\\347\\031\\311\\007\\246*u\\222\\213\\251c\\375\\350\\273@$1\\341I\\352\\273\\207\\251A\\'\\276p\\016=\\363\\364\\315\\272\\301\\242E\\230R\\367v\\241&\\205\\256.$Q\\3458 \\034\\222][<7 \\234\\203\\301=\\353\\035\\032 z\\233\\017\\361\\006\\201\\036@ep]\\211\\3320\\252\\334\\034pyld\\177:\\026\\203\\310{\\270\\002X*!ao\\010et\\354\\304\\017\\313#\\236\\335\\315\\010\\031J\\351*\\334\\003\\010T\\230l\\334\\001!x\\004t\\366*:\\217q\\315Z\\373\\023\\372+!\\271\\272\\264\\276\\022\\200\\217\\036xp76\\017PW\\257=sWI\\252%6\\231\\352O\\263\\215J\\337Q\\360\\225\\207\\335@\\312)\\014\\007\\276}\\273\\177\\336\\2738eq9\\371UH\\334R\\336(\\2112e\\230\\217\\302+KfX\\007\\005\\257\\357\\201\\270\\306\\316\\241;\\323\\277AF$\\215C\\354\\013\\311?\\240\\242\\300\\216\\240m\\354\\255\\214\\263\\310\\261\\250\\306I8\\370\\377\\000ZV:9\\007\\216\\376\\330\\364\\375#6\\232:-\\325\\314\\204\\205q\\215\\252\\240\\343?S\\203\\217\\326\\241\\317\\320\\324N9\\343o\\021k~(\\221g\\324\\357\\034@\\247)k\\036BD\\244\\366\\035\\317\\311\\254\\234\\255\\227\\326\\215:\\337w\\231\\313\\005\\035T\\236\\t\\366#\\342\\206\\306\\217Q\\376\\316\\326\\222\\'\\206n$\\273,#\\221\\301@A\\306>3\\307\\351[CB\\344\\364u6H\\303\\273\\304p\\253\\323\\353Vd\\026(\\344y\\236c\\225Q\\320\\232A\\266B4\\236\\342]\\312N\\334\\362M=\\013f$\\201\\256\\344\\332\\243\\320\\247\\226\\367\\241:\\007\\234\\0236.\\323yp\\202#\\037\\211\\217z;\\005xD$\\264\\335/\\227\\020\\351\\301n\\324v\\006\\275\\031\\275\\002\\001\\034\\013\\352~\\347\\332\\210\\273\\310<`\\232B$\\333\\036\\342O~i7Y\\n\\\"\\353\\0247q\\305\\031\\302\\177\\021\\377\\000J\\023\\265`\\361\\2045-\\262O $\\355\\200u>\\364\\256\\206\\325\\222f\\206f\\333\\274%\\272q\\365\\243+ M\\241\\212}\\276W\\246\\025\\356x\\315\\026\\302\\275\\004\\225#\\212-\\220\\002\\322\\023\\313{R\\261\\3208\\241\\200g8v\\357N\\330Q\\317\\274\\177\\340{o\\020\\332\\316\\312\\250&_\\341\\034dw\\306;\\326s\\202\\221Q\\227S\\211jZ$V\\021Mj\\260\\224h=%I\\344\\032\\343\\222qgDZh\\322n4\\370e\\272I\\243\\220\\001\\301u\\354G\\270\\253R\\300\\232\\'<\\353\\032:\\266\\334\\256:\\037\\216\\206\\232 \\243\\266\\362~\\373 \\211\\262\\216\\230\\\\\\377\\000\\013n\\351ZP\\213-#tn\\261\\23660PO\\362?\\337\\305K\\0327;\\253\\177/K\\017\\t;\\317\\034\\372\\260\\307\\277\\315)`\\026MD,\\227-:#\\210,\\343P\\245\\2622~\\006{\\223\\334\\322\\030\\314v\\351\\035\\201\\267\\263\\226E\\t\\270.\\321\\227\\344\\203\\201\\365\\037\\025-\\346\\312Z\\023\\272,\\245a\\221\\245\\225P0\\016\\354\\002\\216\\370\\3068=\\t=r}\\261M\\003\\034\\322\\034\\307\\026\\314\\242\\306\\350Y\\347bAU\\306N\\t\\350H\\343\\377\\000\\267\\305\\022\\313\\010\\242\\372;p\\261\\312\\267I\\'\\224$\\334#\\3132~\\034s\\217c\\206\\035\\371#\\214\\3262f\\221Cd\\274\\220\\020Q.Z?\\336\\303\\206%\\324\\340\\262)\\374\\211\\343\\266H\\254\\333\\243J($K\\273\\335Z\\342R\\361\\345\\301\\341\\271\\000\\364\\301\\307`\\000\\037L{\\326\\230Q%]\\233lp4\\232=\\244q\\312\\263\\314\\001V*=[\\300\\007q\\036\\331\\353\\377\\0004\\2557bj\\260k7\\352w^\\264\\312p\\250\\311\\017\\247\\322\\234\\234\\025S\\311\\030\\334q\\364\\317CV\\274\\023e\\006\\260\\226\\362$\\206\\332\\031CF\\331Y\\0200\\370 \\377\\000\\220\\236\\006\\017\\025\\244n\\311\\221\\325\\377\\000g\\237\\033Z\\333j\\247K\\271\\231\\374\\373\\254E\\027\\235\\220\\254\\335\\207\\260<\\340c\\256+^5\\326T\\364\\311\\223\\355\\033[G\\241\\226\\341\\355$r\\\"\\363es\\324\\364\\025\\323Vs\\335\\0260\\204Kw\\226@\\2571\\031\\374\\352\\033\\315\\025X\\263K\\361O\\216\\264O\\n\\254_~\\224K\\250O&\\301n\\207,\\270\\0319\\366\\354?1JO\\300$qo\\027\\370\\267Q\\361=\\375\\272\\316\\n\\332\\314\\215:C\\031\\302\\240\\310 \\234w\\000c\\347\\256+\\027+4Q\\255\\234\\207\\304\\0323\\331\\352\\nbm\\317\\264I*\\252\\220\\261\\347\\220\\240\\236O\\030\\347\\334\\342\\232x\\025P\\366\\237p\\227V\\346\\027fs\\234m+\\201\\237\\236\\377\\000\\231\\244\\312Y:\\177\\331\\237\\331)\\325\\246\\032\\206\\267+[ijw\\016\\346_\\200\\010\\353ZF\\027\\261I\\250\\236\\211\\3224K=2\\311V!\\025\\245\\212\\214\\\"\\003\\332\\265\\272\\3022y\\313\\t-\\232\\335\\035\\321I\\345\\333\\223\\205l\\365\\242\\305A$\\324w\\312\\020\\246\\330G\\'\\334\\323\\353\\344V\\032\\342\\3704\\037\\271\\0024\\351\\363IG\\330\\357\\320\\267\\337\\t@\\\"!\\000\\353\\356i\\320\\254j{\\2035\\240\\362\\345\\021\\373\\343\\255JY\\035\\332\\026\\036w\\222\\025\\010\\013\\357\\334\\325\\010]9,\\035\\200q\\324\\367\\246\\007\\316H*\\\"l\\023\\330P\\000\\257\\025\\206\\003\\235\\212\\007Z\\020\\230\\335\\245\\323y\\0016\\357A\\334\\322h\\023\\006\\250\\246\\3443\\215\\3318\\000t\\024\\374\\007\\223\\353\\306\\273\\027\\321\\307\\024\\200\\305\\214\\220\\242\\205T\\'v:\\367\\022\\230\\366\\250\\300\\350s\\326\\246\\213\\260-\\345\\205\\3659Op\\r1\\037B\\252Y\\210;Go\\232\\030\\034\\363\\355/\\303\\311%\\225\\326\\247\\006\\025\\243\\214\\231\\027\\034\\266;\\326<\\260\\354\\254\\322\\022\\247G\\223Z\\352\\340\\311\\\"\\254O\\344\\371\\205C\\340\\345s\\333\\342\\262\\245E\\336L\\336[5\\251\\014\\327D\\006\\352Kd\\373\\340sM;\\023+\\346\\2261#\\233c\\327\\237\\247\\317\\305Z\\021q\\241\\336G=\\354\\013\\370|\\326\\330T\\234\\341\\217\\003?\\035*d\\206\\216\\273\\017\\207/\\340\\322\\2467\\261\\341A\\310\\030\\374 \\177\\177\\245\\022\\203\\240RVr\\333\\253[\\213\\213\\270\\364\\333W\\021\\010\\267<\\3148\\033\\217_\\317\\025\\013VS\\017\\367k[(R\\030f\\222[\\231w\\000\\221`\\274\\236\\355\\273\\353\\306\\017\\267\\036\\364\\236A1\\251\\005\\245\\305\\274\\236t\\346)\\007\\250\\305\\032o@\\203\\252\\223\\365#\\277c\\361Y\\345\\032l<\\010`\\313\\013\\250%\\205\\220J\\254\\212\\010\\334I^3\\301\\003\\217a\\237sI\\310\\245\\022\\372\\321\\030Oo\\024\\245d\\205\\244\\033\\244\\031\\302\\263($v\\004d\\361\\237o\\312\\260r\\331\\252\\210i\\340\\270hmb\\202GX\\311u\\036[`\\240\\317\\nz\\2021\\267\\236\\270\\372\\232I\\330\\364\\002X\\0149*\\213\\363\\317\\275[\\262U\\001\\360\\355\\360\\202\\366\\341\\'\\365\\027\\033c#\\242\\216rq\\216y\\376x\\252\\212\\300\\245\\221k\\213@\\327k-\\324b5\\265~\\021\\263\\211\\030c g\\337\\037\\324\\326\\253\\010\\306\\312[\\251g\\324\\032i\\3402\\023#~\\366\\\\\\2202\\334\\372\\275\\306I\\365w\\300\\315:\\255\\210\\326/\\002\\302\\352-\\245\\023>\\t\\336\\231\\004\\016:\\363[,\\354\\315\\375\\035\\253\\354\\373\\355\\375\\354\\264\\330\\364\\357\\030\\331\\335\\336\\311l\\201R\\376\\327\\r#\\250\\351\\346\\251#$\\017\\342\\007\\'\\270\\'\\232\\331O\\331-Yg\\342_\\267i.t\\333\\327\\360\\256\\237,Q\\254g\\027w\\200rN\\024mE>\\376\\347\\2368\\250\\224\\304\\242y\\346\\363V\\276\\276\\326$\\277\\276\\236In\\344\\220\\310\\354\\347\\235\\307\\373\\376T\\250\\255\\035GO\\271\\032\\235\\275\\202y\\273\\214x\\016\\2100]\\210\\033Io`\\0060}\\353\\007\\263b\\346\\303I\\032\\334\\276Q\\363&\\335\\220\\252\\347\\013\\362Go\\2461\\217z\\020Q\\320\\374\\027\\366G\\246Y\\\\G\\177\\252E\\003N\\236\\250\\242#\\001\\007l\\373\\375+\\252\\020\\254\\263\\031N\\260\\216\\222\\321n\\204\\034\\027H\\370\\004\\017H\\002\\2652c\\020@\\227n\\253<\\205\\227\\256OAF\\203cEb2\\005\\215\\363\\264\\340c\\240\\244\\002h\\312\\214\\352W?4\\304-r\\254\\312v5R\\023!a\\021\\201\\213Jw1\\247\\'b\\212\\240\\355r\\262)\\205\\2063\\355J\\274\\216\\314+<`&\\343\\264\\364\\242\\223\\r\\0031\\346L\\225$\\212b\\016\\347 G\\037\\016\\006x\\355Hac\\217u\\276f\\005\\330s\\212\\227\\274\\002\\326O\\242\\363\\004LB\\200\\247\\240\\241\\214-\\275\\264\\212]\\224\\372\\210\\241\\260H\\314O\\344\\215\\341r\\375)\\0003\\3464\\243{a\\333\\260\\350)\\201\\364\\266\\242\\031}Le\\'\\232\\024\\205DRY\\241\\230\\235\\236`<\\001\\331h\\303A\\2334\\257\\266]u4\\235\\002;f\\2324\\236\\370\\220\\304\\220\\002F\\275\\177R@\\375k\\036YuT\\215`\\255\\3338]\\225\\266\\237&\\223wsm\\206\\224\\261\\232|r\\010\\350\\010\\256Wm\\033\\255\\234\\373T\\373\\275\\375\\343a\\211U\\030\\332?\\206\\264\\215\\244D\\266R\\311\\037\\223>\\330\\360\\274\\360\\307\\371V\\204\\233\\017\\331\\375\\253\\334\\370\\247K\\2160\\204\\313r\\243.7.\\341\\377\\000q\\320\\365\\3150=\\240\\332t7\\026\\362Z\\345]\\312\\204>\\303\\214~\\225\\273X\\311\\215\\344\\363/\\332\\267\\207\\356\\2741\\251\\334G\\021*\\367.\\313\\023t\\016\\033\\031\\347\\351\\221\\\\\\216=]\\033\\247h\\323\\026(\\364\\326\\2160D2\\020\\242Y\\235\\200\\35299\\353\\307\\307~\\224]\\217E\\244\\232\\266\\233l\\322\\253\\313<\\261\\227\\301\\221\\001BN\\000\\311_\\221\\236\\207=\\373\\326.\\022f\\252I\\027\\232u\\3246\\305#1\\277\\335\\344vc\\270\\210\\317\\276T1\\343\\222:\\365\\311\\035+\\236Ql\\3322H\\277\\267\\323b\\0204\\261\\277\\231gq/\\232r=\\310\\343\\362\\365\\014}+8\\247\\'E\\311\\244\\254\\030\\221,\\224\\005\\344\\2633\\020\\335\\362\\007\\177\\312\\272#\\036\\250\\311\\311\\311\\224\\327w\\006\\341Q\\231\\270\\221\\362q\\3063\\377\\0004\\207B\\266Qy\\227h\\001!\\\\\\355\\'<g\\270\\377\\000_\\255Z\\215\\220\\344m\\277h^\\027\\232\\306\\332+\\240\\031\\255\\237\\313i[ny\\034\\022~?N\\t\\256\\211q\\3650R\\263\\237\\352+\\376#\\256Ge\\021\\362\\355Q\\002\\263\\256\\000\\332X\\365\\317\\030\\3439\\367\\315J\\325\\217\\350\\245\\327\\334y\\321\\331Z\\304\\211#p\\n\\271>\\220N>\\204\\214\\037\\241\\355U\\037d\\262\\243U\\201\\355\\3046\\253\\026\\307?\\213\\214\\0269\\350O~j\\354F\\347\\247\\333\\244\\032E\\2723\\306\\253\\0221m\\314\\247\\014F0zry\\307\\\\\\344b\\262o&\\225\\202\\237Q\\360\\244\\221\\002\\3613\\313\\221\\210\\202\\256\\334\\340\\201\\216\\231\\310\\035\\272\\343\\236i\\256DOZ\\013\\341\\324\\324,\\365$\\212X\\323k6z)E>\\370\\035\\276\\230\\241\\245-\\025\\026\\321\\351\\277\\002\\350Q\\307\\246\\305w:G,\\262\\000q\\037\\021\\373\\376u\\267\\037\\022Yfs\\344\\360\\216\\207\\024p\\334E\\213\\2241\\034\\200\\253\\236\\325\\263u\\243=\\354v_\\273\\331\\345$\\'\\310?\\205Gz\\233l\\036\\006-\\356m\\022\\317j\\224_jN\\307\\212(\\365\\251~\\347\\014s@\\371r\\177\\010\\035Mi\\034\\341\\231\\311\\326PId\\2126o1\\200\\366\\002\\221@v\\tF\\350\\337$\\364ZwD\\325\\221\\216)\\267\\222Sv;Qc\\243\\341\\006\\346\\342\\\"\\037\\346\\213\\nCP\\351\\327(\\026V\\301\\347\\241\\245\\3310\\243\\027&s0\\312\\252\\032\\020\\305\\314m\\271\\231I\\335\\335\\250\\001\\230\\022B2\\244\\236\\336\\371\\244\\004\\357 \\226$\\005\\267/\\034\\001B\\3100zi\\226Y\\017\\232J\\250\\343\\216\\246\\251\\244\\211M\\261\\231\\225\\024\\026\\335\\205\\035y\\244U\\230\\206D/\\2222\\242\\206\\205vL\\335B\\331\\010\\240\\021J\\202\\310,\\210\\261\\260\\214\\016Ns@\\316\\025\\366\\354\\360\\335\\353)o:\\254\\211\\035\\272\\2147A\\222Mr|\\231T\\221\\321\\302\\2553\\205\\351\\262-\\216\\257\\035\\271\\221~\\351)1H\\000a\\205n8\\347\\004\\214\\321\\037\\331\\nJ\\230\\226\\257\\244\\335Y\\337\\334Gg\\023,\\010p\\030pH\\246\\245k\\\"hEmn]\\366\\315\\350\\030\\316\\343\\375\\177\\237\\363\\253\\261\\033\\217\\330\\365\\234\\247\\355#BH\\235\\030\\211\\2672\\267F\\000\\023\\237\\257\\260\\370\\247\\034\\264\\'\\243\\330.e,r\\002\\347\\256\\007Z\\350\\243#\\\\\\361\\307\\205\\355<U\\247\\307m\\251\\002\\315\\023y\\220\\310\\274\\024lu\\376\\224\\245\\005$5&\\231\\346o\\024x^\\346\\307\\306\\257i\\251[\\262\\307\\024{\\343-\\314r\\200pNk\\216I\\301Q\\320\\232\\226J\\225\\202\\363dKj\\221\\264\\354\\246Rs\\260\\\"\\356$\\014\\223\\327\\2160y\\002\\241\\265\\344j\\374\\005\\266K8\\241\\213\\357\\273\\t\\331\\346\\226p\\034\\234\\374\\365\\374\\276{T;\\177\\311\\244i\\177F\\357\\240\\334\\331\\217\\017\\335\\013#\\210\\342*N\\3258\\365t\\300\\350+(\\251)d\\2715X+\\257\\265\\0040H\\303\\326\\0252H<\\023\\327\\031\\376\\373\\3258\\330\\223\\242\\252\\371e\\265\\215q$Y\\215\\260\\245I\\303\\247M\\312O$e[?\\034UDRl\\177\\303!\\333R\\2641@e\\203\\315\\014Q[\\005\\362q\\217\\257LU\\251$\\322\\'\\253g\\252.4\\253-K\\303RA8M\\362\\'\\002N6\\2668\\340|\\342\\273Z\\274\\034\\272\\311\\302<i\\366sqa\\250\\311>\\237\\037\\237\\004\\252\\t\\332\\016\\027i\\310\\003\\337\\334\\212\\306\\\\n%\\306I\\234\\346\\366\\310\\333\\353\\270X\\230\\315<%#v8\\021\\234\\367\\357\\361\\324qP\\236\\n\\254\\231\\361\\037\\207\\323P\\363.-d\\331,J\\035\\324d\\205\\302\\200x\\356s\\216G\\034\\347\\336\\245N\\206\\343y\\r\\341;\\263p#\\263\\324-\\355\\243\\236\\037M\\264\\361\\250S\\202:dp\\177?sJk\\312..\\366n\\332w\\206\\031n7\\306\\237\\217k(\\301b\\006x<w\\353\\223\\327\\353Qw\\202\\250\\352>\\025\\3731\\261\\264e\\277\\270\\267C7\\007xr\\006s\\234\\214c\\232\\353\\343\\205e\\230N^\\021\\320\\332\\322(\\n\\201\\351\\210\\340\\222y5\\265\\231\\013\\\\\\253\\317!\\222\\335\\260\\203\\200\\306\\232\\373\\023\\372\\013u\\'\\233\\034Q\\304\\0038\\035_\\251\\241 y%*\\304\\226\\353\\031\\003\\314n\\257\\216\\207\\332\\220\\022m2\\030c\\027\\022\\260\\334\\007\\000\\236\\376\\364v\\360:\\362SMr\\323\\354H\\323?8\\255\\022\\242\\033\\262V\\266\\222y\\233\\336R\\017`\\017J\\033\\022\\217\\262\\305\\024F\\331\\363\\316~\\265\\005\\207\\016A\\007\\314\\024\\200#\\335\\273.\\3230\\300\\366\\245C\\260\\036r\\207\\004\\260c\\363LFL\\303\\234\\250\\037\\024\\001\\364R\\204\\374\\013\\217\\241\\240\\t\\313;?U-\\3654\\0007r\\244y`g\\034\\320\\000]$s\\226\\000\\203\\332\\235\\205\\037l\\227p\\035\\005\\026\\001\\245\\267E\\346\\027?9\\245`\\010@\\330>\\254P\\007\\236\\376\\333\\256\\005\\277\\2125\\002d\\004F\\250\\240g\\246\\024~\\265\\307\\317\\231\\321\\323\\304\\3526pi.RK\\202d.\\261\\273\\203\\277\\335s\\311\\037\\361Z\\245Fm\\233v\\274\\307O\\2069\\356/\\276\\363\\034\\361\\244\\260`r\\312A\\301\\376X\\374\\2536\\277jE\\'\\213f\\243\\367\\331\\246\\222I\\024\\010\\242\\347v\\325\\353\\360j\\352\\211:\\037\\354\\367gs7\\332m\\225\\324)\\347A\\004rI3\\014~\\350\\025\\306p~H\\034~\\265p\\330\\245\\243\\326N\\374\\202rk\\240\\310\\014\\222\\270\\030\\010H\\355F\\005\\222\\273X\\321\\254\\265{c\\016\\241l\\223\\002\\245rG+\\237c\\332\\224\\222\\222\\246R\\264p\\037\\023xhx?Y\\373\\220I\\'\\265\\026\\342X\\035\\224\\035\\3308\\307\\'\\250\\311\\342\\2709\\340\\321\\323\\305#\\236x\\206\\177>\\362R\\203\\323\\237FG*:\\214\\373\\036iq\\252C\\233\\266o\\177d\\232{k0\\370\\202\\304F\\370{$\\225O\\\\\\2728$~y\\\"\\232\\217iW\\3207Q\\277\\262\\254-\\316\\244\\307\\356p\\204\\264\\201\\214l\\314?\\021\\310\\316>\\230#\\363\\254d\\324vi\\004\\345\\220W\\232\\\\O#\\335<\\244\\304\\'*\\203\\234\\272\\347\\003\\003\\266\\006\\177\\\\\\324.J\\304K\\350\\236Yk\\341kf\\223U\\261\\216\\336\\372\\006B\\331\\330\\340\\r\\243=\\307\\031\\351\\267\\333\\232qw%hmR\\301\\351\\335>\\331\\022\\010C\\203\\351Q\\220[v\\rz\\353\\010\\363^Ya<\\261\\310\\233\\014jW\\004c\\037\\030\\245@j\\232\\337\\202\\364]RQ$\\326\\310$P@e\\340\\220NO\\363\\251|i\\224\\244\\321\\257\\307\\366ai\\275X\\\\?\\230\\217\\225n\\236\\223\\214\\203\\216\\371\\035{\\326/\\201\\026\\271h\\235\\257\\331\\036\\203\\346\\t\\256<\\306\\2241l\\203\\214\\347\\250>\\343\\353N<U\\261\\276OF\\373\\245izn\\231n\\261\\303\\032\\034\\177\\026\\332\\325A-\\\"\\034\\333\\330\\374\\227Q\\235\\270\\'\\003\\247\\260\\252\\242\\000Kx\\230%\\311l\\373\\320\\220X\\013 g\\237lQ\\204\\211\\271.\\307\\212o\\000\\213\\335;K\\265\\373\\307\\233\\346\\253\\314\\0068=*\\034\\235\\024\\222\\331l\\272E\\273\\251\\336\\233\\211\\352j;\\217\\252 t\\033Br\\301\\217~X\\232;\\207Ts\\205y\\210\\364\\220\\265\\322cAWv2\\356\\337\\225,\\014*K\\264\\360\\271>\\346\\220\\303\\231\\262=G\\024\\206HK\\0369\\346\\220\\005\\216H\\273\\002O\\322\\200\\014\\236\\276v\\234\\375)\\0013\\n\\236\\010\\305\\000I`\\007\\201\\232\\000\\220\\265\\031\\344\\032\\000\\230\\203\\'\\203\\323\\346\\200&-FFI?\\235\\000Ic\\204\\034\\022\\t\\372\\320\\004\\304Q\\026\\033\\200\\307\\301\\244\\007\\222?h\\370L\\036:\\324U\\230\\254\\0222\\312Cg%J\\202\\000\\374\\353\\231\\377\\000\\344f\\353\\370G&]\\'P\\225\\254\\202[\\227{\\334\\371*\\256\\tl\\036r3\\351\\353\\337\\034s\\322\\264\\242,\\351\\2363\\320\\341\\223\\303\\276\\r\\271\\234\\006\\224\\350\\261\\372A\\352C\\267_|\\002\\005O%\\305\\257\\262\\241\\2334;\\205\\211W\\312p\\016\\t\\302/\\244\\017\\327\\372\\322@\\316\\265\\373;\\351\\260\\177\\215Kw\\026T\\305\\013\\020\\352\\271\\004\\222\\007_j\\276<\\310\\231\\377\\000\\'\\241\\204\\250\\230\\3475\\321FVH\\\\\\241\\343nM\\024;\\010\\262\\202x\\210\\322\\240\\263\\235\\375\\271E\\034\\236\\027\\202VG\\336\\223`*\\246\\354\\202\\2479\\003\\257\\375\\353\\016\\177\\344\\323\\213g\\231o\\031\\231\\310\\352\\352J\\263\\002q\\3562}\\372\\376_J\\306&\\254\\356\\037\\263E\\223\\213\\235f\\355\\300UH\\222\\000=\\362r~\\235\\rW\\016y\\037\\322\\037.8\\327\\3333\\343[\\030\\354u\\275R\\316\\010\\3041\\263oO`\\033\\236?\\235q\\374\\265S6\\370\\356\\342s\\315B5\\263\\267\\232\\007g}\\255\\277$\\343\\031\\004\\177SQ\\007\\333F\\263U\\262\\313\\300\\272|r\\370\\213GD\\212b\\277yQ\\260K\\271\\311\\351\\324\\037n\\265\\254[sH\\315\\245\\325\\236\\242\\216\\322\\1770F\\230q\\327\\203\\323\\342\\275[<\\3521,O\\024\\245$S\\237\\212v\\024E\\033\\234\\355\\024\\001\\366\\377\\000O\\035h\\002!\\311^H#\\246(\\002\\033\\234\\276\\324\\0318\\311\\317j`Cl\\214\\t*@\\240\\014\\210\\274\\305\\033\\377\\000\\005\\027AD\\305\\2523e\\230\\260^\\335\\200\\243\\260\\250b\\311\\\"\\266F\\333+\\251\\'\\'\\034Rn\\306\\225\\017G\\251l\\344M9\\036\\333\\252\\\\P\\354\\372]rR\\347cH1\\3334t\\025\\2252\\301\\004\\010Y\\306[\\260\\025\\242\\311-\\321\\233o2H<\\266\\364@O*:\\237\\316\\206\\222\\022l}\\341\\267H\\200\\362\\224\\214u=j\\013+\\346\\267\\365~\\355\\006O\\277j\\244&\\307\\255\\355\\241\\211I\\234n\\030\\251`FE\\022>\\330\\023d\\177\\347n\\277\\245:\\366\\027z\\010\\023j\\3401$w4\\206MU\\377\\000\\315\\317\\322\\212\\002E\\\\!.\\370\\003\\330QH,\\372\\326?8\\263\\222\\314\\243\\334\\320\\360$[C\\024>P\\n\\tc\\330%C(R}.[\\200v\\227\\211;\\372\\251\\251$*\\260\\366\\372b\\302\\236\\242\\t\\372Rr\\035\\r\\375\\3164L\\224\\311\\307Z\\227!\\321\\343?\\332?\\314\\273\\373Q\\324\\255\\245\\236(m\\332x\\342\\016Ia\\032\\252($\\201\\223\\306k\\024\\256m\\232\\274E\\034\\336\\335\\344\\022+\\375\\345$H\\001\\236!3\\205v\\\\\\200\\0062r\\307\\037\\207=9\\316\\rjA\\350/\\264\\337\\016\\334i\\337d^\\026\\325/c\\215\\r\\255\\275\\274wK\\032c\\310YS\\214\\177\\361;F(\\344\\375\\242\\276\\202\\030l\\363\\255\\364F\\t\\231\\240\\220O#\\260]\\304\\344`\\377\\000}j\\020\\331\\335\\277g0\\222\\352w\\326r\\0062%\\242\\310\\314\\253\\205L\\277O\\317#\\342\\257\\213\\r\\261O(\\364\\014vQ\\220\\025B\\344\\373\\326\\326gD$\\265\\020\\237\\341\\'\\342\\237aQ\\220\\256xP\\000\\367\\240g8\\373y\\333\\007\\205\\254\\326Y\\017\\357.\\t\\003v?\\n\\036z\\375+\\233\\344\\277\\325\\032q\\177G\\233\\257\\362.\\244Y\\031\\204jr;\\206\\350H\\036\\344\\2029\\307\\265a\\035\\033=\\235\\363\\366l\\265\\021xWP\\235P\\315=\\315\\300D*s\\234s\\222~\\246\\266\\370\\352\\345\\'\\376\\023\\317*\\214W\\372k?i:\\250\\227\\306\\227\\314%\\214E\\033\\030IF\\340\\205\\030\\316{\\234\\203\\\\\\237%\\366\\223\\243o\\216\\251Y\\315|S~\\227\\326\\311\\024A\\203\\017[8\\037\\'\\202\\177\\276jx8\\334]\\262\\371\\247j\\216\\237\\3733hF\\367[\\275\\326\\247/\\\"\\330\\247\\223\\021+\\200g\\220z\\211>\\352\\237\\377\\000\\177\\025\\335\\303\\014\\271\\034\\323\\225F\\275\\236\\207\\222\\324g\\207d#\\374\\246\\2679\\305\\244\\266$\\363#\\023\\355\\336\\230\\0201\\034\\363\\201\\217q@\\030\\300b\\001\\220n<a{\\323\\003\\\"\\000\\215\\267\\243t\\315 2#\\332\\t\\\\\\022;\\320\\004|\\271\\010\\3060)\\201#\\001\\003\\2221\\327\\351E\\201\\036\\001 t\\351@\\021\\301#\\330P\\007\\314\\273\\177\\027\\351@\\002\\221\\202\\250\\311\\007<S\\021\\002\\254]\\263\\034\\214w`\\2228\\007\\332\\235\\212\\202\\251\\230\\260`\\273c\\035\\261R1\\201q\\013\\200\\254\\313\\273\\330rMH\\305_R\\264\\210\\224-3\\225\\316v\\304\\306\\251&\\311\\2643\\246\\\\\\303v\\215,\\342kx\\363\\2660\\353\\202\\347\\351JV\\2645Od\\374\\322\\327\\016\\250\\255\\205#%\\272c\\275!\\371\\010\\222\\002\\253\\261w\\223\\311|\\215\\275h\\260\\030\\214G\\345\\357i\\343\\004\\222\\006\\337\\341\\372\\322\\354\\024+<\\221>\\002\\334\\304\\344\\343*}8\\377\\000z\\244\\330\\261\\241\\273)\\235a\\330\\233\\017|\\201\\307=>\\234\\324\\261\\2401\\370\\215!\\2260=LHV]\\235\\373\\216)U\\216\\313\\330u\\270\\344\\225 XCH\\343!U\\371#\\337\\232\\216\\243\\260\\261\\3526\\217#$\\205\\321\\207@P\\237\\313\\216\\364S\\013%.\\243n\\243\\205w\\213\\273\\201\\300\\037\\235KLvy;\\366\\241\\360\\355\\212x\\242\\323\\3046\\323\\314\\332u\\373\\201v\\261\\200LR\\201\\203\\214\\361\\352\\000\\036N84\\253\\253\\267\\344\\273\\354\\260Q\\375\\221x:\\177\\036\\370\\322\\332\\373T\\265\\216\\337\\302\\266EE\\316\\343\\210\\330\\')\\022\\261\\031\\221\\231\\206X\\373\\023\\310\\364\\212\\323/$h\\365_\\217,l\\274O\\340\\275sK\\226\\342=\\267\\226\\262*\\267\\\\\\0207\\002\\007\\301ZM`\\023\\311\\340{\\373o\\27396\\313\\261P\\251`\\027\\361\\023\\365<\\201Y\\305\\331mQ\\332\\277e\\351L\\272\\237\\210U\\034\\274\\346\\013\\177J\\014(\\033\\333\\214~\\225\\254\\010\\221\\3500\\\"\\217\\231\\356\\025W\\034\\202\\340\\014\\326\\226\\210%l\\326\\354\\333\\241\\225%\\037\\3646\\352\\023O@4d\\212\\\"\\026F\\n\\347\\263q@\\036t\\375\\253u\\245\\266\\275\\321- ;\\246\\222\\331\\2449\\350\\252_\\217\\327\\025\\207\\\"\\355$i\\007G\\t\\217P\\226Efp#g\\030\\334\\177\\210{\\017|\\220\\177\\261Q\\326\\213\\263\\322~\\016\\361\\nx_\\354\\256\\3314\\346\\214\\337\\335\\222\\\"\\317!\\023h\\337\\'\\037\\'\\214\\367\\372V\\\\\\\\\\2161\\227\\2735\\346\\217g\\025\\364r}J9\\365;\\343\\016\\237\\034\\267\\027\\212\\030\\244\\021\\220\\322J\\301K\\034/\\004\\234\\002p98<V\\t9K\\3755\\304bk\\032=\\275\\336\\275\\252\\333X\\330\\302^\\356y\\026(\\343\\nybp\\016>;\\347\\330\\327TcXF\\027\\331\\333=\\225\\340\\017\\016[x7\\303\\226\\332U\\226\\371\\004y\\222Y\\234z\\245\\225\\277\\023\\343\\267\\307\\300\\025\\330\\222J\\216yJ\\331\\266\\242\\223\\016\\374\\201\\273\\370\\217j\\004,\\300nb\\277\\326\\230\\210/\\224w\\002\\352\\315\\216\\236\\324X\\022\\267\\211e\\225\\226\\r\\244\\250\\311\\344\\017\\347C`\\221\\211\\242x\\345\\304\\212T\\216\\231\\024&\\001\\000\\033B\\240\\030\\357\\316h\\003\\r\\022\\266\\017%\\317V\\315\\000\\016h\\303(S\\205\\003\\333\\251\\241\\000\\270\\266`\\344\\356-\\037<\\016*\\200\\033Z\\356\\316Y\\263\\356\\034\\361@\\211\\233r\\3025>\\220\\243\\260\\377\\000Z\\000\\3040$-&Hb\\343\\036\\256H\\370\\003\\265\\r\\330#d\\232\\314(|\\006\\033\\2078\\350G\\315b\\231e\\037\\335\\341P\\022@C\\226\\344\\023\\225Q\\332\\264\\242l\\222\\351\\320\\200\\3065\\2126\\220r\\300\\220\\330\\245\\220\\301\\365\\365\\200\\362\\202\\030\\272\\220D\\215\\324\\177\\265$\\330\\332T/v\\327\\036p\\016vl\\003\\324S\\343\\257~\\324\\320\\013\\310\\376dG\\316\\2266\\014q\\353b\\n\\212H@-n,\\254$YbC\\350\\343\\214\\272\\375@5M9`X\\216C\\332\\316\\332\\244\\345\\360\\301Y\\216\\351B\\216>\\203\\267\\326\\216\\275Pv\\260\\272\\245\\224i\\014q\\315\\032\\234\\222\\315*\\203\\234g\\243\\032I\\273\\033V\\204\\323d@-\\253\\244j\\016\\357*2\\333\\017\\327\\346\\206\\357aU\\241\\3513 \\304\\014\\261\\340\\203\\320\\005c\\356sK[\\031?\\2744E\\317\\236\\357&9e\\302\\361\\354(\\253\\000)q!\\237\\324\\362\\355e\\'+\\223\\267\\035\\277\\342\\223@gk\\334#\\\"\\227d$)\\016I\\037<\\naD\\265\\033K\\026\\033\\'\\020\\334\\3020\\002\\317\\006\\356\\2358\\307\\275M\\267\\340z\\003\\177#\\213/%\\347[k|zC\\020\\024\\236\\340\\002*\\326]\\222\\360P\\353\\376,\\323\\264-\\036\\352\\345\\365Kc{\\367WX-\\335\\300\\222V*@\\001z\\214\\232\\316rIS\\034s\\243\\310>\\\"I#vh\\216F6\\222s\\333\\276:t\\037\\025\\214\\rdt\\317\\331zt\\267\\361N\\263o<\\003|\\372z\\314\\031\\373\\354\\220\\177#\\220y\\366\\025\\244^i\\023%\\213=\\005=\\314R\\026Ft{\\206 *\\354\\301c\\354\\t\\025\\255/&w\\350\\270\\322\\341\\202$I.\\031\\203\\026\\313!\\n\\024/v\\000rNz\\232\\206\\322\\376J\\377\\000MK\\306\\236;\\261\\360LG\\316\\270\\212w\\2722<(T\\031\\035G\\005\\213\\034\\004\\\\\\361\\337\\342\\211\\311%\\225\\220I\\370g\\221\\276\\324<Ku\\343\\017\\024M\\254\\316\\230\\210\\242\\301\\036\\314\\224E\\\\\\200\\240\\377\\000y\\353\\336\\241[\\313.\\253F\\261\\007\\2409\\3478\\306(`vO\\017]L\\236\\032\\262\\202\\3766\\202{xY\\014n\\010d\\365g,1\\221\\236+\\207\\227\\365m#\\256?\\265?\\243E\\361E\\334oy\\032[\\310\\004\\253\\373\\306\\221Tn\\017\\333\\014\\017\\004\\361\\364\\307\\315i\\303\\026\\262\\314\\371d\\233\\244w\\037\\331s\\302\\352\\026\\177\\030j\\253>\\311\\014\\226\\272xe\\310\\224\\377\\000\\356\\314\\t\\347\\376\\234\\373\\356\\371\\256\\270\\305\\354\\305\\312\\225{;\\362\\337Z\\0071nx\\355\\202\\360\\250\\006\\\\\\374\\236\\346\\255\\331\\236\\t\\356\\202[\\217E\\324V\\361\\\"\\360f!\\233\\237\\372z~}h\\310`\\372D\\264\\270\\266[}6h.\\245F\\365H\\353\\204\\034\\344\\356?\\355E\\265\\226\\030xA\\227M\\214\\273\\007\\232\\322(\\024d\\307\\000\\004\\223\\376\\224~@\\352/g\\246\\264\\345\\346\\t3\\303\\377\\000\\265\\265W\\'\\337\\251\\246\\347X\\005\\037$\\357\\254\\246\\265\\21270\\231\\\\\\344,i\\206n\\2374)&&\\232\\022[K\\373\\274\\031-\\346\\213\\003\\253\\000\\273G\\326\\253\\262AM\\221Ho\\324\\307\\034p\\226\\317\\002DVe\\030\\376\\372\\321h)\\221U\\235%qs\\2744x-\\271v\\001\\236\\303\\336\\213U\\200\\240\\256.<\\257:\\030I\\214q\\352\\030\\000\\374\\223E\\2550\\246%-\\325\\364L[\\3742Y\\021p7\\357\\0006\\177\\313\\317?\\225Z\\353\\354\\206\\344\\274\\006\\322\\256\\037T\\226h\\036\\326\\342\\321\\323\\031Y\\224\\2438=\\306q\\201JK\\256lj\\336\\321\\261[\\330\\306\\233AX\\343\\030\\300\\301\\034\\326nE\\321U{\\250O1\\\"!\\263\\330\\036j\\222Kbe$\\326\\222\\273\\227\\236\\341\\261\\216x\\305j\\244\\226\\221\\237_lv\\336\\376\\010\\211\\021\\235\\300\\340s\\317\\003\\344\\3248\\266;Hv-A\\034\\224\\212\\'h\\317\\371\\216sS\\325\\242\\254lj\\255\\215\\215i\\036@\\301\\313t\\245\\324v\\'3\\244\\214\\277\\371t\\005z\\034\\363\\372\\323HF\\026\\010K\\0266\\361\\251=\\207J`XY=\\272\\272\\254\\253\\261~:f\\245\\330\\321v\\220+\\240*\\312\\313\\333\\275eeQIy\\341\\330\\213\\022\\211\\220z\\000q\\217\\367\\253R\\023E{hRD\\252\\002\\340\\223\\333\\237\\370\\246\\232\\025\\000\\373\\204\\361\\344b\\335\\343\\336K;\\345\\035G\\260\\034\\203\\317\\3051\\000\\325\\354/\\255\\354\\374\\3756x\\356\\235\\0102\\305\\261\\267\\205\\037\\211\\220\\017\\304q\\333\\031\\357\\317J\\\"\\323t\\306\\323\\254\\032\\354\\272\\235\\365\\354\\3564b\\367\\320\\240\\036ds[\\371d|\\023\\200\\177J\\321A/\\357\\006nM\\377\\000#\\315\\177\\252Md\\231\\265\\267\\262\\273\\0052VI\\034\\225\\317 \\202\\016\\334\\014{\\324\\364\\212{\\264U\\311\\254\\201\\324,\\265\\315KG\\271\\213\\357z\\\\WR+,r:\\310\\305\\t\\007\\325\\302\\365\\031\\366\\371\\353\\212\\231%_\\250\\325\\3719d\\337b\\372\\323a\\322\\377\\000OiA\\334\\255\\373\\323\\372\\372s\\\\\\377\\000\\212W\\206\\215\\324\\342V\\352_a\\336,\\271\\270\\005u\\035\\026\\033wb\\354\\034NN3\\327\\377\\000O\\270\\317\\031\\377\\000zq\\342\\255\\2619\\257\\006\\347\\366q\\366Oq\\341]b\\367S\\277\\324\\341\\271\\272\\232\\037\\273\\306#]\\210\\221\\344\\036A$\\356\\340\\001\\216\\000\\367\\253\\214TE)v:TPI\\014Ab\\373\\273\\241l\\222\\322\\022\\315\\217|\\377\\000\\245\\024M\\230Wh\\036y\\266\\333\\254\\217\\200_%\\212\\216\\300\\177\\305:ag7\\373Y\\3734\\377\\000\\307\\027\\2267\\303UK;\\230`\\362QQ<\\305oV\\341\\270u\\030$\\376Tu\\260L\\373\\300\\277e\\263\\350\\363^\\307wu\\005\\366\\221vcY\\254\\327N\\021\\302YP\\256\\006\\371\\031}Y\\0318\\317\\003\\004d\\322\\353\\215\\216\\363cP}\\216xN\\330\\031 \\320\\030\\314\\276g\\357\\244\\270v\\021\\206]\\274\\0068\\033z\\251\\354\\334\\374T\\270\\375\\217\\267\\321\\257\\353\\237cz%\\344\\322\\311\\026\\267\\252\\333M*\\355+\\036\\311\\324c\\203\\236\\024\\3621\\222[$\\345\\211\\311\\243\\361!\\376B\\337\\301\\177f\\376\\026\\360\\376\\213-\\216\\243\\240Yx\\202\\341\\335\\231\\257\\356\\255\\266H\\312\\335\\006\\335\\307f=\\324\\374\\360j\\234_\\201w\\364nv\\262Ge\\247\\333\\330X\\351\\242\\033Ha\\020E\\024\\223\\222\\261\\240\\341@\\030\\342\\217\\330N\\230\\342\\\\/\\227\\024q\\306\\220\\310\\240\\007$\\263o\\307R}\\263M9y\\023\\243>k\\243\\311\\367i\\321\\304\\215\\267\\023\\0068^\\271\\'?\\323\\365\\247\\226,#\\3575\\336\\356\\\"\\3546\\201\\263j\\200\\020\\177\\325\\217\\345\\376\\364dx\\032\\2677\\021\\251y.R\\325f\\005I\\212 I\\366\\370#\\037\\230\\245\\220\\240r\\317u\\014\\316\\202\\356ic\\333\\200\\273\\031\\000\\366\\030\\317\\037Zu~\\004)$a\\257A\\271Y\\245y=L\\316\\315\\351\\300\\030\\344\\037nq\\217\\217\\232\\245u\\2014\\213e\\271\\274kUB\\333\\320\\256\\335\\376f\\306E\\035\\006:\\023\\365\\346\\242\\262S`g\\271\\270\\020\\001\\034\\327\\200\\240\\036\\217<\\340\\374~x\\247B\\001\\367\\355M\\246\\314\\026N^B7\\312\\323z8\\367\\316O<r)\\250\\373a\\376\\027q\\333\\337\\336\\241h\\367\\364\\001E\\314\\273\\202\\3602v\\202A\\357S\\204:\\026\\272\\323\\226w\\210Oz\\320\\275\\263\\345p\\252\\001\\371\\3178\\035\\361\\371U&,l9\\270/*Es,W\\326\\321\\345\\203\\306\\231+\\307\\\\u\\317\\362\\346\\225yA~\\300_\\230\\345\\220\\230\\020\\2118\\t\\032\\251]\\312?\\213\\332\\232\\265\\2610\\223\\213\\206B!\\214.z\\223\\3115j\\274\\210\\251\\274\\260\\273\\237&WX\\324\\365\\311\\316kH\\312(\\227\\026\\304\\326\\304G(\\023L$A\\321\\020Uw\\275\\023\\322\\213[Ye\\nBF\\024\\036\\006{\\n\\315\\224\\206!\\212^I9\\'\\342\\223\\032\\031\\216\\t\\017$\\363\\364\\251\\030U\\264\\177\\256}\\350\\260$m&\\355\\201J\\306\\026\\030\\356 \\311\\215\\212\\237\\203I\\323\\001\\330u&\\036\\213\\245#\\376\\245\\250\\353\\350\\253\\033\\315\\274\\374\\251\\017F@\\030\\267\\210d\\355\\340\\237\\216i\\330\\201\\274p\\005,\\353\\201\\356\\033\\024\\001Y5\\305\\271\\375\\314\\017( \\362@\\316>\\265]X\\254N\\345c\\365<\\221\\233\\200\\007\\253\\017\\201\\217\\247ZhA\\\"\\363\\032\\325c\\264\\265\\213\\313$\\220\\2128\\037<\\321\\376\\214\\021\\263\\2304\\202H\\325$\\177Pf\\030\\013\\361\\201\\375h\\300d\\025\\215\\235\\345\\315\\304\\212\\315\\350\\034.\\345!s\\237pzb\\207I\\002\\260\\215a,\\021\\227\\270\\201V@\\344\\262\\253\\356]\\277\\031\\346\\225\\257\\000\\r%\\267\\363JE\\024\\326\\367\\030\\311\\2300\\351\\376^\\237\\312\\233\\213\\025\\240\\023\\331\\311t\\300,\\222F\\370\\306T\\377\\000\\276qB\\300\\366\\027\\356p\\213\\266\\232[iX\\260\\n\\341\\244\\335\\236\\0108\\035\\272\\363\\336\\213t\\024\\035\\257\\246@\\\"\\267\\215\\242\\266\\004\\r\\200\\000p;g\\375\\277Z]o,,\\225\\325\\314\\023@C@\\344\\026\\350\\3447\\030\\376\\375\\351uv;+\\215\\234\\317*\\313\\004E`\\004\\026\\214F\\0307\\377\\000oj\\245\\366,\\222\\236\\307v\\033\\311\\202,\\223\\225y\\367\\021\\365\\242\\300X\\333\\301\\346\\272/\\255\\202\\362|\\334\\217\\314c\\375i\\201(l\\313\\027!r\\261\\214\\357\\010ph\\000\\t4Q<\\274\\214\\217\\305\\354O\\322\\2351Y=\\341\\201\\304bbGD\\003?\\314\\321@\\033D\\335re\\363 kX\\242\\374*H$\\222;`\\340R\\234R\\034X\\353\\007q\\224|\\260\\030\\000\\256\\007L\\340\\232UC\\263\\021\\026a\\207\\205Y\\361\\200Y\\361\\333\\266:QB\\261\\230\\355\\343VS P\\212\\244\\205U\\004~y<\\32012!\\373\\332\\307k*\\311t\\334*\\276@\\3163\\203\\357\\3074\\351\\213\\316\\t\\251\\212,\\233\\240B\\251\\332DH0\\017\\267\\037_\\347J\\237\\201\\330\\343\\265\\202\\215\\2069\\327\\374\\300\\205J\\232c\\264W\\337$W\\n\\253\\024R*\\'*\\262K\\310>\\365QM\\022\\362\\',W\\322:\\230\\'\\206%U\\001Z1\\202\\010\\317>\\344\\363U\\217\\\"\\310\\254\\366\\232\\244\\357\\\"\\313{1\\217\\361\\030ZC\\260\\373\\356\\035\\017\\277\\2654\\342\\274\\022\\342\\316\\205\\034K\\201\\305cf\\207\\322\\333F\\352w(?\\225\\0262\\236m>\\024\\224\\355\\030\\317\\305Z\\223\\023TN;T\\342\\213\\020\\324v\\351\\232V4\\206c\\205E+\\n\\014\\261(\\2440\\253\\030\\244\\007\\306\\025\\357E\\2007\\266\\215\\324\\206\\003\\332\\213\\002\\256\\342#i(h\\\\\\203Uv&\\013\\317\\225\\311Wv?C\\212t\\204\\301\\276\\016\\\\\\356\\'\\360\\234\\266sN\\304C\\312EpH\\334\\247\\215\\275\\006}\\351\\330\\020\\270o+\\010\\000\\303\\002O\\024,\\211\\261X59\\232\\375cOFx\\310\\246\\342\\252\\301H~Y\\345<4\\204\\216\\234\\376\\2254Q\\031$\\226\\334\\264k)\\3329\\302\\360)Ry\\001\\013\\231\\211!\\233s\\036\\243-\\300=j\\222B#n\\215t\\312\\031\\312\\014g\\322)\\274\\000Yn\\026;\\221n\\250s\\2007\\356\\346\\225^B\\313T\\204\\342P\\356[f\\322;pj\\n\\242:\\204\\021\\213\\006\\225\\024\\006\\333\\221\\236y\\367\\242/ \\304\\254,\\267\\334}\\331\\245b\\330,d#\\236=\\275\\252\\333\\254\\211\\\"\\352-&&\\210H\\356\\354\\3141\\223Y9\\027\\324\\256\\227I\\216/0\\254\\215\\2058\\000\\001V\\244K@$\\021F\\025\\032=\\305F\\342\\331\\306i\\330\\204\\356\\237{,j\\210\\250\\343\\257%\\201\\'\\256I\\307\\362\\246\\220\\200#\\371r4\\210\\251\\273\\240\\310\\310\\030\\366\\372\\325\\001_\\251]\\274\\n\\307lfIH\\033\\202\\201\\264{q\\375j\\243\\024\\311n\\2138\\2265X#H\\221U\\210S\\201\\317\\247\\276}\\3536\\362Z\\312\\033\\271\\2701.\\324E\\351\\234\\237\\201I\\005\\202\\260g\\270F,\\373H?\\302(n\\203c)\\022\\371\\3102\\371\\337\\214\\203\\361J\\306\\035\\341\\215#\\014\\201\\201Rps\\317\\344{P\\244\\302\\205\\274\\200\\267\\010\\373\\211c\\220j\\257\\300\\253\\310;\\350\\222\\r\\315\\313yxb3\\370\\207\\267\\322\\204\\304\\361\\221\\213\\004k\\3551oCyI\\316!\\0000\\030>\\346\\224\\237WCK\\026\\016\\331\\313\\2175\\271\\'\\004\\346\\233\\004\\0268\\326\\342W\\007 \\020{\\346\\226\\220\\217\\377\\331\"\n",
       "    }\n",
       "  }\n",
       "}\n",
       "feature {\n",
       "  key: \"label\"\n",
       "  value {\n",
       "    int64_list {\n",
       "      value: 1\n",
       "    }\n",
       "  }\n",
       "}\n",
       "feature {\n",
       "  key: \"width\"\n",
       "  value {\n",
       "    int64_list {\n",
       "      value: 320\n",
       "    }\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ie.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-02T03:11:20.855024Z",
     "start_time": "2021-08-02T03:11:20.852106Z"
    }
   },
   "outputs": [],
   "source": [
    "record_file = './images.tfrecords'\n",
    "with tf.io.TFRecordWriter(record_file) as writer:\n",
    "    writer.write(ie.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-02T03:16:12.345283Z",
     "start_time": "2021-08-02T03:16:12.275444Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset shapes: {depth: (), height: (), image_raw: (), label: (), width: ()}, types: {depth: tf.int64, height: tf.int64, image_raw: tf.string, label: tf.int64, width: tf.int64}>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read image from the file above\n",
    "raw_image_dataset = tf.data.TFRecordDataset('images.tfrecords')\n",
    "\n",
    "image_feature_description = {\n",
    "    'height': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'width': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'depth': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'label': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'image_raw': tf.io.FixedLenFeature([], tf.string),\n",
    "}\n",
    "\n",
    "def _parse_image_function(example_proto):\n",
    "  # Parse the input tf.Example proto using the dictionary above.\n",
    "  return tf.io.parse_single_example(example_proto, image_feature_description)\n",
    "\n",
    "parsed_image_dataset = raw_image_dataset.map(_parse_image_function)\n",
    "parsed_image_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-02T03:16:36.724974Z",
     "start_time": "2021-08-02T03:16:36.712245Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQEASABIAAD/2wBDAAYEBQYFBAYGBQYHBwYIChAKCgkJChQODwwQFxQYGBcUFhYaHSUfGhsjHBYWICwgIyYnKSopGR8tMC0oMCUoKSj/2wBDAQcHBwoIChMKChMoGhYaKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCj/wAARCADVAUADAREAAhEBAxEB/8QAHAAAAgIDAQEAAAAAAAAAAAAAAwQCBQEGBwgA/8QAPxAAAgEDAwIFAQUGBQIGAwAAAQIDAAQRBRIhMUEGEyJRYXEHFDKBkQgjQqGx8BVSwdHxYuEWJDNDcoI0U7L/xAAaAQADAQEBAQAAAAAAAAAAAAAAAQIDBAUG/8QAJxEAAgICAgICAwEBAAMAAAAAAAECESExAxJBUQRhEyIycSMzgbH/2gAMAwEAAhEDEQA/AO0suOldRzkVTcaACABRSGDmkHSmkJiy+pqYieMnFABolx0pDQwHCjmlQxea5wSBTSE2V8spZqtIiz4Lu60wCJF3qbHQVYgetKx0Zx2FABUXApAECH8qLHQSOIDmk2NIM5AXHekMgCAcnmgRCVyR7D2oSBiMiK3PQVZLEbn92cp3q1kl4BQR73LPTbEkNQLhiF6VLKQ/DhRmoZSDlty1JWyvmdlk+K0SIZgEtyaBBFGR7UhkXIUYzk0AU1+hkfgVrEzaJ2cODiQUpMaQ1LbRnoKlMfUqrqEKxrRMhoSCgyiqEkFkkKjAooCMQ3OM0mM2WzH7tQo6VlI1Qxu9RGelSMS1SVfKwOtXBZM5suyAOtZGxAsFNAiEj8UxCknJqkIJEuDSYIKQKQz4PgdaAASTEZANVQrF2JbmmIykdDYB0j+MUrHQdE46VIzOygCJGGGKYhiNOmalspDG0BaQwRODQBkgsOKAJBcDmgAE5A600JldMxJ9NWiGDVQ/4uTTCibRApxSsKIplTimwQ5HwvPWpKIByG68UAAuJAapIlkoiDjNJjRKY44XihDYq6sckGqRADdlsGmAzbKHJBFSxobEY2Ee1TZVFJqSHeQBWsDKRSTiRJsgGrJTJ5yMmmFhrYbmGKljRslrIEhA71i0aolKQPUDyaSBiF5ZzTnKqcEVakkQ4tmwMeayNQUjYFMGBZiaYj4LmgQUEKKQwbSCnQAGct0piMBC1FioQ1nVYtLltoDEZp5wWVA4TCjjOT88YrLk5VD7NYcfYstNuYb2ASwNx0ZW6qfY0Q5I8itClBwdMe2r7iqsVEtyKPxCgCJmix+IUAAe6iBwDTyGhG98SWNjJ5chkdx+MRqCE+pJH6DJrHk5ocbqTyaw4pSVosPv6lQQdwIyCO4rWjMib1SelFAGS8bgKtIZNpXkPoHSgBOZnZsVSJZ9HCe9FhQRYAKVjSM+Wi8seKMgAeSNTmnTDBg3HpO0EgewooLRKKKecZCYB96LoVWTeyMYJc5p9rF1I2UPnOE7k0NgkX6aCrR89ay7l9SH/hzdn1YFH5BdAEnhbByrn9aa5hfjFn0h7TJLZqu9h1ozHZu4yoOKLHQC50aR1MgPPzTXJRLga/d2TAkMACK2UzNxEI7ctMEAzzVOWBKOTZ4tKjjiQ7fVisHNm3RIKlnn0qMUrCh620pI8M5LH5qXIaQ2EjVTgAUhlTnJ61ZJB8DqaAYPKjvTFREzAdKAIJKJG5pMEfTKAuUPNCY2hVvPI9I5qrJoYiEir6utIpGjeMHYeJElmP7qGNF/FgKDnnNcfK/+lfR0wX/O17C6fqUlhdyPHiWJhk7WOdoHJ6YyOO/NZO4PtHZSqS6yNmgvhdQpLDKWRhkGu/inHlj2ics4uD6sLud/4ia0pEWyQTjnNICn1bVFgb7tZkPct1ZeQg9/76fWub5HyOn6Q/r/AOG/Dw9v2loor+Nf8ElLJmZiMAnkZ7464rirFs6k/wBi/wDDn3i40WxLZwI9uT8HH+lej8Z3xKzj+Qq5WkX0EYQkE7jWrMkxqFwCFI5NS0UmWltGijOeTUMojJahiStFhQq42EjqaoVETuPQHPtQAGe1mk+BTTSE0VhtpproRp+EHk1paSsjNm0abYxCLYVye5NYSkapDbxpEnHQUrsZXXMbTgFc4qk6JasxptuYr9AelOTtBFZN0TBUYrnZqTIFIZFsUAUmrRtI4C9K0iZshn7vbAkdBT2x6Ka+1NsEJxWsYGUpGs3s7SOcnOa2UaM7szpyA3Kn2NKWio7N4hhEsagdcVzN0bUKuohl5wMUwGjKPLyOlKgKu+vkiGBy3xVqLZLkkVmG/wA1OgIFWzyxoCzG0Z6k0xH20D+EmixEwhPbFKwokExQMlxQB8eOTQBpvjS3W5vvKjIMjWoeRWwAyhyowT/ED2ri+U1Hki36Oz4/7cbRqMN8X0+ELMxdX2ortljzjHA5z0xz7VE2CRQf4pfw6fNaRXH3MR3RZJopCqqm4hl56/TscVzKUuN9oM1pTVNGuHX/ABPatayWHia+mt5srCxfJI7A5GAcEjPwTXVHnl5eTGXGi/tNd8V6hIket63N5CzkSpZqiOYlwWG5QDnJCkjoM/Wp5PmSSqI48C2zbdAlSeC5uonKoZAFWMcKgGAOhH5HFcnHJ3k6pRVJIuNUnZo8LFh1QsFOAAvUscfrgda0lNVkXHx5N10qBLbQtOSJmZPuyMGYYLZGckds5r1eBdYJHmcz7Tk/szbyjzjuP51s1gyWwisXuB5fIHU0vAeS4gBcioZoiygjwhDd6hlIiLNd5JGTRYqJiBN4UAZosdEb9AkZVfxYoixMrbKMIjEj1E1TYkiwhcQW7MTyal5Hoq1u2nu9mfRV1SJu2XOEEe1Bk1BZKzs8SiWTr7UnLwCReQ9OKzZaC5x1pDISEbDQBUzE5JarRAtfjzLcgVccMUtGoXYbzCpBFdCZg0VkyHcQa0TJMW7mOQVMiom56FehkGT0rmmjeLB6uk0rmSFcrRHApCL30i25iKkPVqNktiEihVEkjZatEQ0MQxSXBJQcVm3RaJLYys2CaLBotbXSlVQW5NQ5FUMGziTqopWBUX7ASbIwKtIluiVpD/8AsoYIYS1R5M9qQyVzBGqYA5pDND+1Rm0rwvJeKilfwbiuSpOSOf1rl+XxufV+jp+LyLjbOI6NcQ/dBdy2/mTSFgHPAVO4GTgnPIHFRLVBfkubgJqMU5kSMgRGCXzGY+oglQOOpxjjklc+9YSRpF5K3SbeXT9Q0PTTGifd5HsZkB/dCdDv3Dd0DI2TnPK+xFRJ3bKS0i48P28e++1BLRES+uHu7fzDykTqCGOejHk4HYis3n/0af4bhpzQzWkVpc27LaM3mFIG25B6cD8Xt+VQnTK0sGuzTSRa+dOhb1tKV2YxlSeD8DHT2q2uyNPydMo7NfyLDHHCn/toE656DFe9xxpJM8OcrZVAu0mFJya2Mi+sYBFENw5NYydmsVRbWiDrUMpDxYBetSUYmuUhhJYjNACWm3qS3DeY2COlOSEmWE6ibO31UkNkH08LFuXrR2CimujIQUJIFWiWAs02TBiOKbdgkbHbTQ4BGKydlqg5lB9SdqQxuynVxjPNS0NDMrYANIbIO3p5PFAip1GZVZVX8VaRRLIopcDPPFNgIahZxHngGqjJkuKNZ1CGNWOGHFbxkZSRVAjcc9Ktkou9CR3xyQtZTo1gbeg/dBCOKwZoV19ZI4JC/nVJktGs39s4DYbPsK3i7MZJl7pu0WyqvXFYy2ax0WUMOcHFS2Oh8LiI4FTZQnOMoTTQjXXI+9Et0FarRm9jsQ3j09KllJljaQ+nmpbGhW6XMwXHemgZzr7e5mTwTHApPlS3cazYIwVAJ2nvgkL0rPlf6l8aycOsrmK3tI7qZnS3jXbMYF3uuDhVAHQ+31rlbvDNkvJtNjPpl0INInXUrKdb2G6H3uIJGzKSBHuUnaWPAz1Ix16c6t/yauks+SOpaPBr+pR3boVV5ZWuYiSM5jEZ3Y6YA69azk3BtM0VSVo2zxHp62/3C4DeXA9g9vFAsRkZ8soDKg5KqAQM4GcVkuRRzIrq3hFfpckSK1rBJcrdW8irPZ3ELQuFf8LAMOVPbHek/DWmUs2Z1dCuqTNtQ3Vsf3Mg5dQMtj5BJPBqY8ji0U4Jo3nS9RXV7OG6jYHzFBbBHB7/AM6+mhNSVo8OcXF0XenWWZ1ZgQKcp4FGJa3rxW0YdnUKenPWsrNaK2TxVpVlHK13qFpDHFjc0koAHek2NJnP/Ef29eH7ItFosVxq9yOAIxsjHyWPb6A8VDmkUoNmnat9vl7J/wDh6HvQHAkaQ4c9yAOgznjrS/KP8ZRL9umurNu/we0EYHIEjZOe319+KPysOiNh0L9pa5s2A1Hw2s0f8Tw3JB+gBX+eaHOwUUdEsP2kPA93GqXg1SxkKgsXtd6AnsCDn8yBSTH1Rvmg6zo/iOBbrR72C8tnPDxODz9OtaXghxosxpytIcH00rFROSyit03lsChWwqiME6tIRH+HHWm4gmHsZQ8xCcUmhpltIoEfXmoKBMCUJzTBlLsaS8Oa00iPI+5SCIkkZxU7G8Gnarc3MkzbdwWuiEVRhKTNeu5W3EMSD81uoozshYRPNIepUVLwVHJumg2+0qPesJs3ijY5I9gB9qxssBcEGI4FNCZrXk+fdPv4VK1ukZ1YLS7jbNg9KJIUWbJFMrEBayo0ssVX089KkZX3vAIHSqQma9NAxmJI4rRPBm1ksrWPZEM1LZSQ7azqBjvUtFJn17EAnmUJgzl/2p28mq+GL6KGQJKgEsZIyu5Tnke1VONwYoSqRxzw/bWejwXGnatE0mm6lEYJ7hGAZHJDB1PZgQpGf8v5V5vIm8rZ2Qa8g/H2nasNKgv21bRbqEzorXFqkizzNkNuZCNqkY5wSMnisuBQjJ1dl8naSV6Nw8M3FvdzXl2QUimuGkdieMk8r+R69qz+TyrsacPG6GdZTWtZ8ZeIrq0tLa+0XZBYrDLdrbvGIQdpjL+kgszkrkcsDWMnDkildNFuLh9ph5rSS8tL3/H4oprvU3iRIYZ96W8cYO1RICC8jFmLEengDNJpRiop2EW+16FZ/DN/oeluBqSppgRp1DsTNH13Jv8A8vzjNO+zTaHlYOI6f4z1PTdWe806fbFECIopDlM/5se9erBuCSOKaUm2Xk/2meMLyAB9RManBykYVR26+3Wm+V+xKCrRU6jretagq3F9qN5NvGOZSFVPoOAen8qn8jb2NwRqt7+/mCs5kLHG52JJJPX/AL1omZ0WMREEBtYgQxBO4E8fP9+9ZPLs0WAtzLlYoU3BgMAL1A7/ANaaQN+haeJbSQKedoy3qyQfbNO7FoYMUbw7pAEXHAzyam2iqTEhYr5JcZRc9WPJFX3I6DWj3Wr+Gr9dR0O8uLO6To8eMkY5ypyCPqKa5EwcJI719lH7QVsiiz8eTXKTHhb7ZuQk/wCYKMgfODWvYikzur30Ws2UV3YXMU9nJhkkjbKuPg961jSMpJ+RxSn3bbCMNjk0vIeAaXH3YKE5bvTqw0WIvGEW6Q/lU9SrMx3nmqdvNHULF5pTGCwXmmkSVs0r7DIzk/FXQMErCXgj1fSnoWyl1XRZnJeE8ntWkeT2ZS434AaPY3kBcSIAuaJyTHBNG0WUnkkOeNo6Vi8mqY6uomVCMZqeo7FbjUPLjYvgCqUbE3RWaddedclnGFz0q3GkTF2B+7lQHTOaLJotNLkZQGfOfmokiosuxeKUweDWfU0sBJtk5zgU9CF51XyiAOaoQAsRb4x6qBGdMRg5Mnc0SBFjqRBtDj2qFst6NDukWTekgyrZBBFdNWjDRyjxN4XmsL2BDepDo0j52FMHHXYW+vTIrg5eLrL6OuHJ2X2JXXhpZdQ/w8G4aJx5kU0mPTnnp8cc4rN8dOkV3xbKDS59SsEXw59xlXWEmMHkYw7EjIbB6qeu7PSuLm+PfJk9Di5UuHvZ2m38HyWVvDp95I8l1JEgmZVLKJCoG4t8Yx7HFc645QfUUuRTXYDq+g6lolzHJpl9Zyyhdr/eY2G9sclAuf5DJq5cfUiM09o0b7VdeOmaE6tOp1GeMxRrECoTPUjPT8/eq4oXJBOWDg8MXn3EEU4VpG/E+cE//L5/nxXc5YbOZR0jZNQgVYIYUJC5VckEMf8AjmueLt2dElgDrkam3WCHhcAMQcEADP55GKvjeSJrBqoVQscjE53GRhj8IHGPk11HMWSysbcMq7VJHPc49v8AtUqORtg7IiKYFxmRhuY/9PtVMSHDIrweZ5aksAAxXOAD7e9SkOwcsMb24klMhBG4ntS80PxZGSVVVdsY3AjOB/Sl1bKUkhuAfeoAxU89MKTWbfU0rsip1CyVDuwykdDjIP51rHksylx0bJ9n32g694Luh9yuZJLEt++s3YFJB8ccHp0rVS66Irthnr/wV4s0nxR4fTUdGuUmAAE0YyGhfHKsCOP9a3TUtGUouOx+3k82Z2BzVtUiFkO2+ZwD0pDLiwiVIiCOcVEmUirurzNyYUGatLBNmVtw+C36UWFBobcBzxSbAMYgAc0rHQvDGz5OOAadgZu4VMZxw2KExFNFOYSyfxVdWSmJ6pdAxlSfVnpVwjkmbBaYxUbz0FVMUTb47FRGpYVzdjWiLoqqdoAAoATeUtkDqKoRODe7DOcUmA+8WEzSsYBBufBximAWQpGuR1pAJPOzZDfhqqARS1Sa4yV4FVdIirZYz6Tb3Vm8MsYaNhyp9+1ZtlpHMtX0k+HrlYJXLQknynBJYDuST8np8Vl/JpsS07TFOvwa3b6sw1CC3a3QSIpHllt2D36/NZyp5KVm6xa7FdJmYo9yn4tgOOOuCevviueSjdmqbqjVfFPiC30/zZZnUXXAjkPKtu6ce2Pbn9K5ZtWdEE6OFeN7mXU9UJvztlB3SoTwoA4IPcY6VfHjI5o1y3hluL/zIozljkrjt2OO9aydRyZxVsevpFkCjfsQTBVJOQfn8+azii5MDq0v7q4RT+Ecs3O4nn++1awRnN4KG9tttpGoVSW2qm0+3UV0JnO0HClbq3iAA2rk4HBpgAuIijzSDgBcBemP9/rQB8wcQRxhiWYAscgkD2x+nzQIF98ciSJhlRgKp/l/P+lFeQssLFFEcpnO0KdrMD1PcD498f0qOTWDTjXsvdLhX7kJpUKJv2hcEcdOv+v9K5J3Z1Rqiv1RmFw0GQQTk5Pf61pB4siWcGv3UCxysICElGSBng57D3/Ot1L2YSj6Ng8EeJ77RNVW8024+7zYxIu4hXHHDDoc9qabhlBiSpnrvwJq0GvaTFqNpKrxvw4HVH7qR2/Ou1TUlaOVxcXRuKRBIw+OamxmLm68qNmzjihIG6K6yiPmNI/LNzmrfolIcDgEgnmpGPW6kpkDmpZSGHjUL80rHRXmTy2ZQfTVE2LPMJOFPNOgKSdXSd5GGABxWq1RkynZWmmLHlc1rpGZcWkIkQbfwrWUmapG2PKQMdq5zUTkfcCKskWijJkJxRYh62AzgUmMncyYwi0JDYvnac0xA2JdvigCEo5AoEM2UA37j0pNjSHZp44xheoFSlZV0al4xs3v9LmMcYkmj/eIv+bHaiUbjSCLp5Of6bPGpaYyqW53enGMDoPjr+tcTfs6Cqv/ABEn+KPbWpIDYQOcFPUMA/JBx+mPauScrdI6IwxbNU1O8+/TNBM4K2b7k3ndujbufocfI3Gs/DNVtGnzyxXk7ysR5SHywWPXAyFB/nWqTikiG7tgbOBY2JZfL85eSeMqDx+p6CnKVglQKRB5GwsPMR92GOOc9v76U1sGVV/LukVjtZmyDjOeB1+tdMVRzSdgbELKLaNgCqguMjGTxVkE4woklmOMseOM8Y68f6UAwUOwxSFhuDOWUEZzjp/r8UxCKMB5hcnDEKABk59l9v8AemIJDEEaSNtvmMAd3J2gg9uu7jA+tDYIsIbaGzEkczkxxvlyycs2eVUZ5/hzz/rWbdmkcF0oyiFtq4XAwDhFOcAe/HT6VzyRvF+ANxFBawnIzcDsy7vnB/v3ojkcmUGpoXkWfaDt5RSeGHuO/XPb3+lbxeKMZLNi01rFJ6o1kV8cqxxz1789KpNoTSeUb99jPjOTwv4pgiuZQmn3ZEU27pnsTnvz1rXjl1ZEl2VM9kC7V4FAxyOOa3owsSuYzIVPO0GqToQzkJtUd6QApkMb7veiwLS0mCw89alotMhd3BEW5T+dCQmyr8wlSfxZ71dEg7eFlkZ15+Pam2CMajD58BUdaIumKStFJa2siSFHB2561q5Gaiy8toVSLatYt2apUh4SE8GpoYLH7zNMQYcdKQGQ208UAYY4bcaABsdxyOaYGVHIoAzOmAMUkwMrNhcDiigIE5JJpgDl3NhccUCOU+PYLfw9rUQjkWFL0F4iRwrA+ofQZzXJzwSydHE2zQJdVspJlVJI2ZJA/o4A28kk/kPn9a89xzZ2J4o1u4uZlsdQuio8u5LKDjBA3AgcdPw/rRGNsqTpFVHBJLboHDLFnexJyHPye3firdJkLKLeWyhjTe8mZVXK55GD0+n0rNOzR4Nb1wyQh2iY7WI9Pv8Al7V0caTZjySaRRJJv3MyqwGcAD4/r/tXTRz3ZYx7Y5pXwMJDkZHbv/zU7wMkIGS0WMfix6z3APOB8/7UWIjIoVmUBQkQ9ee3HSqQhSUBbdZGiG8/+mnGAPp70woYmg+6G3uy0atCqttJx1HGfnjpU3Y0EtUuby4gBICIC+CoIRc9AOmSP1pPCKRsVhbQvcPKXKhSWRWyA2MDHJHX88DHHOBzytm8aRWXkYvpUkMkaQAhi7EZzjcRjOM9sdeABVRVbJk7YW1i+8LG0EVvFFkjkcFSSeuOwbAYdjUylRUY2VU0OJ13ZbYFR++Mk8HHtjk1SlaCqYskcXmRiaAyRSBv3UcoRg5BAGSCOuDjHI44zmtYszkj079gPiKfXPDcdhqF0ZrvTsRs0h9bJ/CT746Zrr4p9onNyRp2dmMMbQ8AfFOyaKrUPMimi2qTngVaJY22EhMk/GBSBmvm7ubq62xHZDnr8VpSiiE22XL3KGD7tH6j/Eais2aX4BXCGOJQvpHehCGNOQzDEY496JYGshmtGMpDdBU2FGGtkQHcOTRYADEI1LKelMRCJT1agA20sMjigCYdEQ7qQCb3H734qqFZJmaU4Xp70hhVQxr9aACRlQOetAH0jhgQBzSoACRMzZY8e1MQcwrjrikMUluCJfKAzjvVUK/BzL7XLFb/AFyxiuEzD93IVs9CW5rn5VZrB0jncvhTTIEIgMsMcmQSpJduCWP8gPqa8/kdbOyGdGveJSrCDT4l8vYNpOegz+I/yohjI3qiutlMsi2ihkfdgFu4A56fGf1pSwuw45wT1R1ktwVBQwjB5OOPcduKnjWSpukatd3YfeJDwWwM/wBDx/fNdkY0cspWV1m4+8zKrYVlJ4HUd8j++laMhFzaRqY8yjBZUBAO7qeT9agocuifMKrklcHcOnHAB980kDAXMQKrbkKuB5kpB4Yjtn+/inYhTzSs+ZFXdI+5OM4x3pgNabF97s91yoWIOCqHOSBkhQe/Tp9MVLZSD6pGxszGIsMMZJU5fIyM8ntjv70IBqBUFje2aySTTNGpjw4cjJUDjrkjIHtUNFpgJ9v3C22H9zETkBcbpByQDjkH2+D2xT0F2yx+8zWdkzJJIvqEaqg3mNSOTk9s7j+WBWTVs0TwLSxBmLKhLllSPC7mkYdCe+CRzzjke1Kh2JXlmQgaG3YHjgsd4OTgA/JB69AKuONkSydB+wbWDZeJYreYHyblDANxUtGxORzxkZ4P1FdPBKpV7MuRXGz08sz27Ks/pB6AmurejmLKRRPAjKBuWp0x7BSJFcwOknToaMpg1Zq96q20hETEKDjFbRd7MngtLBolhBA9R7mobtmiQ3H5UtrKJcF+wpWG0Rs5Bbw+o7cdqHkA33sMNynJpUFg5riDyBJPMB8A069AyuXVklLQxwOd3RyOMUU7DwWKqFJ3dRSsQKScbtqnFMBa4k6AdKaEyDqGAJHAo0GxmBlEfXBpDJmQMvJoATknaOQgAkU0iWR+9tngH86KHZiO8kz7/SgD6S5kmbYmQaEqC7CLbyJF5h5J/WhsKrJr/i/SZNSsBOqt59t6kPx3/lUyVoqLOW6jLJboJI4wHHpUnkKvfJPfHPHxXncsHZ18cjn1xBcuJrySRWFw5cOBgAbsAY7cCs1jBo85JHbDdh4VbftPlg/p/pUvKoqOHZSX+pylQZU4LYXn3+lbcfHRlOdlLexL92kMBYyRjPBzkfH0rdGJU6bIv35QMeWcrk9Bn3pyWBLZfQekyxNhMAFGPHBOMf0qPBbH23BTMzMSWAGADk/1465oELXBN1ZSsFAZ2Kh2PUDv+n9aNAzEb27H7zlGUSeVGxGd2DgZH0GfyxToLAO1xdefDbHbGCEU7Op/07jAoryF+B+wuN8dwPMdXWRYfVjdICpx8YyBz2OKGsgtGbeLyZZJlRlnm8p9o9IEYzuPTPxn5PfFJjWSwtbVDY3lnb7cwRB1m9OQoH4QR05PzzWMpXk2iqClI553RwrJaoCY9jESck4B6kAbj0BwDQAKdblwkhZkYhSk3LYxgjntjpge546mpKEb2B3szcW8s9tPFJhk2kD3Oe3YHr9KcbTrwJ01Yx4anMerfepLX7sUx5Mg/eBGBHA6Hkd8nBx75q3+tUyUeuNO1l9U0+zubiItIyBiT3OOtejHKtHFLDDre3DSsC/lqP4RVUibYU3biILnaCfzpUMrLuAzXqsWOwdapOlRLVuyxlnRoxHEuFUdazUadstu9AorwRNtBOaqrEBvL6GwU3eqXMcVp7u2AKTaSBLJrT/aX4W82NF1WJVlbai4OW+fgfJpKaK6su7F7fVJfNguUe2XvG2Qa0vGCOrvJZeZHkJEMk8CkkAe5ebO0fiNQhmbaJiQJeD3psBnUZLVQgGAR1qY2N0J+YhTOcrVCPnnjdML1FFALzCTYGU8e1ABUEojMkm0KO1AC8ErXU+xUwpPLVTjRKlbG7qNIFxERnvSWStH1hCQvmz429qGJBnu0J2orbfelQ7IXe7yPR6if4RQgZoninwy13E91bKu8As8Z6N/ftWfJxqWioTo5d4nWG0sJ/OfYSMhQm1V+B844rhnCmdUJWc8uNUOUkSJxNGm1WUEhsUKA3LGBVZU1CJDKzCdfWo75Hz+n8q0qjO7KycX9tK0zQ7ldvUK0VEFdbDzL2RwuY2GcZx3x+XNN6BGyaeGknyjBoyMqdo4PHJB7dP5VBRbTQr5UokOEQFRtHq56ge5NJgVRgmur8oX2xxoF2qDsUEcjPdumew6/FO6DYtKbOAebFFPdPE4G4EABPYAcde/NJNsdE3uJor+2QiNI0JLscgnGSAQOnbPuR8VdkBHCtKEkVpLNpEkC/OO5xnJB6YqdZKLqWP96LtAJDHhSeq7h6lBJ75wDj3z9M26waJFmFL3dqEmha4uJFHlOCAckl1bPDcgnIPBPesdGiB6mw/xBoEeQGVwXYnaMKrcHHB5bGR/OhaDyHu4AlgqIWFvCGV07MQPyyOe3c0IGUrpKtwDCFSYbNwBIXgEdPYqOo9xzVr7E/orIbm6tL4SgI8eeHA3Ng9QV689c1dJqiU2mepPs41K31HwlYfdQMopDAe+fbt/3rs4ZXE5+VVI3FLeKIkyZZiPwitLZlgHBa/vgbjGzqE7079BRiSNQ+wLyT+gosCOoG3srYyzyLGoxkk4+P8AWlY6OQeO/tj0/SM2mjot1cyEhXGNqqDjP1ODj9ahz9DUTjnjbxFrfiiRZ9TvHECnKWseQkSk9h3PyaycrZfWjTrfd5nLBR1Ungn2I+KGxo9R/s7WkieGbiS7LCORwUBBxj4zx+lbQ0Lk9HU2SMO7xHCr0+tWZBYo5HmeY5VR0JpBtkI0nuJdyk7c8k09C2Ykga7k2qPQp5b3oToHnBM2LtN5cIIjH4mPejsFeEQktN0vlxDpwW7Udga9Gb0CARwL6n7n2oi7yDxgmkIk2x7iT35pN1kKIusUN3HFGcJ/Ef8AShO1YPGENS2yTyAk7YB1PvSuhtWSZoZm27wlunH1oysgTaGKfb5XphXueM0Wwr0ElSOKLZAC0hPLe1Kx0DihgGc4du9O2FHPvH/ge28Q2s7KqCZf4Rxkd8Y71nOCkVGXU4lqWiRWEU1qsJRoPSVJ5BrjknFnRFpo0m40+GW6SaOQAcF17Ee4q1LAmic86xo6ttyuOh+Ohpogo7byfvsgibKOmFz/AAtu6VpQiy0jdG6xnjYwUE/yP9/FSxo3O6t/L0sPCTvPHPqwx7/NKWAWTUQsly06I4gs41ClsjJ+BnuT3NIYzHbpHYG3s5ZFCbgu0Zfkg4H1HxUt5spaE7ospWGRpZVQMA7sAo74xjg9CT1yfbFNAxzSHMcWzKLG6FnnYkFVxk4J6Ejj/wC3xRLLCKL6O3CxyrdJJ5Qk3CPLMn4cc49jhh35I4zWMmaRQ2S8kBBRLlo/3sOGJdTgsin8ieO2SKzbo0ooJEu73VriUvHlweG5APTBx2AAH0x71phRJV2bbHA0mj2kccqzzAFWKj1bwAdxHtnr/wA0rTdiarBrN+p3XrTKcKjJD6fSnJwVU8kY3HH0z0NWvBNlBrCW8iSG2hlDRtlZEDD4IP8AkJ4GDxWkbsmR1f8AZ58bWttqp0u5mfz7rEUXnZCs3YewPOBjriteNdZU9MmT7RtbR6GW4e0kciLzZXPU9BXTVnPdFjCES3eWQK8xGfzqG80VWLNL8U+OtE8KrF9+lEuoTybBbocsuBk59uw/MUpPwCRxbxf4t1HxPf26zgrazI06QxnCoMggnHcAY+euKxcrNFGtnIfEGjPZ6gpibc+0SSqqkLHnkKCeTxjn3OKaeBVQ9p9wl1bmF2ZznG0rgZ+e/wCZpMpZOn/Zn9kp1aYahrcrW2lqdw7mX4AI61pGF7FJqJ6J0jRLPTLJViEVpYqMIgPatbrCMnnLCS2a3R3RSeXbk4Vs9aLFQSTUd8oQpthHJ9zT6+RWGuL4NB+5AjTp80lH2O/Qt98JQCIhAOvuadCsanuDNaDy5RH7461KWR3aFh53khUIC+/c1QhdOSwdgHHU96YHzkgqImwT2FAArxWGA52KB1oQmN2l03kBNu9B3NJoEwaopuQzjdk4AHQU/AeT68a7F9HHFIDFjJCihVQndjr3Epj2qMDoc9ami7At5YX1OU9wDTEfQqpZiDtHb5oYHPPtL8PJJZXWpwYVo4yZFxy2O9Y8sOys0hKnR5Na6uDJIqxP5PmFQ+Dlc9visqVF3kzeWzWpDNdEBupLZPvgc007EyvmljEjm2PXn6fPxVoRcaHeRz3sC/h81thUnOGPAz8dKmSGjrsPhy/g0qY3seFByBj8IH9/pRKDoFJWcturW4uLuPTbVxEItzzMOBuPX88VC1ZTD/drWyhSGGaSW5l3AJFgvJ7tu+vGD7ce9J5BMakFpcW8nnTmKQeoxRpvQIOqk/Ujv2PxWeUabDwIYMsLqCWFkEqsigjcSV4zwQOPYZ9zScilEvrRGE9vFKVkhaQbpBnCsygkdgRk8Z9vyrBy2aqIaeC4aG1igkdYyXUeW2Cgzwp6gjG3nrj6mknY9AJYDDkqi/PPvVuyVQHw7fCC9uEn9RcbYyOijnJxjnn+eKqKwKWRa4tA12st1GI1tX4Rs4kYYyBn3x/U1qsIxspbqWfUGmngMhMjfvZckDLc+r3GSfV3wM06rYjWLwLC6i2lEz4J3pkEDjrzWyzszf0dq+z77f3stNj07xjZ3d7JbIFS/tcNI6jp5qkjJA/iBye4J5rZT9ktWWfiX7dpLnTb1/CunyxRrGcXd4ByThRtRT7+5544qJTEonnm81a+vtYkv76eSW7kkMjs553H+/5UqK0dR0+5Gp29gnm7jHgOiDBdiBtJb2AGMH3rB7Ni5sNJGty+UfMm3ZCq5wvyR2+mMY96EFHQ/Bf2R6ZZXEd/qkUDTp6ooiMBB2z7/SuqEKyzGU6wjpLRboQcF0j4BA9IArUyYxBAl26rPIWXrk9BRoNjRWIyBY3ztOBjoKQCaMqM6lc/NMQtcqzKdjVSEyFhEYGLSncxpydiiqDtcrIphYYz7Uq8jswrPGAm47T0opMNAzHmTJUkimIO5yBHHw4GeO1IYWOPdb5mBdhzipe8AtZPovMETEKAp6ChjC29tIpdlPqIobBIzE/kjeFy/SkAM+Y0o3th27DoKYH0tqIZfUxlJ5oUhURSWaGYnZ5gPAHZaMNBmzSvtl11NJ0CO2aaNJ74kMSQAka9f1JA/WseWXVUjWCt2zhdlbafJpN3c22GlLGafHII6AiuV20brZz7VPu9/eNhiVUY2j+GtI2kRLZSyR+TPtjwvPDH+VaEmw/Z/avc+KdLjjCEy3KjLjcu4f8AcdD1zTA9oNp0NxbyWuVdyoQ+w4x+lbtYyY3k8y/at4fuvDGp3EcRKvcuyxN0DhsZ5+mRXI49XRunaNMWKPTWjjBEMhCiWZ2A6jk568fHfpRdj0WkmrabbNKryzyxl8GRAUJOAMlfkZ6HPfvWLhJmqkkXmnXUNsUjMb/d5HZjuIjPvlQx45I69ckdK55RbNoySL+302IQNLG/mWdxL5pyPcjj8vUMfSs4pydFyaSsGJEslAXkszMQ3fIHf8q6Ix6oycnJlNd3BuFRmbiR8nHGM/8ANIdCtlF5l2gBIVztJzxnuP8AX61ajZDkbb9oXheaxtoroBmtn8tpW255HBJ+P04Jrolx9TBSs5/qK/4jrkdlEfLtUQKzrgDaWPXPGOM5981K1Y/opdfcedHZWsSJI3AKuT6QTj6EjB+h7VUfZLKjVYHtxDarFsc/i4wWOehPfmrsRuen26QaRbozxqsSMW3MpwxGMHpyecdc5GKybyaVgp9R8KSRAvEzy5GIgq7c4IGOmcgduuOeaa5ET1oL4dTULPUkiljTazZ6KUU++B2+mKGlLRUW0em/AuhRx6bFdzpHLLIAcR8R+/51tx8SWWZz5PCOhxRw3EWLlDEcgKue1bN1oz3sdl+72eUkJ8g/hUd6m2weBi3ubRLPapRfak7Hiij1qX7nDHNA+XJ/CB1NaRzhmcnWUElkijZvMYD2ApFAdglG6N8k9Fp3RNWRjim3klN2O1Fjo+EG5uIiH+aLCkNQ6dcoFlbB56Gl2TCjFyZzMMqqGhDFzG25mUnd3agBmBJCMqSe3vmkBO8gliQFty8cAULIMHppllkPmkqo446mqaSJTbGZlRQW3YUdeaRVmIZEL5IyooaFdkzdQtkIoBFKgsgsiLGwjA5Oc0DOFfbs8N3rKW86rIkduow3QZJNcnyZVJHRwq0zhemyLY6vHbmRfukpMUgAYYVuOOcEjNEf2QpKmJavpN1Z39xHZxMsCHAYcEimpWsiaEVtbl32zegYzuP9f5/zq7Ebj9j1nKftI0JInRiJtzK3RgATn6+w+KcctCej2C5lLHIC564HWuijI1zxx4XtPFWnx22pAs0TeZDIvBRsdf6UpQUkNSaZ5m8UeF7mx8avaalbsscUe+MtzHKAcE5rjknBUdCalkqVgvNkS2qRtOymUnOwIu4kDJPXjjB5AqG15Gr8BbZLOKGL77sJ2eaWcByc/PX8vntUO3/JpGl/Ru+g3NmPD90LI4jiKk7VOPV0wOgrKKkpZLk1WCuvtQQwSMPWFTJIPBPXGf771TjYk6Kq+WW1jXEkWY2wpUnDp03KTyRlWz8cVURSbH/DIdtStDFAZYPNDFFbBfJxj69MVakk0ierZ6ouNKstS8NSQThN8icCTja2OOB84rtavBy6ycI8afZzcWGoyT6fH58EqgnaDhdpyAPf3IrGXG4lxkmc5vbI2+u4WJjNPCUjdjgRnPfv8dRxUJ4KrJnxH4fTUPMuLWTZLEod1GSFwoB47nOORxzn3qVOhuN5DeE7s3Ajs9Qt7aOeH0208ahTgjpkcH8/c0pryi4u9m7ad4YZbjfGn49rKMFiBng8d+uT1+tRd4Ko6j4V+zGxtGW/uLdDNwd4cgZznIxjmuvjhWWYTl4R0NrSKAqB6Yjgknk1tZkLXKvPIZLdsIOAxpr7E/oLdSebHFHEAzgdX6mhIHklKsSW6xkDzG6vjofakBJtMhhjFxKw3AcAnv70dvA68lNNctPsSNM/OK0SohuyVraSeZveUg9gD0obEo+yxRRG2fPOfrUFhw5BB8wUgCPduy7TMMD2pUOwHnKHBLBj80xGTMOcqB8UAfRShPwLj6GgCcs7P1Ut9TQAN3KkeWBnHNAAXSRzlgCD2p2FH2yXcB0FFgGlt0XmFz85pWAIQNg+rFAHnv7brgW/ijUCZARGqKBnphR+tcfPmdHTxOo2cGkuUkuCZC6xu4O/3XPJH/FapUZtm3a8x0+GOe4vvvMc8aSwYHLKQcH+WPyrNr9qRSeLZqP32aaSSRQIoud21evwauqJOh/s92dzN9ptldQp50EEckkzDH7oFcZwfkgcfrVw2KWj1k78gnJroMgMkrgYCEjtRgWSu1jRrLV7Yw6hbJMCpXJHK59j2pSSkqZStHAfE3hoeD9Z+5BJJ7UW4lgdlB3YOMcnqMniuDng0dPFI554hn8+8lKD059GRyo6jPseaXGqQ5u2b39kmntrMPiCxEb4eySVT1y6OCR+eSKaj2lX0DdRv7KsLc6kx+5whLSBjGzMPxHIzj6YI/OsZNR2aQTlkFeaXE8j3TykxCcqg5y65wMDtgZ/XNQuSsRL6J5Za+FrZpNVsY7e+gZC2djgDaM9xxnpt9uacXclaG1SwendPtkSCEOD6VGQW3YNeusI815ZYTyxyJsMalcEYx8YpUBqmt+C9F1SUSTWyCRQQGXgkE5P86l8aZSk0a/H9mFpvVhcP5iPlW6ek4yDjvkde9YvgRa5aJ2v2R6D5gmuPMaUMWyDjOeoPuPrTjxVsb5PRvulaXpumW6xwxocfxba1UEtIhzb2PyXUZ24JwOnsKqiAEt4mCXJbPvQkFgLIGefbFGEibkux4pvAIvdO0u1+8eb5qvMBjg9KhydFJLZbLpFu6nem4nqajuPqiB0G0JywY9+WJo7h1RzhXmI9JC10mNBV3Yy7t+VLAwqS7TwuT7mkMOZsj1HFIZISx455pAFjki7Ak/SgAyevnac/SkBMwqeCMUASWAHgZoAkLUZ5BoAmIMng9PmgCYtRkZJP50ASWOEHBIJ+tAExFEWG4DHwaQHkj9o+EweOtRVmKwSMspDZyVKggD865n/AORm6/hHJl0nUJWsgluXe9z5Kq4JbB5yM+nr3xxz0rSiLOmeM9Dhk8O+DbmcBpTosfpB6kO3X3wCBU8lxa+yoZs0O4WJV8pwDgnCL6QP1/rSQM61+zvpsH+NS3cWVMULEOq5BJIHX2q+PMiZ/wAnoYSomOc10UZWSFyh425NFDsIsoJ4iNKgs539uUUcnheCVkfek2AqpuyCpzkDr/3rDn/k04tnmW8Zmcjq6kqzAnHuMn36/l9Kxias7h+zRZOLnWbtwFVIkgA98nJ+nQ1XDnkf0h8uONfbM+NbGOx1vVLOCMQxs29PYBueP51x/LVTNvju4nPNQjWzt5oHZ32tvyTjGQR/U1EH20azVbLLwLp8cviLR0SKYr95UbBLucnp1B9utaxbc0jNpdWeoo7SfzBGmHHXg9PivVs86jEsTxSlJFOfinYURRuc7RQB9v8ATx1oAiHJXkgjpigCG5y+1Bk4yc9qYENsjAkqQKAMiLzFG/8ABRdBRMWqM2WYsF7dgKOwqGLJIrZG2yupJyccUm7GlQ9HqWzkTTke26pcUOz6XXJS52NIMds0dBWVMsEECFnGW7AVoskt0ZtvMkg8tvRATyo6n86GkhJsfeG3SIDylIx1PWoLK+a39X7tBk+/aqQmx63toYlJnG4YqWBGRRI+2BNkf+duv6U69hd6CBNq4DEkdzSGTVX/AM3P0ooCRVwhLvgD2FFILPrWPzizksyj3NDwJFtDFD5QCglj2CVDKFJ9LluAdpeJO/qpqSQqsPb6YsKeogn6UnIdDf3ONEyUycdalyHR4z/aP8y7+1HUraWeKG3aeOIOSWEaqigkgZPGaxSubZq8RRze3eQSK/3lJEgBniEzhXZcgAYycscfhz05zg1qQegvtN8O3GnfZF4W1S9jjQ2tvbx3SxpjyFlTjH/xO0Yo5P2ivoIYbPOt9EYJmaCQTyOwXcTkYP8AfWoQ2d2/ZzCS6nfWcgYyJaLIzKuFTL9PzyPir4sNsU8o9Ax2UZAVQuT71tZnRCS1EJ/hJ+KfYVGQrnhQAPegZzj7edsHhazWWQ/vLgkDdj8KHnr9K5vkv9UacX9Hm6/yLqRZGYRqcjuG6Ege5II5x7VhHRs9nfP2bLUReFdQnVDNPc3ARCpznHOSfqa2+OrlJ/4TzyqMV/prP2k6qJfGl8wljEUbGElG4IUYznucg1yfJfaTo2+OqVnNfFN+l9bJFEGDD1s4HyeCf75qeDjcXbL5p2qOn/szaEb3W73Wpy8i2KeTESuAZ5B6iT7qn/8AfxXdwwy5HNOVRr2eh5LUZ4dkI/ymtznFpLYk8yMT7d6YEDEc84GPcUAYwGIBkG48YXvTAyIAjbejdM0gMiPaCVwSO9AEfLkIxjApgSMBA5Ix1+lFgR4BIHTpQBHBI9hQB8y7fxfpQAKRgqjJBzxTEQKsXbMcjHdgkjgH2p2KgqmYsGC7Yx2xUjGBcQuArMu72HJNSMVfUrSIlC0zlc52xMapJsm0M6Zcw3aNLOJrePO2MOuC5+lKVrQ1T2T80tcOqK2FIyW6Y70h+QiSAquxd5PJfI29aLAYjEfl72njBJIG3+H60uwUKzyRPgLcxOTjKn04/wB6pNixobspnWHYmw98gcc9PpzUsaAx+I0hljA9TEhWXZ37jilVjsvYdbjklSBYQ0jjIVX5I9+ajqOwseo2jyMkhdGHQFCfy470UwslLqNuo4V3i7uBwB+dS0x2eTv2ofDtinii08Q208zadfuBdrGATFKBg4zx6gAeTjg0q6u35LvssFH9kXg6fx740tr7VLWO38K2RUXO44jYJykSsRmRmYZY+xPI9IrTLyRo9V+PLGy8T+C9c0uW4j23lrIqt1wQNwIHwVpNYBPJ4Hv7b7s5NsuxUKlgF/ET9TyBWcXZbVHav2XpTLqfiFUcvOYLf0oMKBvbjH6VrAiR6DAij5nuFVccguAM1paIJWzW7NuhlSUf9DbqE09ANGSKIhZGCuezcUAedP2rdaW2vdEtIDumktmkOeiqX4/XFYci7SRpB0cJj1CWRWZwI2cY3H+Iew98kH+xUdaLs9J+DvEKeF/srtk05ozf3ZIizyETaN8nHyeM9/pWXFyOMZe7NeaPZxX0cn1KOfU74w6fHLcXihikEZDSSsFLHC8EnAJwOTg8Vgk5S/01xGJrGj293r2q21jYwl7ueRYo4wp5YnAOPjvn2NdUY1hGF9nbPZXgDw5beDfDltpVlvkEeZJZnHqllb8T47fHwBXYkkqOeUrZtqKTDvyBu/iPagQswG5iv9aYiC+UdwLqzY6e1FgSt4lllZYNpKjJ5A/nQ2CRiaJ45cSKVI6ZFCYBABtCoBjvzmgDDRK2DyXPVs0ADmjDKFOFA9upoQC4tmDk7i0fPA4qgBta7s5Zs+4c8UCJm3LCNT6Qo7D/AFoAxDAkLSZIYuMerkj4A7UN2CNkmswofAYbhzjoR81imWUf3eFQEkBDluQTlVHatKJskunQgMY1ijaQcsCQ2KWQwfX1gPKCGLqQRI3Uf7Uk2NpUL3bXHnAOdmwD1FPjr37U0AvI/mRHzpY2DHHrYgqKSEAtbiysJFliQ+jjjLr9QDVNOWBYjkPaztqk5fDBWY7pQo4+g7fWjr1QdrC6pZRpDHHNGpySzSqDnGejGkm7G1aE02RALaukag7vKjLbD9fmhu9hVaHpMyDEDLHgg9AFY+5zS1sZP7w0Rc+e7yY5ZcLx7CirAClxIZ/U8u1lJyuTtx2/4pNAZ2vcIyKXZCQpDkkfPAphRLUbSxYbJxDcwjACzwbunTjHvU234HoDfyOLLyXnW2t8ekMQFJ7gAirWXZLwUOv+LNO0LR7q5fVLY3v3V1gt3cCSVipAAXqMms5ySVMcc6PIPiJJI3ZojkY2knPbvjp0HxWMDWR0z9l6dLfxTrNvPAN8+nrMGfvskH8jkHn2FaReaRMliz0FPcxSFkZ0e4YgKuzBY+wJFa0vJnfouNLhgiRJLhmDFsshChQvdgByTnqahtL+Sv8ATUvGnjux8ExHzriKd7oyPChUGR1HBYscBFzx3+KJySWVkEn4Z5G+1DxLdeMPFE2szpiIosEezJRFXICg/wB5696hW8suq0axB6A55zjGKGB2Tw9dTJ4asoL+NoJ7eFkMbghk9WcsMZGeK4eX9W0jrj+1P6NF8UXcb3kaW8gEq/vGkVRuD9sMDwTx9MfNacMWssz5ZJukdx/Zc8LqFn8Yaqs+yQyWunhlyJT/AO7MCef+nPvu+a64xezFypV7O/LfWgcxbnjtgvCoBlz8nuat2Z4J7oJbj0XUVvEi8GYhm5/6en59aMhg+kS0uLZbfTZoLqVG9UjrhBzk7j/tRbWWGHhBl02Muwea0igUZMcABJP+lH5A6i9nprTl5gkzw/8AtbVXJ9+ppudYBR8k76ymtYo3MJlc5Cxphm6fNCkmJpoSW0v7vBkt5osDqwC7R9arskFNkUhv1McccJbPAkRWZRj++tFoKZFVnSVxc7w0eC25dgGew96LVYCgri48rzoYSYxx6hgA/JNFrTCmJS3V9Exb/DJZEXA37wA2f8vPP5Va6+yG5LwG0q4fVJZoHtbi0dMZWZSjOD3GcYFKS65sat7RsVvYxptBWOMYwMEc1m5F0VV7qE8xIiGz2B5qkktiZSTWkruXnuGxjnjFaqSWkZ9fbHbe/giJEZ3A4HPPA+TUOLY7SHYtQRyUiidoz/mOc1PVoqxsaq2NjWkeQMHLdKXUdiczpIy/+XQFehzz+tNIRhYISxY28ak9h0pgWFk9urqsq7F+Omal2NF2kCugKsrL271lZVFJeeHYixKJkHoAcY/3q1ITRXtoUkSqAuCT25/4ppoVAPuE8eRi3ePeSzvlHUewHIPPxTEA1ewvrez8/TZ47p0IMsWxt4UfiZAPxHHbGe/PSiLTdMbTrBrsup317O40YvfQoB5kc1v5ZHwTgH9K0UEv7wZuTf8AI81/qk1kmbW3srsFMlZJHJXPIIIO3Ax71PSKe7RVyayB1Cy1zUtHuYvvelxXUisscjrIxQkH1cL1Gfb564qZJV+o1fk5ZN9i+tNh0v8AT2lB3K370/r6c1z/AIpXho3U4lbqX2HeLLm4BXUdFht3YuwcTk4z1/8AT7jPGf8AenHirbE5rwbn9nH2T3HhXWL3U7/U4bm6mh+7xiNdiJHkHkEk7uABjgD3q4xURSl2OlRQSQxBYvu7oWyS0hLNj3z/AKUUTZhXaB55ttusj4BfJYqOwH/FOmFnN/tZ+zT/AMcXljfDVUs7mGDyUVE8xW9W4bh1GCT+VHWwTPvAv2Wz6PNex3d1BfaRdmNZrNdOEcJZUK4G+Rl9WRk4zwMEZNLrjY7zY1B9jnhO2Bkg0BjMvmfvpLh2EYZdvAY4G3qp7Nz8VLj9j7fRr+ufY3ol5NLJFreq200q7SseydRjg54U8jGSWyTlicmj8SH+Qt/Bf2b+FvD+iy2Oo6BZeILh3Zmv7q22SMrdBt3HZj3U/PBqnF+Bd/RudrJHZafb2FjpohtIYRBFFJOSsaDhQBjij9hOmOJcL5cUccaQyKAHJLNvx1J9s005eROjPmujyfdp0cSNtxMGOF65Jz/T9aeWLCPvNd7uIuw2gbNqgBB/1Y/l/vRkeBq3NxGpeS5S1WYFSYogSfb4Ix+YpZCgcs91DM6C7mlj24C7GQD2GM8fWnV+BCkkYa9BuVmleT1Mzs3pwBjkH25xj4+apXWBNItlubxrVULb0K7d/mbGRR0GOhP15qKyU2BnubgQARzXgKAejzzg/H54p0IB9+1NpswWTl5CN8rTejj3zk88cimo+2H+F3Hb396haPf0AUXMu4LwMnaCQe9ThDoWutOWd4hPetC9s+VwqgH5zzgd8flVJixsObgvKkVzLFfW0eWDxpkrx1x1z/LmlXlBfsBfmOWQmBCJOAkaqV3KP4vamrWxMJOLhkIhjC56k8k1aryIqbywu58mV1jU9cnOa0jKKJcWxNbERygTTCRB0RBVd70T0otbWWUKQkYUHgZ7Cs2UhiGKXkk5J+KTGhmOCQ8k8/SpGFW0f6596LAkbSbtgUrGFhjuIMmNip+DSdMB2HUmHoulI/6lqOvoqxvNvPypD0ZAGLeIZO3gn45p2IG8cAUs64HuGxQBWTXFuf3MDygg8kDOPrVdWKxO5WP1PJGbgAerD4GPp1poQSLzGtVjtLWLyySQijgfPNH+jBGzmDSCSNUkf1BmGAvxgf1owGQVjZ3lzcSKzegcLuUhc59wemKHSQKwjWEsEZe4gVZA5LKr7l2/GeaVrwANJbfzSkUU1vcYyZgw6f5en8qbixWgE9nJdMAskkb4xlT/AL5xQsD2F+5wi7aaW2lYsArhpN2eCDgduvPei3QUHa+mQCK3jaK2BA2AAHA7Z/2/Wl1vLCyV1cwTQENA5Bbo5DcY/v3pdXY7K42czyrLBEVgBBaMRhg3/wBvaqX2LJKex3YbyYIsk5V59xH1osBY28Hmui+tgvJ83I/MY/1pgShsyxchcrGM7whwaAAJNFE8vIyPxexP0p0xWT3hgcRiYkdEAz/M0UAbRN1yZfMga1ii/CpIJJI7YOBSnFIcWOsHcZR8sBgArgdM4JpVQ7MRFmGHhVnxgFnx27Y6UUKxmO3jVlMgUIqkhVUEfnk80DEyIfvax2sqyXTcKr5AzjOD78c06YvOCamKLJugQqnaREgwD7cfX+dKn4HY47WCjYY51/zAhUqaY7RX3yRXCqsUUionKrJLyD71UU0S8icsV9I6mCeGJVUBWjGCCM8+5PNVjyLIrPaapO8iy3sxj/EYWkOw++4dD7+1NOK8EuLOhRxLgcVjZofS20bqdyg/lRYynm0+FJTtGM/FWpMTVE47VOKLENR26ZpWNIZjhUUrCgyxKKQwqxikB8YV70WAN7aN1IYD2osCruIjaShoXINVdiYLz5XJV3Y/Q4p0hMG+DlzuJ/CctnNOxEPKRXBI3KeNvQZ96dgQuG8rCADDAk8ULImxWDU5mv1jT0Z4yKbiqsFIflnlPDSEjpz+lTRRGSSW3LRrKdo5wvApUnkBC5mJIZtzHqMtwD1qkkIjbo10yhnKDGfSKbwAWW4WO5FuqHOAN+7mlV5Cy1SE4lDuW2bSO3BqCqI6hBGLBpUUBtuRnnn3oi8gxKwst9x92aVi2CxkI549varbrIki6i0mJohI7uzMMZNZORfUrpdJji8wrI2FOAABVqRLQCQRRhUaPcVG4tnGadiE7p97LGqIqOOvJYEnrknH8qaQgCP5cjSIqbugyMgY9vrVAV+pXbwKx2xmSUgbgoG0e3H9aqMUyW6LOJY1WCNIkVWIU4HPp7596zbyWsobubgxLtRF6ZyfgUkFgrBnuEYs+0g/wihug2MpEvnIMvnfjIPxSsYd4Y0jDIGBUnBzz+R7UKTChbyAtwj7iWOQaq/Aq8g76JINzct5eGIz+Ie30oTE8ZGLBGvtMW9DeUnOIQAwGD7mlJ9XQ0sWDtnLjzW5JwTmmwQWONbiVwcgEHvmlpCP/9k=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for image_features in parsed_image_dataset:\n",
    "  image_raw = image_features['image_raw'].numpy()\n",
    "  display.display(display.Image(data=image_raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read and watch search rank tfrecord data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-02T03:46:44.421785Z",
     "start_time": "2021-08-02T03:46:44.414184Z"
    }
   },
   "outputs": [],
   "source": [
    "filepath= '/hdfs/user/ld-jiahua_wu/sq-rank-service/enc/combination_unified_v2_2/train/list_tfdata/ID/20210712/data.tfd.0115899577788536205463366997816311623391'\n",
    "\n",
    "rankData = tf.data.TFRecordDataset(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-02T03:46:57.340828Z",
     "start_time": "2021-08-02T03:46:57.338031Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorSpec(shape=(), dtype=tf.string, name=None)\n"
     ]
    }
   ],
   "source": [
    "print(rankData.element_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-02T04:06:17.915323Z",
     "start_time": "2021-08-02T04:06:17.854183Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features {\n",
      "  feature {\n",
      "    key: \"i\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 0\n",
      "        value: 1\n",
      "        value: 3\n",
      "        value: 4\n",
      "        value: 5\n",
      "        value: 6\n",
      "        value: 7\n",
      "        value: 8\n",
      "        value: 9\n",
      "        value: 10\n",
      "        value: 11\n",
      "        value: 12\n",
      "        value: 16\n",
      "        value: 17\n",
      "        value: 19\n",
      "        value: 20\n",
      "        value: 22\n",
      "        value: 23\n",
      "        value: 25\n",
      "        value: 26\n",
      "        value: 28\n",
      "        value: 29\n",
      "        value: 31\n",
      "        value: 32\n",
      "        value: 34\n",
      "        value: 35\n",
      "        value: 37\n",
      "        value: 38\n",
      "        value: 40\n",
      "        value: 41\n",
      "        value: 43\n",
      "        value: 44\n",
      "        value: 46\n",
      "        value: 47\n",
      "        value: 49\n",
      "        value: 50\n",
      "        value: 52\n",
      "        value: 53\n",
      "        value: 55\n",
      "        value: 56\n",
      "        value: 58\n",
      "        value: 59\n",
      "        value: 61\n",
      "        value: 62\n",
      "        value: 64\n",
      "        value: 65\n",
      "        value: 67\n",
      "        value: 68\n",
      "        value: 70\n",
      "        value: 71\n",
      "        value: 73\n",
      "        value: 74\n",
      "        value: 76\n",
      "        value: 77\n",
      "        value: 79\n",
      "        value: 80\n",
      "        value: 82\n",
      "        value: 83\n",
      "        value: 85\n",
      "        value: 86\n",
      "        value: 88\n",
      "        value: 89\n",
      "        value: 91\n",
      "        value: 92\n",
      "        value: 94\n",
      "        value: 95\n",
      "        value: 97\n",
      "        value: 98\n",
      "        value: 100\n",
      "        value: 101\n",
      "        value: 103\n",
      "        value: 104\n",
      "        value: 106\n",
      "        value: 107\n",
      "        value: 108\n",
      "        value: 109\n",
      "        value: 110\n",
      "        value: 111\n",
      "        value: 112\n",
      "        value: 113\n",
      "        value: 114\n",
      "        value: 115\n",
      "        value: 116\n",
      "        value: 117\n",
      "        value: 118\n",
      "        value: 119\n",
      "        value: 120\n",
      "        value: 121\n",
      "        value: 122\n",
      "        value: 123\n",
      "        value: 124\n",
      "        value: 125\n",
      "        value: 126\n",
      "        value: 127\n",
      "        value: 128\n",
      "        value: 129\n",
      "        value: 130\n",
      "        value: 131\n",
      "        value: 132\n",
      "        value: 133\n",
      "        value: 135\n",
      "        value: 136\n",
      "        value: 137\n",
      "        value: 138\n",
      "        value: 139\n",
      "        value: 140\n",
      "        value: 141\n",
      "        value: 142\n",
      "        value: 143\n",
      "        value: 144\n",
      "        value: 145\n",
      "        value: 146\n",
      "        value: 147\n",
      "        value: 148\n",
      "        value: 149\n",
      "        value: 150\n",
      "        value: 151\n",
      "        value: 152\n",
      "        value: 153\n",
      "        value: 154\n",
      "        value: 155\n",
      "        value: 156\n",
      "        value: 157\n",
      "        value: 158\n",
      "        value: 159\n",
      "        value: 160\n",
      "        value: 161\n",
      "        value: 162\n",
      "        value: 163\n",
      "        value: 164\n",
      "        value: 165\n",
      "        value: 166\n",
      "        value: 167\n",
      "        value: 169\n",
      "        value: 170\n",
      "        value: 172\n",
      "        value: 173\n",
      "        value: 174\n",
      "        value: 175\n",
      "        value: 176\n",
      "        value: 177\n",
      "        value: 178\n",
      "        value: 179\n",
      "        value: 180\n",
      "        value: 181\n",
      "        value: 182\n",
      "        value: 183\n",
      "        value: 184\n",
      "        value: 185\n",
      "        value: 186\n",
      "        value: 187\n",
      "        value: 188\n",
      "        value: 189\n",
      "        value: 190\n",
      "        value: 191\n",
      "        value: 192\n",
      "        value: 193\n",
      "        value: 194\n",
      "        value: 195\n",
      "        value: 196\n",
      "        value: 197\n",
      "        value: 198\n",
      "        value: 199\n",
      "        value: 200\n",
      "        value: 201\n",
      "        value: 202\n",
      "        value: 203\n",
      "        value: 204\n",
      "        value: 205\n",
      "        value: 206\n",
      "        value: 207\n",
      "        value: 208\n",
      "        value: 209\n",
      "        value: 210\n",
      "        value: 211\n",
      "        value: 212\n",
      "        value: 213\n",
      "        value: 214\n",
      "        value: 215\n",
      "        value: 216\n",
      "        value: 217\n",
      "        value: 219\n",
      "        value: 220\n",
      "        value: 222\n",
      "        value: 223\n",
      "        value: 224\n",
      "        value: 225\n",
      "        value: 226\n",
      "        value: 227\n",
      "        value: 228\n",
      "        value: 229\n",
      "        value: 230\n",
      "        value: 231\n",
      "        value: 232\n",
      "        value: 233\n",
      "        value: 234\n",
      "        value: 235\n",
      "        value: 236\n",
      "        value: 237\n",
      "        value: 238\n",
      "        value: 239\n",
      "        value: 240\n",
      "        value: 241\n",
      "        value: 242\n",
      "        value: 243\n",
      "        value: 244\n",
      "        value: 245\n",
      "        value: 246\n",
      "        value: 247\n",
      "        value: 248\n",
      "        value: 249\n",
      "        value: 250\n",
      "        value: 251\n",
      "        value: 252\n",
      "        value: 253\n",
      "        value: 254\n",
      "        value: 255\n",
      "        value: 256\n",
      "        value: 257\n",
      "        value: 258\n",
      "        value: 259\n",
      "        value: 260\n",
      "        value: 261\n",
      "        value: 262\n",
      "        value: 263\n",
      "        value: 264\n",
      "        value: 265\n",
      "        value: 266\n",
      "        value: 267\n",
      "        value: 268\n",
      "        value: 269\n",
      "        value: 270\n",
      "        value: 271\n",
      "        value: 272\n",
      "        value: 273\n",
      "        value: 274\n",
      "        value: 275\n",
      "        value: 276\n",
      "        value: 277\n",
      "        value: 278\n",
      "        value: 279\n",
      "        value: 280\n",
      "        value: 281\n",
      "        value: 282\n",
      "        value: 283\n",
      "        value: 284\n",
      "        value: 285\n",
      "        value: 286\n",
      "        value: 287\n",
      "        value: 288\n",
      "        value: 289\n",
      "        value: 290\n",
      "        value: 291\n",
      "        value: 292\n",
      "        value: 293\n",
      "        value: 294\n",
      "        value: 295\n",
      "        value: 296\n",
      "        value: 297\n",
      "        value: 298\n",
      "        value: 299\n",
      "        value: 300\n",
      "        value: 301\n",
      "        value: 302\n",
      "        value: 303\n",
      "        value: 304\n",
      "        value: 305\n",
      "        value: 306\n",
      "        value: 307\n",
      "        value: 308\n",
      "        value: 309\n",
      "        value: 310\n",
      "        value: 311\n",
      "        value: 312\n",
      "        value: 313\n",
      "        value: 314\n",
      "        value: 315\n",
      "        value: 316\n",
      "        value: 317\n",
      "        value: 318\n",
      "        value: 319\n",
      "        value: 320\n",
      "        value: 321\n",
      "        value: 322\n",
      "        value: 323\n",
      "        value: 324\n",
      "        value: 325\n",
      "        value: 326\n",
      "        value: 327\n",
      "        value: 328\n",
      "        value: 329\n",
      "        value: 330\n",
      "        value: 331\n",
      "        value: 332\n",
      "        value: 333\n",
      "        value: 334\n",
      "        value: 335\n",
      "        value: 336\n",
      "        value: 337\n",
      "        value: 338\n",
      "        value: 339\n",
      "        value: 340\n",
      "        value: 341\n",
      "        value: 342\n",
      "        value: 343\n",
      "        value: 344\n",
      "        value: 345\n",
      "        value: 346\n",
      "        value: 347\n",
      "        value: 348\n",
      "        value: 349\n",
      "        value: 350\n",
      "        value: 351\n",
      "        value: 352\n",
      "        value: 353\n",
      "        value: 354\n",
      "        value: 355\n",
      "        value: 356\n",
      "        value: 357\n",
      "        value: 358\n",
      "        value: 359\n",
      "        value: 360\n",
      "        value: 361\n",
      "        value: 362\n",
      "        value: 363\n",
      "        value: 364\n",
      "        value: 365\n",
      "        value: 366\n",
      "        value: 367\n",
      "        value: 368\n",
      "        value: 369\n",
      "        value: 372\n",
      "        value: 373\n",
      "        value: 374\n",
      "        value: 375\n",
      "        value: 378\n",
      "        value: 379\n",
      "        value: 380\n",
      "        value: 381\n",
      "        value: 382\n",
      "        value: 383\n",
      "        value: 384\n",
      "        value: 385\n",
      "        value: 386\n",
      "        value: 387\n",
      "        value: 408\n",
      "        value: 409\n",
      "        value: 412\n",
      "        value: 413\n",
      "        value: 414\n",
      "        value: 415\n",
      "        value: 423\n",
      "        value: 424\n",
      "        value: 427\n",
      "        value: 428\n",
      "        value: 429\n",
      "        value: 430\n",
      "        value: 432\n",
      "        value: 434\n",
      "        value: 435\n",
      "        value: 436\n",
      "        value: 437\n",
      "        value: 438\n",
      "        value: 439\n",
      "        value: 440\n",
      "        value: 441\n",
      "        value: 442\n",
      "        value: 443\n",
      "        value: 444\n",
      "        value: 445\n",
      "        value: 446\n",
      "        value: 447\n",
      "        value: 448\n",
      "        value: 449\n",
      "        value: 450\n",
      "        value: 451\n",
      "        value: 452\n",
      "        value: 453\n",
      "        value: 454\n",
      "        value: 455\n",
      "        value: 456\n",
      "        value: 457\n",
      "        value: 458\n",
      "        value: 459\n",
      "        value: 460\n",
      "        value: 461\n",
      "        value: 462\n",
      "        value: 463\n",
      "        value: 464\n",
      "        value: 465\n",
      "        value: 466\n",
      "        value: 467\n",
      "        value: 468\n",
      "        value: 469\n",
      "        value: 470\n",
      "        value: 471\n",
      "        value: 472\n",
      "        value: 473\n",
      "        value: 474\n",
      "        value: 475\n",
      "        value: 476\n",
      "        value: 477\n",
      "        value: 478\n",
      "        value: 479\n",
      "        value: 480\n",
      "        value: 481\n",
      "        value: 482\n",
      "        value: 483\n",
      "        value: 484\n",
      "        value: 485\n",
      "        value: 486\n",
      "        value: 487\n",
      "        value: 488\n",
      "        value: 489\n",
      "        value: 490\n",
      "        value: 491\n",
      "        value: 492\n",
      "        value: 493\n",
      "        value: 494\n",
      "        value: 495\n",
      "        value: 496\n",
      "        value: 497\n",
      "        value: 498\n",
      "        value: 499\n",
      "        value: 500\n",
      "        value: 501\n",
      "        value: 502\n",
      "        value: 503\n",
      "        value: 504\n",
      "        value: 505\n",
      "        value: 506\n",
      "        value: 507\n",
      "        value: 508\n",
      "        value: 509\n",
      "        value: 510\n",
      "        value: 511\n",
      "        value: 512\n",
      "        value: 513\n",
      "        value: 514\n",
      "        value: 515\n",
      "        value: 516\n",
      "        value: 517\n",
      "        value: 518\n",
      "        value: 519\n",
      "        value: 520\n",
      "        value: 521\n",
      "        value: 522\n",
      "        value: 523\n",
      "        value: 524\n",
      "        value: 525\n",
      "        value: 526\n",
      "        value: 530\n",
      "        value: 531\n",
      "        value: 532\n",
      "        value: 533\n",
      "        value: 534\n",
      "        value: 535\n",
      "        value: 537\n",
      "        value: 538\n",
      "        value: 540\n",
      "        value: 545\n",
      "        value: 546\n",
      "        value: 547\n",
      "        value: 548\n",
      "        value: 549\n",
      "        value: 550\n",
      "        value: 551\n",
      "        value: 552\n",
      "        value: 553\n",
      "        value: 554\n",
      "        value: 555\n",
      "        value: 556\n",
      "        value: 557\n",
      "        value: 558\n",
      "        value: 559\n",
      "        value: 560\n",
      "        value: 561\n",
      "        value: 562\n",
      "        value: 563\n",
      "        value: 564\n",
      "        value: 565\n",
      "        value: 566\n",
      "        value: 567\n",
      "        value: 568\n",
      "        value: 569\n",
      "        value: 570\n",
      "        value: 571\n",
      "        value: 572\n",
      "        value: 577\n",
      "        value: 582\n",
      "        value: 590\n",
      "        value: 591\n",
      "        value: 593\n",
      "        value: 598\n",
      "        value: 601\n",
      "        value: 606\n",
      "        value: 613\n",
      "        value: 614\n",
      "        value: 615\n",
      "        value: 616\n",
      "        value: 617\n",
      "        value: 618\n",
      "        value: 622\n",
      "        value: 631\n",
      "        value: 633\n",
      "        value: 634\n",
      "        value: 635\n",
      "        value: 636\n",
      "        value: 637\n",
      "        value: 638\n",
      "        value: 639\n",
      "        value: 640\n",
      "        value: 641\n",
      "        value: 642\n",
      "        value: 643\n",
      "        value: 644\n",
      "        value: 645\n",
      "        value: 646\n",
      "        value: 647\n",
      "        value: 648\n",
      "        value: 649\n",
      "        value: 650\n",
      "        value: 651\n",
      "        value: 652\n",
      "        value: 653\n",
      "        value: 654\n",
      "        value: 655\n",
      "        value: 656\n",
      "        value: 657\n",
      "        value: 658\n",
      "        value: 659\n",
      "        value: 660\n",
      "        value: 661\n",
      "        value: 662\n",
      "        value: 663\n",
      "        value: 664\n",
      "        value: 665\n",
      "        value: 666\n",
      "        value: 667\n",
      "        value: 668\n",
      "        value: 669\n",
      "        value: 670\n",
      "        value: 671\n",
      "        value: 672\n",
      "        value: 673\n",
      "        value: 674\n",
      "        value: 675\n",
      "        value: 676\n",
      "        value: 677\n",
      "        value: 678\n",
      "        value: 679\n",
      "        value: 680\n",
      "        value: 681\n",
      "        value: 682\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"l\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 1\n",
      "        value: 1\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"v\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 8222342.0\n",
      "        value: 804.0\n",
      "        value: 168.0\n",
      "        value: 557509.0\n",
      "        value: 390.0\n",
      "        value: 430927.0\n",
      "        value: 9847574.0\n",
      "        value: 4019294.0\n",
      "        value: 145099.0\n",
      "        value: 100011.0\n",
      "        value: 100054.0\n",
      "        value: 100242.0\n",
      "        value: 3369743.0\n",
      "        value: 66.0\n",
      "        value: 6930724.0\n",
      "        value: 457.0\n",
      "        value: 6158171.0\n",
      "        value: 901.0\n",
      "        value: 238618.0\n",
      "        value: 970.0\n",
      "        value: 538991.0\n",
      "        value: 655.0\n",
      "        value: 8399367.0\n",
      "        value: 664.0\n",
      "        value: 106953.0\n",
      "        value: 656.0\n",
      "        value: 7191000.0\n",
      "        value: 811.0\n",
      "        value: 106953.0\n",
      "        value: 656.0\n",
      "        value: 5089237.0\n",
      "        value: 504.0\n",
      "        value: 5746280.0\n",
      "        value: 303.0\n",
      "        value: 168634.0\n",
      "        value: 698.0\n",
      "        value: 6742011.0\n",
      "        value: 302.0\n",
      "        value: 1936536.0\n",
      "        value: 474.0\n",
      "        value: 8580863.0\n",
      "        value: 291.0\n",
      "        value: 2268042.0\n",
      "        value: 812.0\n",
      "        value: 1772115.0\n",
      "        value: 206.0\n",
      "        value: 6923356.0\n",
      "        value: 500.0\n",
      "        value: 6842744.0\n",
      "        value: 354.0\n",
      "        value: 6775477.0\n",
      "        value: 641.0\n",
      "        value: 1549222.0\n",
      "        value: 216.0\n",
      "        value: 2240049.0\n",
      "        value: 289.0\n",
      "        value: 1771666.0\n",
      "        value: 973.0\n",
      "        value: 8396765.0\n",
      "        value: 924.0\n",
      "        value: 3382315.0\n",
      "        value: 62.0\n",
      "        value: 6650993.0\n",
      "        value: 59.0\n",
      "        value: 9440216.0\n",
      "        value: 567.0\n",
      "        value: 3409095.0\n",
      "        value: 62.0\n",
      "        value: 3409095.0\n",
      "        value: 62.0\n",
      "        value: 3409095.0\n",
      "        value: 62.0\n",
      "        value: 11.0\n",
      "        value: 413837.0\n",
      "        value: 11.0\n",
      "        value: 413837.0\n",
      "        value: 11.0\n",
      "        value: 413837.0\n",
      "        value: 11.0\n",
      "        value: 413837.0\n",
      "        value: 280.0\n",
      "        value: 768787.0\n",
      "        value: 280.0\n",
      "        value: 768787.0\n",
      "        value: 6.0\n",
      "        value: 852976.0\n",
      "        value: 6.0\n",
      "        value: 852976.0\n",
      "        value: 6.0\n",
      "        value: 852976.0\n",
      "        value: 6.0\n",
      "        value: 852976.0\n",
      "        value: 20.0\n",
      "        value: 544865.0\n",
      "        value: 20.0\n",
      "        value: 544865.0\n",
      "        value: 20.0\n",
      "        value: 544865.0\n",
      "        value: 272.0\n",
      "        value: 426058.0\n",
      "        value: 920406.0\n",
      "        value: 50.0\n",
      "        value: 972887.0\n",
      "        value: 136.0\n",
      "        value: 945184.0\n",
      "        value: 136.0\n",
      "        value: 945184.0\n",
      "        value: 136.0\n",
      "        value: 945184.0\n",
      "        value: 136.0\n",
      "        value: 945184.0\n",
      "        value: 136.0\n",
      "        value: 945184.0\n",
      "        value: 136.0\n",
      "        value: 945184.0\n",
      "        value: 45.0\n",
      "        value: 495764.0\n",
      "        value: 45.0\n",
      "        value: 495764.0\n",
      "        value: 17.0\n",
      "        value: 566419.0\n",
      "        value: 16.0\n",
      "        value: 190837.0\n",
      "        value: 277.0\n",
      "        value: 260554.0\n",
      "        value: 17.0\n",
      "        value: 566419.0\n",
      "        value: 17.0\n",
      "        value: 566419.0\n",
      "        value: 17.0\n",
      "        value: 566419.0\n",
      "        value: 2153530.0\n",
      "        value: 841.0\n",
      "        value: 2153530.0\n",
      "        value: 841.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 237.0\n",
      "        value: 801529.0\n",
      "        value: 237.0\n",
      "        value: 801529.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 2153530.0\n",
      "        value: 841.0\n",
      "        value: 2153530.0\n",
      "        value: 841.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 237.0\n",
      "        value: 801529.0\n",
      "        value: 237.0\n",
      "        value: 801529.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 162.0\n",
      "        value: 117.0\n",
      "        value: 265.0\n",
      "        value: 218.0\n",
      "        value: 161.0\n",
      "        value: 110.0\n",
      "        value: 267.0\n",
      "        value: 214.0\n",
      "        value: 262.0\n",
      "        value: 215.0\n",
      "        value: 34.0\n",
      "        value: 5.0\n",
      "        value: 149.0\n",
      "        value: 110.0\n",
      "        value: 236.0\n",
      "        value: 209.0\n",
      "        value: 102.0\n",
      "        value: 102.0\n",
      "        value: 36.0\n",
      "        value: 73.0\n",
      "        value: 83.0\n",
      "        value: 99.0\n",
      "        value: 39.0\n",
      "        value: 64.0\n",
      "        value: 1.0\n",
      "        value: 0.20000000298023224\n",
      "        value: 0.00949000008404255\n",
      "        value: 0.28916457295417786\n",
      "        value: 0.28916457295417786\n",
      "        value: 0.28916457295417786\n",
      "        value: 0.04771212488412857\n",
      "        value: 0.18687649071216583\n",
      "        value: 0.07893134653568268\n",
      "        value: 0.03527971729636192\n",
      "        value: 0.029898857697844505\n",
      "        value: 0.08108308166265488\n",
      "        value: 0.04898178204894066\n",
      "        value: -0.01655319705605507\n",
      "        value: 0.0006667228881269693\n",
      "        value: -0.009364018216729164\n",
      "        value: 0.07987897098064423\n",
      "        value: -0.06798361241817474\n",
      "        value: 0.08175204694271088\n",
      "        value: -0.026881350204348564\n",
      "        value: -0.015727069228887558\n",
      "        value: -0.008201665244996548\n",
      "        value: 0.05083167925477028\n",
      "        value: 0.03144090995192528\n",
      "        value: 0.8999999761581421\n",
      "        value: 0.10000000149011612\n",
      "        value: 0.27535831928253174\n",
      "        value: 0.3820595443248749\n",
      "        value: 0.025728987529873848\n",
      "        value: 0.9708404541015625\n",
      "        value: 0.9549828171730042\n",
      "        value: 0.24440447986125946\n",
      "        value: 0.4708446264266968\n",
      "        value: 0.3852967619895935\n",
      "        value: 0.13648957014083862\n",
      "        value: 0.43176454305648804\n",
      "        value: 0.3453165292739868\n",
      "        value: 0.13197806477546692\n",
      "        value: 0.4001084268093109\n",
      "        value: 0.1274501383304596\n",
      "        value: 0.36440443992614746\n",
      "        value: 0.11410680413246155\n",
      "        value: 0.6377732753753662\n",
      "        value: 0.5123364925384521\n",
      "        value: 0.05538075789809227\n",
      "        value: 0.49121636152267456\n",
      "        value: 0.04898495227098465\n",
      "        value: 0.605477511882782\n",
      "        value: 0.4719206988811493\n",
      "        value: 0.0457921102643013\n",
      "        value: 0.4375736713409424\n",
      "        value: 0.044896114617586136\n",
      "        value: 0.6343784928321838\n",
      "        value: 0.5041976571083069\n",
      "        value: 0.0496235117316246\n",
      "        value: 0.5981580018997192\n",
      "        value: 0.46745580434799194\n",
      "        value: 0.04888223111629486\n",
      "        value: 0.5673280954360962\n",
      "        value: 0.4371917247772217\n",
      "        value: 0.04934122785925865\n",
      "        value: 0.5323781967163086\n",
      "        value: 0.04944075271487236\n",
      "        value: 0.4025960862636566\n",
      "        value: 0.8478445410728455\n",
      "        value: 0.992749810218811\n",
      "        value: 0.0355549156665802\n",
      "        value: 0.8144431710243225\n",
      "        value: 0.9604353308677673\n",
      "        value: 0.03467431664466858\n",
      "        value: 0.7573500871658325\n",
      "        value: 0.900134265422821\n",
      "        value: 0.037326883524656296\n",
      "        value: 0.5468329787254333\n",
      "        value: 0.41772767901420593\n",
      "        value: 0.05036814138293266\n",
      "        value: 0.5465898513793945\n",
      "        value: 0.4176322817802429\n",
      "        value: 0.050538938492536545\n",
      "        value: 0.5463558435440063\n",
      "        value: 0.4175221920013428\n",
      "        value: 0.05068238452076912\n",
      "        value: 0.1623249351978302\n",
      "        value: 0.005568529013544321\n",
      "        value: 0.004243576433509588\n",
      "        value: 1.0\n",
      "        value: 0.1840577870607376\n",
      "        value: 0.006369345355778933\n",
      "        value: 0.040498122572898865\n",
      "        value: 0.31781134009361267\n",
      "        value: 0.29813656210899353\n",
      "        value: 0.31159430742263794\n",
      "        value: 0.006762887816876173\n",
      "        value: 0.29020029306411743\n",
      "        value: 0.006840972695499659\n",
      "        value: 0.005422570277005434\n",
      "        value: 0.21875207126140594\n",
      "        value: 0.005500686354935169\n",
      "        value: 0.5014258027076721\n",
      "        value: 0.00016576572670601308\n",
      "        value: 0.06326674669981003\n",
      "        value: 0.054148945957422256\n",
      "        value: 0.023642636835575104\n",
      "        value: 0.02195098251104355\n",
      "        value: 0.8999999761581421\n",
      "        value: 0.33083510398864746\n",
      "        value: 0.12041199952363968\n",
      "        value: 0.2845357358455658\n",
      "        value: 1.0\n",
      "        value: 0.36492374539375305\n",
      "        value: 0.30182844400405884\n",
      "        value: 0.16020600497722626\n",
      "        value: 0.07781512290239334\n",
      "        value: 0.9447887539863586\n",
      "        value: 0.4711334705352783\n",
      "        value: 0.38543060421943665\n",
      "        value: 0.13600704073905945\n",
      "        value: 0.43214741349220276\n",
      "        value: 0.345499724149704\n",
      "        value: 0.40041062235832214\n",
      "        value: 0.3129367530345917\n",
      "        value: 0.12685392796993256\n",
      "        value: 0.364952951669693\n",
      "        value: 0.1128835529088974\n",
      "        value: 0.6553401350975037\n",
      "        value: 0.5341590642929077\n",
      "        value: 0.0611543245613575\n",
      "        value: 0.6404645442962646\n",
      "        value: 0.51646888256073\n",
      "        value: 0.05726355314254761\n",
      "        value: 0.6239129900932312\n",
      "        value: 0.05428585410118103\n",
      "        value: 0.5902683138847351\n",
      "        value: 0.053290486335754395\n",
      "        value: 0.2733999192714691\n",
      "        value: 0.06346438825130463\n",
      "        value: 0.05427323281764984\n",
      "        value: 1.0\n",
      "        value: 1.0\n",
      "        value: 1.0\n",
      "        value: 0.41057485342025757\n",
      "        value: 1.0\n",
      "        value: 1.0\n",
      "        value: 1.0\n",
      "        value: 1.0\n",
      "        value: 0.09030900150537491\n",
      "        value: 0.09030900150537491\n",
      "        value: 0.08450980484485626\n",
      "        value: 0.32352757453918457\n",
      "        value: 0.19138137996196747\n",
      "        value: 0.038095757365226746\n",
      "        value: 0.08450980484485626\n",
      "        value: 0.10000000149011612\n",
      "        value: 0.01141068059951067\n",
      "        value: 0.21071171760559082\n",
      "        value: 0.3072909116744995\n",
      "        value: 0.47340771555900574\n",
      "        value: 0.46989700198173523\n",
      "        value: 0.2507426142692566\n",
      "        value: 0.3622504770755768\n",
      "        value: 0.30678144097328186\n",
      "        value: 0.1832980215549469\n",
      "        value: 0.06616131961345673\n",
      "        value: 0.06438598781824112\n",
      "        value: 0.42142343521118164\n",
      "        value: 0.00033798249205574393\n",
      "        value: 0.002414338756352663\n",
      "        value: 0.002605876885354519\n",
      "        value: 0.00033798249205574393\n",
      "        value: 9.872547525446862e-05\n",
      "        value: 0.002414338756352663\n",
      "        value: 0.002605876885354519\n",
      "        value: 0.023629751056432724\n",
      "        value: 0.00033798249205574393\n",
      "        value: 9.872547525446862e-05\n",
      "        value: 0.002414338756352663\n",
      "        value: 0.002605876885354519\n",
      "        value: 0.023629751056432724\n",
      "        value: 0.00033798249205574393\n",
      "        value: 9.872547525446862e-05\n",
      "        value: 0.002414338756352663\n",
      "        value: 0.002605876885354519\n",
      "        value: 0.023629751056432724\n",
      "        value: 0.01068063173443079\n",
      "        value: 2.9393875593086705e-05\n",
      "        value: 0.0006155047449283302\n",
      "        value: 0.03547753393650055\n",
      "        value: 0.01310634147375822\n",
      "        value: 0.03547753393650055\n",
      "        value: 0.6060442924499512\n",
      "        value: 0.22124934196472168\n",
      "        value: 0.0003367942408658564\n",
      "        value: 0.02296740934252739\n",
      "        value: 0.029525170102715492\n",
      "        value: 0.04642750695347786\n",
      "        value: 0.04719500243663788\n",
      "        value: 0.8182253241539001\n",
      "        value: 0.8757087588310242\n",
      "        value: 0.001960023306310177\n",
      "        value: 0.03010299988090992\n",
      "        value: 0.005435766186565161\n",
      "        value: 0.03010299988090992\n",
      "        value: 0.4728896915912628\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for raw_record in rankData.take(1):  # 从dataset中取一个样本进行查看即可\n",
    "    example = tf.train.Example()\n",
    "    example.ParseFromString(raw_record.numpy())\n",
    "    print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-02T04:15:50.035688Z",
     "start_time": "2021-08-02T04:15:49.883098Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'i': <tf.Tensor: shape=(554,), dtype=int64, numpy=\n",
      "array([  0,   1,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  16,\n",
      "        17,  19,  20,  22,  23,  25,  26,  28,  29,  31,  32,  34,  35,\n",
      "        37,  38,  40,  41,  43,  44,  46,  47,  49,  50,  52,  53,  55,\n",
      "        56,  58,  59,  61,  62,  64,  65,  67,  68,  70,  71,  73,  74,\n",
      "        76,  77,  79,  80,  82,  83,  85,  86,  88,  89,  91,  92,  94,\n",
      "        95,  97,  98, 100, 101, 103, 104, 106, 107, 108, 109, 110, 111,\n",
      "       112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124,\n",
      "       125, 126, 127, 128, 129, 130, 131, 132, 133, 135, 136, 137, 138,\n",
      "       139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151,\n",
      "       152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
      "       165, 166, 167, 169, 170, 172, 173, 174, 175, 176, 177, 178, 179,\n",
      "       180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192,\n",
      "       193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "       206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 219,\n",
      "       220, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "       234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246,\n",
      "       247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259,\n",
      "       260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272,\n",
      "       273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n",
      "       286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298,\n",
      "       299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
      "       312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324,\n",
      "       325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337,\n",
      "       338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350,\n",
      "       351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
      "       364, 365, 366, 367, 368, 369, 372, 373, 374, 375, 378, 379, 380,\n",
      "       381, 382, 383, 384, 385, 386, 387, 408, 409, 412, 413, 414, 415,\n",
      "       423, 424, 427, 428, 429, 430, 432, 434, 435, 436, 437, 438, 439,\n",
      "       440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452,\n",
      "       453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465,\n",
      "       466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478,\n",
      "       479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491,\n",
      "       492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504,\n",
      "       505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517,\n",
      "       518, 519, 520, 521, 522, 523, 524, 525, 526, 530, 531, 532, 533,\n",
      "       534, 535, 537, 538, 540, 545, 546, 547, 548, 549, 550, 551, 552,\n",
      "       553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565,\n",
      "       566, 567, 568, 569, 570, 571, 572, 577, 582, 590, 591, 593, 598,\n",
      "       601, 606, 613, 614, 615, 616, 617, 618, 622, 631, 633, 634, 635,\n",
      "       636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648,\n",
      "       649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661,\n",
      "       662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674,\n",
      "       675, 676, 677, 678, 679, 680, 681, 682])>, 'l': <tf.Tensor: shape=(2,), dtype=int64, numpy=array([1, 1])>, 'v': <tf.Tensor: shape=(554,), dtype=float32, numpy=\n",
      "array([ 8.22234200e+06,  8.04000000e+02,  1.68000000e+02,  5.57509000e+05,\n",
      "        3.90000000e+02,  4.30927000e+05,  9.84757400e+06,  4.01929400e+06,\n",
      "        1.45099000e+05,  1.00011000e+05,  1.00054000e+05,  1.00242000e+05,\n",
      "        3.36974300e+06,  6.60000000e+01,  6.93072400e+06,  4.57000000e+02,\n",
      "        6.15817100e+06,  9.01000000e+02,  2.38618000e+05,  9.70000000e+02,\n",
      "        5.38991000e+05,  6.55000000e+02,  8.39936700e+06,  6.64000000e+02,\n",
      "        1.06953000e+05,  6.56000000e+02,  7.19100000e+06,  8.11000000e+02,\n",
      "        1.06953000e+05,  6.56000000e+02,  5.08923700e+06,  5.04000000e+02,\n",
      "        5.74628000e+06,  3.03000000e+02,  1.68634000e+05,  6.98000000e+02,\n",
      "        6.74201100e+06,  3.02000000e+02,  1.93653600e+06,  4.74000000e+02,\n",
      "        8.58086300e+06,  2.91000000e+02,  2.26804200e+06,  8.12000000e+02,\n",
      "        1.77211500e+06,  2.06000000e+02,  6.92335600e+06,  5.00000000e+02,\n",
      "        6.84274400e+06,  3.54000000e+02,  6.77547700e+06,  6.41000000e+02,\n",
      "        1.54922200e+06,  2.16000000e+02,  2.24004900e+06,  2.89000000e+02,\n",
      "        1.77166600e+06,  9.73000000e+02,  8.39676500e+06,  9.24000000e+02,\n",
      "        3.38231500e+06,  6.20000000e+01,  6.65099300e+06,  5.90000000e+01,\n",
      "        9.44021600e+06,  5.67000000e+02,  3.40909500e+06,  6.20000000e+01,\n",
      "        3.40909500e+06,  6.20000000e+01,  3.40909500e+06,  6.20000000e+01,\n",
      "        1.10000000e+01,  4.13837000e+05,  1.10000000e+01,  4.13837000e+05,\n",
      "        1.10000000e+01,  4.13837000e+05,  1.10000000e+01,  4.13837000e+05,\n",
      "        2.80000000e+02,  7.68787000e+05,  2.80000000e+02,  7.68787000e+05,\n",
      "        6.00000000e+00,  8.52976000e+05,  6.00000000e+00,  8.52976000e+05,\n",
      "        6.00000000e+00,  8.52976000e+05,  6.00000000e+00,  8.52976000e+05,\n",
      "        2.00000000e+01,  5.44865000e+05,  2.00000000e+01,  5.44865000e+05,\n",
      "        2.00000000e+01,  5.44865000e+05,  2.72000000e+02,  4.26058000e+05,\n",
      "        9.20406000e+05,  5.00000000e+01,  9.72887000e+05,  1.36000000e+02,\n",
      "        9.45184000e+05,  1.36000000e+02,  9.45184000e+05,  1.36000000e+02,\n",
      "        9.45184000e+05,  1.36000000e+02,  9.45184000e+05,  1.36000000e+02,\n",
      "        9.45184000e+05,  1.36000000e+02,  9.45184000e+05,  4.50000000e+01,\n",
      "        4.95764000e+05,  4.50000000e+01,  4.95764000e+05,  1.70000000e+01,\n",
      "        5.66419000e+05,  1.60000000e+01,  1.90837000e+05,  2.77000000e+02,\n",
      "        2.60554000e+05,  1.70000000e+01,  5.66419000e+05,  1.70000000e+01,\n",
      "        5.66419000e+05,  1.70000000e+01,  5.66419000e+05,  2.15353000e+06,\n",
      "        8.41000000e+02,  2.15353000e+06,  8.41000000e+02,  1.00000000e+07,\n",
      "        1.00000000e+07,  1.00000000e+07,  1.00000000e+07,  1.00000000e+07,\n",
      "        1.00000000e+07,  1.00000000e+07,  1.00000000e+07,  1.00000000e+07,\n",
      "        1.00000000e+07,  1.00000000e+07,  1.00000000e+07,  1.00000000e+07,\n",
      "        1.00000000e+07,  1.00000000e+07,  1.00000000e+07,  1.00000000e+07,\n",
      "        1.00000000e+07,  1.00000000e+07,  1.00000000e+07,  1.00000000e+07,\n",
      "        1.00000000e+07,  1.00000000e+07,  1.00000000e+07,  2.37000000e+02,\n",
      "        8.01529000e+05,  2.37000000e+02,  8.01529000e+05,  1.00000000e+06,\n",
      "        1.00000000e+06,  1.00000000e+06,  1.00000000e+06,  1.00000000e+06,\n",
      "        1.00000000e+06,  1.00000000e+06,  1.00000000e+06,  1.00000000e+06,\n",
      "        1.00000000e+06,  1.00000000e+06,  1.00000000e+06,  1.00000000e+06,\n",
      "        1.00000000e+06,  1.00000000e+06,  1.00000000e+06,  2.15353000e+06,\n",
      "        8.41000000e+02,  2.15353000e+06,  8.41000000e+02,  1.00000000e+07,\n",
      "        1.00000000e+07,  1.00000000e+07,  1.00000000e+07,  1.00000000e+07,\n",
      "        1.00000000e+07,  1.00000000e+07,  1.00000000e+07,  1.00000000e+07,\n",
      "        1.00000000e+07,  1.00000000e+07,  1.00000000e+07,  1.00000000e+07,\n",
      "        1.00000000e+07,  1.00000000e+07,  1.00000000e+07,  1.00000000e+07,\n",
      "        1.00000000e+07,  1.00000000e+07,  1.00000000e+07,  1.00000000e+07,\n",
      "        1.00000000e+07,  1.00000000e+07,  1.00000000e+07,  1.00000000e+07,\n",
      "        1.00000000e+07,  1.00000000e+07,  1.00000000e+07,  1.00000000e+07,\n",
      "        1.00000000e+07,  1.00000000e+07,  1.00000000e+07,  1.00000000e+07,\n",
      "        1.00000000e+07,  1.00000000e+07,  1.00000000e+07,  1.00000000e+07,\n",
      "        1.00000000e+07,  1.00000000e+07,  1.00000000e+07,  1.00000000e+07,\n",
      "        1.00000000e+07,  1.00000000e+07,  1.00000000e+07,  1.00000000e+07,\n",
      "        1.00000000e+07,  1.00000000e+07,  1.00000000e+07,  1.00000000e+07,\n",
      "        1.00000000e+07,  1.00000000e+07,  1.00000000e+07,  1.00000000e+07,\n",
      "        1.00000000e+07,  1.00000000e+07,  1.00000000e+07,  1.00000000e+07,\n",
      "        1.00000000e+07,  1.00000000e+07,  1.00000000e+07,  1.00000000e+07,\n",
      "        1.00000000e+07,  1.00000000e+07,  1.00000000e+07,  1.00000000e+07,\n",
      "        1.00000000e+07,  1.00000000e+07,  1.00000000e+07,  1.00000000e+07,\n",
      "        1.00000000e+07,  1.00000000e+07,  1.00000000e+07,  1.00000000e+07,\n",
      "        1.00000000e+07,  1.00000000e+07,  1.00000000e+07,  1.00000000e+07,\n",
      "        1.00000000e+07,  1.00000000e+07,  1.00000000e+07,  1.00000000e+07,\n",
      "        1.00000000e+07,  1.00000000e+07,  1.00000000e+07,  2.37000000e+02,\n",
      "        8.01529000e+05,  2.37000000e+02,  8.01529000e+05,  1.00000000e+06,\n",
      "        1.00000000e+06,  1.00000000e+06,  1.00000000e+06,  1.00000000e+06,\n",
      "        1.00000000e+06,  1.00000000e+06,  1.00000000e+06,  1.00000000e+06,\n",
      "        1.00000000e+06,  1.00000000e+06,  1.00000000e+06,  1.00000000e+06,\n",
      "        1.00000000e+06,  1.00000000e+06,  1.00000000e+06,  1.00000000e+06,\n",
      "        1.00000000e+06,  1.00000000e+06,  1.00000000e+06,  1.00000000e+06,\n",
      "        1.00000000e+06,  1.00000000e+06,  1.00000000e+06,  1.00000000e+06,\n",
      "        1.00000000e+06,  1.00000000e+06,  1.00000000e+06,  1.00000000e+06,\n",
      "        1.00000000e+06,  1.00000000e+06,  1.00000000e+06,  1.00000000e+06,\n",
      "        1.00000000e+06,  1.00000000e+06,  1.00000000e+06,  1.00000000e+06,\n",
      "        1.00000000e+06,  1.00000000e+06,  1.00000000e+06,  1.00000000e+06,\n",
      "        1.00000000e+06,  1.00000000e+06,  1.00000000e+06,  1.00000000e+06,\n",
      "        1.00000000e+06,  1.00000000e+06,  1.00000000e+06,  1.00000000e+06,\n",
      "        1.00000000e+06,  1.00000000e+06,  1.00000000e+06,  1.00000000e+06,\n",
      "        1.00000000e+06,  1.00000000e+06,  1.00000000e+06,  1.62000000e+02,\n",
      "        1.17000000e+02,  2.65000000e+02,  2.18000000e+02,  1.61000000e+02,\n",
      "        1.10000000e+02,  2.67000000e+02,  2.14000000e+02,  2.62000000e+02,\n",
      "        2.15000000e+02,  3.40000000e+01,  5.00000000e+00,  1.49000000e+02,\n",
      "        1.10000000e+02,  2.36000000e+02,  2.09000000e+02,  1.02000000e+02,\n",
      "        1.02000000e+02,  3.60000000e+01,  7.30000000e+01,  8.30000000e+01,\n",
      "        9.90000000e+01,  3.90000000e+01,  6.40000000e+01,  1.00000000e+00,\n",
      "        2.00000003e-01,  9.49000008e-03,  2.89164573e-01,  2.89164573e-01,\n",
      "        2.89164573e-01,  4.77121249e-02,  1.86876491e-01,  7.89313465e-02,\n",
      "        3.52797173e-02,  2.98988577e-02,  8.10830817e-02,  4.89817820e-02,\n",
      "       -1.65531971e-02,  6.66722888e-04, -9.36401822e-03,  7.98789710e-02,\n",
      "       -6.79836124e-02,  8.17520469e-02, -2.68813502e-02, -1.57270692e-02,\n",
      "       -8.20166524e-03,  5.08316793e-02,  3.14409100e-02,  8.99999976e-01,\n",
      "        1.00000001e-01,  2.75358319e-01,  3.82059544e-01,  2.57289875e-02,\n",
      "        9.70840454e-01,  9.54982817e-01,  2.44404480e-01,  4.70844626e-01,\n",
      "        3.85296762e-01,  1.36489570e-01,  4.31764543e-01,  3.45316529e-01,\n",
      "        1.31978065e-01,  4.00108427e-01,  1.27450138e-01,  3.64404440e-01,\n",
      "        1.14106804e-01,  6.37773275e-01,  5.12336493e-01,  5.53807579e-02,\n",
      "        4.91216362e-01,  4.89849523e-02,  6.05477512e-01,  4.71920699e-01,\n",
      "        4.57921103e-02,  4.37573671e-01,  4.48961146e-02,  6.34378493e-01,\n",
      "        5.04197657e-01,  4.96235117e-02,  5.98158002e-01,  4.67455804e-01,\n",
      "        4.88822311e-02,  5.67328095e-01,  4.37191725e-01,  4.93412279e-02,\n",
      "        5.32378197e-01,  4.94407527e-02,  4.02596086e-01,  8.47844541e-01,\n",
      "        9.92749810e-01,  3.55549157e-02,  8.14443171e-01,  9.60435331e-01,\n",
      "        3.46743166e-02,  7.57350087e-01,  9.00134265e-01,  3.73268835e-02,\n",
      "        5.46832979e-01,  4.17727679e-01,  5.03681414e-02,  5.46589851e-01,\n",
      "        4.17632282e-01,  5.05389385e-02,  5.46355844e-01,  4.17522192e-01,\n",
      "        5.06823845e-02,  1.62324935e-01,  5.56852901e-03,  4.24357643e-03,\n",
      "        1.00000000e+00,  1.84057787e-01,  6.36934536e-03,  4.04981226e-02,\n",
      "        3.17811340e-01,  2.98136562e-01,  3.11594307e-01,  6.76288782e-03,\n",
      "        2.90200293e-01,  6.84097270e-03,  5.42257028e-03,  2.18752071e-01,\n",
      "        5.50068635e-03,  5.01425803e-01,  1.65765727e-04,  6.32667467e-02,\n",
      "        5.41489460e-02,  2.36426368e-02,  2.19509825e-02,  8.99999976e-01,\n",
      "        3.30835104e-01,  1.20412000e-01,  2.84535736e-01,  1.00000000e+00,\n",
      "        3.64923745e-01,  3.01828444e-01,  1.60206005e-01,  7.78151229e-02,\n",
      "        9.44788754e-01,  4.71133471e-01,  3.85430604e-01,  1.36007041e-01,\n",
      "        4.32147413e-01,  3.45499724e-01,  4.00410622e-01,  3.12936753e-01,\n",
      "        1.26853928e-01,  3.64952952e-01,  1.12883553e-01,  6.55340135e-01,\n",
      "        5.34159064e-01,  6.11543246e-02,  6.40464544e-01,  5.16468883e-01,\n",
      "        5.72635531e-02,  6.23912990e-01,  5.42858541e-02,  5.90268314e-01,\n",
      "        5.32904863e-02,  2.73399919e-01,  6.34643883e-02,  5.42732328e-02,\n",
      "        1.00000000e+00,  1.00000000e+00,  1.00000000e+00,  4.10574853e-01,\n",
      "        1.00000000e+00,  1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
      "        9.03090015e-02,  9.03090015e-02,  8.45098048e-02,  3.23527575e-01,\n",
      "        1.91381380e-01,  3.80957574e-02,  8.45098048e-02,  1.00000001e-01,\n",
      "        1.14106806e-02,  2.10711718e-01,  3.07290912e-01,  4.73407716e-01,\n",
      "        4.69897002e-01,  2.50742614e-01,  3.62250477e-01,  3.06781441e-01,\n",
      "        1.83298022e-01,  6.61613196e-02,  6.43859878e-02,  4.21423435e-01,\n",
      "        3.37982492e-04,  2.41433876e-03,  2.60587689e-03,  3.37982492e-04,\n",
      "        9.87254753e-05,  2.41433876e-03,  2.60587689e-03,  2.36297511e-02,\n",
      "        3.37982492e-04,  9.87254753e-05,  2.41433876e-03,  2.60587689e-03,\n",
      "        2.36297511e-02,  3.37982492e-04,  9.87254753e-05,  2.41433876e-03,\n",
      "        2.60587689e-03,  2.36297511e-02,  1.06806317e-02,  2.93938756e-05,\n",
      "        6.15504745e-04,  3.54775339e-02,  1.31063415e-02,  3.54775339e-02,\n",
      "        6.06044292e-01,  2.21249342e-01,  3.36794241e-04,  2.29674093e-02,\n",
      "        2.95251701e-02,  4.64275070e-02,  4.71950024e-02,  8.18225324e-01,\n",
      "        8.75708759e-01,  1.96002331e-03,  3.01029999e-02,  5.43576619e-03,\n",
      "        3.01029999e-02,  4.72889692e-01], dtype=float32)>}\n"
     ]
    }
   ],
   "source": [
    "description = {\n",
    "    'i': tf.io.FixedLenFeature(\n",
    "        [554], #要确定维度 不然会报错\n",
    "        tf.int64,\n",
    "    ),\n",
    "    'l': tf.io.FixedLenFeature(\n",
    "        [2],\n",
    "        tf.int64,\n",
    "    ),\n",
    "    'v': tf.io.FixedLenFeature(\n",
    "        [554],\n",
    "        tf.float32,\n",
    "    ),\n",
    "}\n",
    "\n",
    "\n",
    "def _parse_example(example):\n",
    "    return tf.io.parse_single_example(example, description)\n",
    "\n",
    "rankData = tf.data.TFRecordDataset(filepath)\n",
    "rankDataMap = rankData.map(_parse_example)\n",
    "\n",
    "for item in rankDataMap:\n",
    "    print(item)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### parse tfrecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for a single example use  \"tf.io.parse_single_example(serialized_example, features=description)\"\n",
    "# for batch examples use   \"tf.io.parse_exsample(serialized_example, features=description)\"\n",
    "\n",
    "# another function is \"tf.train.Example.FromString(serialized_example)\" which is not uesed frequently 这个不用给description\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dataset api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-02T07:52:46.441941Z",
     "start_time": "2021-08-02T07:52:46.433442Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.data.ops.dataset_ops.ShuffleDataset'>\n",
      "tf.Tensor(b'./files/b.txt', shape=(), dtype=string)\n",
      "tf.Tensor(b'./files/a.txt', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "# list_files\n",
    "datasetlist = tf.data.Dataset.list_files('./files/*.txt')\n",
    "print(type(datasetlist))\n",
    "for i in datasetlist:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-02T08:09:55.268558Z",
     "start_time": "2021-08-02T08:09:55.249709Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1 2], shape=(2,), dtype=int32)\n",
      "tf.Tensor([3 4], shape=(2,), dtype=int32)\n",
      "------------\n",
      "tf.Tensor(0.1, shape=(), dtype=float64) tf.Tensor(0, shape=(), dtype=int64)\n",
      "tf.Tensor(0.4, shape=(), dtype=float64) tf.Tensor(0, shape=(), dtype=int64)\n",
      "tf.Tensor(0.6, shape=(), dtype=float64) tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(0.2, shape=(), dtype=float64) tf.Tensor(0, shape=(), dtype=int64)\n",
      "tf.Tensor(0.8, shape=(), dtype=float64) tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(0.8, shape=(), dtype=float64) tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(0.4, shape=(), dtype=float64) tf.Tensor(0, shape=(), dtype=int64)\n",
      "tf.Tensor(0.9, shape=(), dtype=float64) tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(0.3, shape=(), dtype=float64) tf.Tensor(0, shape=(), dtype=int64)\n",
      "tf.Tensor(0.2, shape=(), dtype=float64) tf.Tensor(0, shape=(), dtype=int64)\n",
      "------------\n",
      "tf.Tensor(b'/var/data/file1.txt', shape=(), dtype=string)\n",
      "tf.Tensor(b'/var/data/file2.txt', shape=(), dtype=string)\n",
      "tf.Tensor(b'/var/data/file3.txt', shape=(), dtype=string)\n",
      "tf.Tensor(b'/var/data/file4.txt', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "# from_tensor_slices\n",
    "import numpy as np\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices([[1, 2], [3, 4]])\n",
    "for i in dataset:\n",
    "    print(i)\n",
    "print('------------')\n",
    "\n",
    "data = np.array([0.1, 0.4, 0.6, 0.2, 0.8, 0.8, 0.4, 0.9, 0.3, 0.2])\n",
    "label = np.array([0, 0, 1, 0, 1, 1, 0, 1, 0, 0])\n",
    "dataset = tf.data.Dataset.from_tensor_slices((data, label))\n",
    "for x, y in dataset:\n",
    "    print(x, y)\n",
    "\n",
    "print('------------')\n",
    "filenames = [\"/var/data/file1.txt\", \"/var/data/file2.txt\",\n",
    "             \"/var/data/file3.txt\", \"/var/data/file4.txt\"]\n",
    "dataset = tf.data.Dataset.from_tensor_slices(filenames)\n",
    "for i in dataset:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interleave 首先该方法会从该Dataset中取出cycle_length个element，\n",
    "#然后对这些element apply map_func, 得到cycle_length个新的Dataset对象。\n",
    "#然后从这些新生成的Dataset对象中取数据，每个Dataset对象一次取block_length个数据\n",
    "#当新生成的某个Dataset的对象取尽时，从原Dataset中再取一个element，然后apply map_func，以此类推。\n",
    "ds = dataset.interleave(map_func=lambda filename: tf.data.TFRecordDataset(filename),\n",
    "                           cycle_length=8,\n",
    "                           block_length=1,\n",
    "                           num_parallel_calls=tf.data.AUTOTUNE,\n",
    "                           deterministic=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds = ds.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "# ds = ds.shuffle(buffer_size=GLOBAL_BATCH_SIZE * 10)\n",
    "# ds = ds.batch(GLOBAL_BATCH_SIZE)\n",
    "# ds = ds.map(_decoder, num_parallel_calls=tf.data.AUTOTUNE, deterministic=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-06T09:35:17.741655Z",
     "start_time": "2021-08-06T09:35:17.723973Z"
    }
   },
   "outputs": [],
   "source": [
    "# TextLineDataset\n",
    "file_names = tf.data.Dataset.list_files('./*.txt')\n",
    "dataset = tf.data.TextLineDataset(file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-06T09:35:30.485790Z",
     "start_time": "2021-08-06T09:35:30.476276Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'hello ', shape=(), dtype=string)\n",
      "tf.Tensor(b'jumped ove', shape=(), dtype=string)\n",
      "tf.Tensor(b'the moon', shape=(), dtype=string)\n",
      "tf.Tensor(b'hello 2', shape=(), dtype=string)\n",
      "tf.Tensor(b'jumped ove 2', shape=(), dtype=string)\n",
      "tf.Tensor(b'the moon 2', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "for i in dataset:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU and distributed training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-02T09:09:08.351240Z",
     "start_time": "2021-08-02T09:09:08.348063Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorflow 默认情况下，将运算分配给设备时优先使用 GPU 设备。 \n",
    "# 指定gpu使用 os.environ['CUDA_VISIBLE_DEVICES'] = '3'\n",
    "# 可以认为tensorflow将gpu加速与用户隔开，不需要像pytorch一样\n",
    "# 指定tensor放在内存或者gpu上\n",
    "# 默认的tensor.device 是 device:CPU:0\n",
    "# tensorflow 回在需要时会自动在设备之间复制张量\n",
    "\n",
    "#指定在cpu上：\n",
    "with tf.device('/CPU:0'):\n",
    "  a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "  b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
    "\n",
    "#指定在GPU上\n",
    "with tf.device('/GPU:0'):\n",
    "  a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "  b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-02T10:36:41.610969Z",
     "start_time": "2021-08-02T10:36:41.608848Z"
    }
   },
   "outputs": [],
   "source": [
    "# TensorFlow 会映射进程可见的所有 GPU 所以需要指定GPU 在tensorflow中指定gpu\n",
    "# 使用 set_visible_devices\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only use the first GPU\n",
    "  try:\n",
    "    tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "  except RuntimeError as e:\n",
    "    # Visible devices must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorflow 默认直接占满gpu 可以设置按需分配\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 多GPU训练\n",
    "strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\", \"/gpu:1\"])\n",
    "with strategy.scope():\n",
    "    #input_data\n",
    "    #model\n",
    "    #train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### performance improving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras layers/models inherit from tf.train.Checkpointable and are integrated with @tf.function, \n",
    "# which makes it possible to directly checkpoint or export SavedModels from Keras objects. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can fully utilize dataset async prefetching/streaming features by wrapping your code in tf.function,\n",
    "# which replaces Python iteration with the equivalent graph operations using AutoGraph.\n",
    "\n",
    "@tf.function\n",
    "def train(model, dataset, optimizer):\n",
    "  for x, y in dataset:\n",
    "    with tf.GradientTape() as tape:\n",
    "      # training=True is only needed if there are layers with different\n",
    "      # behavior during training versus inference (e.g. Dropout).\n",
    "      prediction = model(x, training=True)\n",
    "      loss = loss_fn(prediction, y)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "# If you use the Keras Model.fit API, you won't have to worry about dataset iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.function best practices\n",
    "# It may take some time to get used to the behavior of Function. To get started quickly, \n",
    "# first-time users should play around with decorating toy functions with @tf.function \n",
    "# to get experience with going from eager to graph execution.\n",
    "\n",
    "# Designing for tf.function may be your best bet for writing graph-compatible TensorFlow programs. \n",
    "# Here are some tips:\n",
    "\n",
    "# Toggle between eager and graph execution early and often with tf.config.run_functions_eagerly to \n",
    "# pinpoint if/ when the two modes diverge.\n",
    "\n",
    "# Create tf.Variables outside the Python function and modify them on the inside. \n",
    "# The same goes for objects that use tf.Variable, like keras.layers, keras.Models and tf.optimizers.\n",
    "\n",
    "# Avoid writing functions that depend on outer Python variables, excluding tf.Variables and Keras objects.\n",
    "# Prefer to write functions which take tensors and other TensorFlow types as input. \n",
    "# You can pass in other object types but be careful!\n",
    "\n",
    "# Include as much computation as possible under a tf.function to maximize the performance gain.\n",
    "# For example, decorate a whole training step or the entire training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default is eager execution. \n",
    "# certain APIs like tf.function, tf.keras use Graph execution\n",
    "# to debug Graph execution fuction, use \"tf.config.run_functions_eagerly(True)\"\n",
    "\n",
    "@tf.function\n",
    "def f(x):\n",
    "  if x > 0:\n",
    "    import pdb\n",
    "    pdb.set_trace()\n",
    "    x = x + 1\n",
    "  return x\n",
    "\n",
    "tf.config.run_functions_eagerly(True)\n",
    "f(tf.constant(1)) # can use pdb to debug\n",
    "\n",
    "\n",
    "\n",
    "class CustomModel(tf.keras.models.Model):\n",
    "  @tf.function\n",
    "  def call(self, input_data):\n",
    "    if tf.reduce_mean(input_data) > 0:\n",
    "      return input_data\n",
    "    else:\n",
    "      import pdb\n",
    "      pdb.set_trace()\n",
    "      return input_data // 2\n",
    "\n",
    "\n",
    "tf.config.run_functions_eagerly(True)\n",
    "model = CustomModel()\n",
    "model(tf.constant([-2, -4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To log summaries, use tf.summary.(scalar|histogram|...) and redirect it to a writer using a context manager.\n",
    "# If you omit the context manager, nothing happens.\n",
    "summary_writer = tf.summary.create_file_writer('/tmp/summaries')\n",
    "with summary_writer.as_default():\n",
    "  tf.summary.scalar('loss', 0.1, step=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.metrics are stateful\n",
    "# Clear accumulated values with Model.reset_states.\n",
    "\n",
    "def train(model, optimizer, dataset, log_freq=10):\n",
    "  avg_loss = tf.keras.metrics.Mean(name='loss', dtype=tf.float32)\n",
    "  for images, labels in dataset:\n",
    "    loss = train_step(model, optimizer, images, labels)\n",
    "    avg_loss.update_state(loss)\n",
    "    if tf.equal(optimizer.iterations % log_freq, 0):\n",
    "      tf.summary.scalar('loss', avg_loss.result(), step=optimizer.iterations)\n",
    "      avg_loss.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tensor operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-03T03:56:25.399436Z",
     "start_time": "2021-08-03T03:56:25.393363Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<dtype: 'float32'>\n",
      "2\n",
      "(3, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dtype:\n",
    "# tf.float16: 16-bit half-precision floating-point.\n",
    "# tf.float32: 32-bit single-precision floating-point.\n",
    "# tf.float64: 64-bit double-precision floating-point.\n",
    "# tf.uint8: 8-bit unsigned integer.\n",
    "# tf.uint16: 16-bit unsigned integer.\n",
    "# tf.uint32: 32-bit unsigned integer.\n",
    "# tf.uint64: 64-bit unsigned integer.\n",
    "# tf.int8: 8-bit signed integer.\n",
    "# tf.int16: 16-bit signed integer.\n",
    "# tf.int32: 32-bit signed integer.\n",
    "# tf.int64: 64-bit signed integer.\n",
    "# tf.bool: Boolean.\n",
    "# tf.string: String.\n",
    "\n",
    "# shape: 标量，形状：[]  向量，形状: [3]\n",
    "\n",
    "zero = tf.zeros([3,4],dtype=tf.float32)\n",
    "\n",
    "print(zero.dtype)\n",
    "print(zero.ndim)\n",
    "print(zero.shape)\n",
    "zero.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-03T03:57:44.690173Z",
     "start_time": "2021-08-03T03:57:44.684450Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 3), dtype=float32, numpy=\n",
       "array([[0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reshape\n",
    "zero_r = tf.reshape(zero,[4,3])\n",
    "zero_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-03T03:59:02.414038Z",
     "start_time": "2021-08-03T03:59:02.410116Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 4), dtype=float64, numpy=\n",
       "array([[0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.]])>"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change data type\n",
    "zero_f64 = tf.cast(zero,dtype=tf.float64)\n",
    "zero_f64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-03T03:59:43.651570Z",
     "start_time": "2021-08-03T03:59:43.643641Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparseTensor(indices=tf.Tensor(\n",
      "[[0 0]\n",
      " [1 2]], shape=(2, 2), dtype=int64), values=tf.Tensor([1 2], shape=(2,), dtype=int32), dense_shape=tf.Tensor([3 4], shape=(2,), dtype=int64)) \n",
      "\n",
      "tf.Tensor(\n",
      "[[1 0 0 0]\n",
      " [0 0 2 0]\n",
      " [0 0 0 0]], shape=(3, 4), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# sparse tensor\n",
    "sparse_tensor = tf.sparse.SparseTensor(indices=[[0, 0], [1, 2]],\n",
    "                                       values=[1, 2],\n",
    "                                       dense_shape=[3, 4])\n",
    "print(sparse_tensor, \"\\n\")\n",
    "\n",
    "# to dense\n",
    "print(tf.sparse.to_dense(sparse_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 变量在创建时确定输入的维度，所以无需在声明时指定输入维度\n",
    "class FlexibleDenseModule(tf.Module):\n",
    "  # Note: No need for `in+features`\n",
    "  def __init__(self, out_features, name=None):\n",
    "    super().__init__(name=name)\n",
    "    self.is_built = False\n",
    "    self.out_features = out_features\n",
    "\n",
    "  def __call__(self, x):\n",
    "    # Create variables on first call.\n",
    "    if not self.is_built:\n",
    "      self.w = tf.Variable(\n",
    "        tf.random.normal([x.shape[-1], self.out_features]), name='w')\n",
    "      self.b = tf.Variable(tf.zeros([self.out_features]), name='b')\n",
    "      self.is_built = True\n",
    "\n",
    "    y = tf.matmul(x, self.w) + self.b\n",
    "    return tf.nn.relu(y)\n",
    "\n",
    "# Used in a module\n",
    "class MySequentialModule(tf.Module):\n",
    "  def __init__(self, name=None):\n",
    "    super().__init__(name=name)\n",
    "\n",
    "    self.dense_1 = FlexibleDenseModule(out_features=3)\n",
    "    self.dense_2 = FlexibleDenseModule(out_features=2)\n",
    "\n",
    "  def __call__(self, x):\n",
    "    x = self.dense_1(x)\n",
    "    return self.dense_2(x)\n",
    "\n",
    "my_model = MySequentialModule(name=\"the_model\")\n",
    "print(\"Model results:\", my_model(tf.constant([[2.0, 2.0, 2.0]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### variable length  tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-03T15:01:05.819947Z",
     "start_time": "2021-08-03T15:01:05.798061Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "queries = tf.ragged.constant([['Who', 'is', 'Dan', 'Smith'],\n",
    "                              ['Pause'],\n",
    "                              ['Will', 'it', 'rain', 'later', 'today']])\n",
    "\n",
    "# Create an embedding table.\n",
    "num_buckets = 1024\n",
    "embedding_size = 4\n",
    "embedding_table = tf.Variable(\n",
    "    tf.random.truncated_normal([num_buckets, embedding_size],\n",
    "                       stddev=1.0 / math.sqrt(embedding_size)))\n",
    "\n",
    "# Look up the embedding for each word.\n",
    "word_buckets = tf.strings.to_hash_bucket_fast(queries, num_buckets)\n",
    "word_embeddings = tf.nn.embedding_lookup(embedding_table, word_buckets)     # ①\n",
    "\n",
    "# Add markers to the beginning and end of each sentence.\n",
    "marker = tf.fill([queries.nrows(), 1], '#')\n",
    "padded = tf.concat([marker, queries, marker], axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-03T15:01:09.126466Z",
     "start_time": "2021-08-03T15:01:09.123198Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[b'#', b'Who', b'is', b'Dan', b'Smith', b'#'], [b'#', b'Pause', b'#'], [b'#', b'Will', b'it', b'rain', b'later', b'today', b'#']]>"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-03T15:03:10.559216Z",
     "start_time": "2021-08-03T15:03:10.556145Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(word_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-03T15:08:44.929875Z",
     "start_time": "2021-08-03T15:08:42.982320Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.local/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 1ms/step - loss: 5.6928\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 623us/step - loss: 2.2661\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 586us/step - loss: 2.0595\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 580us/step - loss: 1.9995\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 600us/step - loss: 1.9530\n",
      "[[0.02303804]\n",
      " [0.01037051]\n",
      " [0.02112119]\n",
      " [0.00715554]]\n"
     ]
    }
   ],
   "source": [
    "# Task: predict whether each sentence is a question or not.\n",
    "sentences = tf.constant(\n",
    "    ['What makes you think she is a witch?',\n",
    "     'She turned me into a newt.',\n",
    "     'A newt?',\n",
    "     'Well, I got better.'])\n",
    "is_question = tf.constant([True, False, True, False])\n",
    "\n",
    "# Preprocess the input strings.\n",
    "hash_buckets = 1000\n",
    "words = tf.strings.split(sentences, ' ')\n",
    "hashed_words = tf.strings.to_hash_bucket_fast(words, hash_buckets)\n",
    "# Build the Keras model.\n",
    "keras_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=[None], dtype=tf.int64, ragged=True),\n",
    "    tf.keras.layers.Embedding(hash_buckets, 16),\n",
    "    tf.keras.layers.LSTM(32, use_bias=False),\n",
    "    tf.keras.layers.Dense(32),\n",
    "    tf.keras.layers.Activation(tf.nn.relu),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "keras_model.compile(loss='binary_crossentropy', optimizer='rmsprop')\n",
    "keras_model.fit(hashed_words, is_question, epochs=5)\n",
    "print(keras_model.predict(hashed_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf example\n",
    "import google.protobuf.text_format as pbtext\n",
    "\n",
    "def build_tf_example(s):\n",
    "  return pbtext.Merge(s, tf.train.Example()).SerializeToString()\n",
    "\n",
    "example_batch = [\n",
    "  build_tf_example(r'''\n",
    "    features {\n",
    "      feature {key: \"colors\" value {bytes_list {value: [\"red\", \"blue\"]} } }\n",
    "      feature {key: \"lengths\" value {int64_list {value: [7]} } } }'''),\n",
    "  build_tf_example(r'''\n",
    "    features {\n",
    "      feature {key: \"colors\" value {bytes_list {value: [\"orange\"]} } }\n",
    "      feature {key: \"lengths\" value {int64_list {value: []} } } }'''),\n",
    "  build_tf_example(r'''\n",
    "    features {\n",
    "      feature {key: \"colors\" value {bytes_list {value: [\"black\", \"yellow\"]} } }\n",
    "      feature {key: \"lengths\" value {int64_list {value: [1, 3]} } } }'''),\n",
    "  build_tf_example(r'''\n",
    "    features {\n",
    "      feature {key: \"colors\" value {bytes_list {value: [\"green\"]} } }\n",
    "      feature {key: \"lengths\" value {int64_list {value: [3, 5, 2]} } } }''')]\n",
    "\n",
    "feature_specification = {\n",
    "    'colors': tf.io.RaggedFeature(tf.string),\n",
    "    'lengths': tf.io.RaggedFeature(tf.int64),\n",
    "}\n",
    "feature_tensors = tf.io.parse_example(example_batch, feature_specification)\n",
    "for name, value in feature_tensors.items():\n",
    "  print(\"{}={}\".format(name, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-03T15:19:07.950388Z",
     "start_time": "2021-08-03T15:19:07.941942Z"
    }
   },
   "outputs": [],
   "source": [
    "non_ragged_dataset = tf.data.Dataset.from_tensor_slices([1, 5, 3, 2, 8])\n",
    "non_ragged_dataset = non_ragged_dataset.map(tf.range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# referece https://www.tensorflow.org/guide/keras/functional?hl=zh-cn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequential\n",
    "\n",
    "# only for situation where exactly one input tensor and on output tensor\n",
    "\n",
    "# Define Sequential model with 3 layers\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        layers.Dense(2, activation=\"relu\", name=\"layer1\"),\n",
    "        layers.Dense(3, activation=\"relu\", name=\"layer2\"),\n",
    "        layers.Dense(4, name=\"layer3\"),\n",
    "    ]\n",
    ")\n",
    "# Call model on a test input\n",
    "x = tf.ones((3, 3))\n",
    "y = model(x)\n",
    "\n",
    "\n",
    "# Create 3 layers\n",
    "layer1 = layers.Dense(2, activation=\"relu\", name=\"layer1\")\n",
    "layer2 = layers.Dense(3, activation=\"relu\", name=\"layer2\")\n",
    "layer3 = layers.Dense(4, name=\"layer3\")\n",
    "\n",
    "# Call layers on a test input\n",
    "x = tf.ones((3, 3))\n",
    "y = layer3(layer2(layer1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras model:\n",
    "# two ways to get a keras model\n",
    "\n",
    "# first way is to use \"functional api\" where start from Input and \n",
    "# finally you create your model from inputs and outputs:\n",
    "inputs = tf.keras.Input(shape=(3,))\n",
    "x = tf.keras.layers.Dense(4, activation=tf.nn.relu)(inputs)\n",
    "outputs = tf.keras.layers.Dense(5, activation=tf.nn.softmax)(x)\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# second way is to create a object which is a subclass of keras.Model\n",
    "class MyModel(tf.keras.Model):\n",
    "  def __init__(self):\n",
    "    super(MyModel, self).__init__()\n",
    "    self.dense1 = tf.keras.layers.Dense(4, activation=tf.nn.relu)\n",
    "    self.dense2 = tf.keras.layers.Dense(5, activation=tf.nn.softmax)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    x = self.dense1(inputs)\n",
    "    return self.dense2(x)\n",
    "\n",
    "model = MyModel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T10:34:56.034775Z",
     "start_time": "2021-08-04T10:34:56.031678Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers.experimental import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T10:36:52.002348Z",
     "start_time": "2021-08-04T10:36:51.983731Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow.keras.layers.experimental.preprocessing' has no attribute 'IntegerLookup'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-209-ff10a96268f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Use IntegerLookup to build an index of the feature values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIntegerLookup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madapt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow.keras.layers.experimental.preprocessing' has no attribute 'IntegerLookup'"
     ]
    }
   ],
   "source": [
    "# Define some toy data\n",
    "data = tf.constant([10, 20, 20, 10, 30, 0])\n",
    "\n",
    "# Use IntegerLookup to build an index of the feature values\n",
    "indexer = preprocessing.IntegerLookup()\n",
    "indexer.adapt(data)\n",
    "\n",
    "# Use CategoryEncoding to encode the integer indices to a one-hot vector\n",
    "encoder = preprocessing.CategoryEncoding(output_mode=\"binary\")\n",
    "encoder.adapt(indexer(data))\n",
    "\n",
    "# Convert new test data (which includes unknown feature values)\n",
    "test_data = tf.constant([10, 10, 20, 50, 60, 0])\n",
    "encoded_data = encoder(indexer(test_data))\n",
    "print(encoded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-05T06:50:47.018028Z",
     "start_time": "2021-08-05T06:50:47.015595Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T11:00:52.612517Z",
     "start_time": "2021-08-04T11:00:52.605894Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 711  632   71    0    0    0]\n",
      " [  73    8 3215   55  927    0]\n",
      " [  83   91    1  645 1253  927]]\n"
     ]
    }
   ],
   "source": [
    "raw_inputs = [\n",
    "    [711, 632, 71],\n",
    "    [73, 8, 3215, 55, 927],\n",
    "    [83, 91, 1, 645, 1253, 927],\n",
    "]\n",
    "\n",
    "# By default, this will pad using 0s; it is configurable via the\n",
    "# \"value\" parameter.\n",
    "# Note that you could \"pre\" padding (at the beginning) or\n",
    "# \"post\" padding (at the end).\n",
    "# We recommend using \"post\" padding when working with RNN layers\n",
    "# (in order to be able to use the\n",
    "# CuDNN implementation of the layers).\n",
    "padded_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "    raw_inputs, padding=\"post\"\n",
    ")\n",
    "print(padded_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-05T06:50:50.210691Z",
     "start_time": "2021-08-05T06:50:50.202802Z"
    }
   },
   "outputs": [],
   "source": [
    "embedding = layers.Embedding(input_dim=5000, output_dim=16, mask_zero=True)\n",
    "masked_output = embedding(padded_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-05T06:50:58.323433Z",
     "start_time": "2021-08-05T06:50:58.320160Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ True  True  True False False False]\n",
      " [ True  True  True  True  True False]\n",
      " [ True  True  True  True  True  True]], shape=(3, 6), dtype=bool)\n"
     ]
    }
   ],
   "source": [
    "print(masked_output._keras_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-05T06:59:24.816872Z",
     "start_time": "2021-08-05T06:59:24.812414Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 6), dtype=bool, numpy=\n",
       "array([[ True,  True,  True, False, False, False],\n",
       "       [ True,  True,  True,  True,  True, False],\n",
       "       [ True,  True,  True,  True,  True,  True]])>"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding.compute_mask(padded_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T11:00:58.079374Z",
     "start_time": "2021-08-04T11:00:58.073367Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 6, 10), dtype=float32, numpy=\n",
       "array([[[7.110e+02, 7.110e+02, 7.110e+02, 7.110e+02, 7.110e+02,\n",
       "         7.110e+02, 7.110e+02, 7.110e+02, 7.110e+02, 7.110e+02],\n",
       "        [6.320e+02, 6.320e+02, 6.320e+02, 6.320e+02, 6.320e+02,\n",
       "         6.320e+02, 6.320e+02, 6.320e+02, 6.320e+02, 6.320e+02],\n",
       "        [7.100e+01, 7.100e+01, 7.100e+01, 7.100e+01, 7.100e+01,\n",
       "         7.100e+01, 7.100e+01, 7.100e+01, 7.100e+01, 7.100e+01],\n",
       "        [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "         0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
       "        [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "         0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
       "        [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "         0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00]],\n",
       "\n",
       "       [[7.300e+01, 7.300e+01, 7.300e+01, 7.300e+01, 7.300e+01,\n",
       "         7.300e+01, 7.300e+01, 7.300e+01, 7.300e+01, 7.300e+01],\n",
       "        [8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00,\n",
       "         8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00, 8.000e+00],\n",
       "        [3.215e+03, 3.215e+03, 3.215e+03, 3.215e+03, 3.215e+03,\n",
       "         3.215e+03, 3.215e+03, 3.215e+03, 3.215e+03, 3.215e+03],\n",
       "        [5.500e+01, 5.500e+01, 5.500e+01, 5.500e+01, 5.500e+01,\n",
       "         5.500e+01, 5.500e+01, 5.500e+01, 5.500e+01, 5.500e+01],\n",
       "        [9.270e+02, 9.270e+02, 9.270e+02, 9.270e+02, 9.270e+02,\n",
       "         9.270e+02, 9.270e+02, 9.270e+02, 9.270e+02, 9.270e+02],\n",
       "        [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "         0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00]],\n",
       "\n",
       "       [[8.300e+01, 8.300e+01, 8.300e+01, 8.300e+01, 8.300e+01,\n",
       "         8.300e+01, 8.300e+01, 8.300e+01, 8.300e+01, 8.300e+01],\n",
       "        [9.100e+01, 9.100e+01, 9.100e+01, 9.100e+01, 9.100e+01,\n",
       "         9.100e+01, 9.100e+01, 9.100e+01, 9.100e+01, 9.100e+01],\n",
       "        [1.000e+00, 1.000e+00, 1.000e+00, 1.000e+00, 1.000e+00,\n",
       "         1.000e+00, 1.000e+00, 1.000e+00, 1.000e+00, 1.000e+00],\n",
       "        [6.450e+02, 6.450e+02, 6.450e+02, 6.450e+02, 6.450e+02,\n",
       "         6.450e+02, 6.450e+02, 6.450e+02, 6.450e+02, 6.450e+02],\n",
       "        [1.253e+03, 1.253e+03, 1.253e+03, 1.253e+03, 1.253e+03,\n",
       "         1.253e+03, 1.253e+03, 1.253e+03, 1.253e+03, 1.253e+03],\n",
       "        [9.270e+02, 9.270e+02, 9.270e+02, 9.270e+02, 9.270e+02,\n",
       "         9.270e+02, 9.270e+02, 9.270e+02, 9.270e+02, 9.270e+02]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmasked_embedding = tf.cast(\n",
    "    tf.tile(tf.expand_dims(padded_inputs, axis=-1), [1, 1, 10]), tf.float32\n",
    ")\n",
    "unmasked_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在使用函数式 API 或序列式 API 时，由 Embedding 或 Masking 层生成的掩码将通过网络传播给任何能够使用它们的层（如 RNN 层）。\n",
    "# Keras 将自动提取与输入相对应的掩码，并将其传递给任何知道该掩码使用方法的层。\n",
    "# 例如，在下面的序贯模型中，LSTM 层将自动接收掩码，这意味着它将忽略填充的值：\n",
    "\n",
    "\n",
    "model = keras.Sequential(\n",
    "    [layers.Embedding(input_dim=5000, output_dim=16, mask_zero=True), layers.LSTM(32),]\n",
    ")\n",
    "\n",
    "inputs = keras.Input(shape=(None,), dtype=\"int32\")\n",
    "x = layers.Embedding(input_dim=5000, output_dim=16, mask_zero=True)(inputs)\n",
    "outputs = layers.LSTM(32)(x)\n",
    "\n",
    "model = keras.Model(inputs, outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-05T07:02:01.067483Z",
     "start_time": "2021-08-05T07:02:01.026354Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32, 32), dtype=float32, numpy=\n",
       "array([[ 0.00495397,  0.00249305, -0.00054821, ..., -0.00147414,\n",
       "         0.00012534, -0.00703044],\n",
       "       [ 0.00437572, -0.00014834, -0.00762161, ...,  0.00251274,\n",
       "         0.00028577,  0.00576928],\n",
       "       [-0.0003177 , -0.00157183,  0.00057587, ...,  0.00145412,\n",
       "         0.00819546, -0.00408571],\n",
       "       ...,\n",
       "       [ 0.00026466, -0.00576172, -0.00170023, ..., -0.00273737,\n",
       "         0.00999384,  0.00287618],\n",
       "       [ 0.00212171,  0.00030742, -0.00083584, ..., -0.00533008,\n",
       "         0.00745369,  0.00152066],\n",
       "       [ 0.00301097, -0.00383959, -0.00305695, ...,  0.00670212,\n",
       "         0.00123353, -0.00142203]], dtype=float32)>"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MyLayer(layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(MyLayer, self).__init__(**kwargs)\n",
    "        self.embedding = layers.Embedding(input_dim=5000, output_dim=16, mask_zero=True)\n",
    "        self.lstm = layers.LSTM(32)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.embedding(inputs)\n",
    "        # Note that you could also prepare a `mask` tensor manually.\n",
    "        # It only needs to be a boolean tensor\n",
    "        # with the right shape, i.e. (batch_size, timesteps).\n",
    "        mask = self.embedding.compute_mask(inputs)\n",
    "        output = self.lstm(x, mask=mask)  # The layer will ignore the masked values\n",
    "        return output\n",
    "\n",
    "\n",
    "layer = MyLayer()\n",
    "x = np.random.random((32, 10)) * 100\n",
    "x = x.astype(\"int32\")\n",
    "layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tensorflow 教程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### text classification with tf.keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-05T07:52:29.826817Z",
     "start_time": "2021-08-05T07:52:29.823228Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.3\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-05T07:53:14.097559Z",
     "start_time": "2021-08-05T07:53:08.102286Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "17465344/17464789 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "imdb = keras.datasets.imdb\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-05T07:53:50.101499Z",
     "start_time": "2021-08-05T07:53:50.098147Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training entries: 25000, labels: 25000\n"
     ]
    }
   ],
   "source": [
    "print(\"Training entries: {}, labels: {}\".format(len(train_data), len(train_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-05T07:54:29.275351Z",
     "start_time": "2021-08-05T07:54:29.272306Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0])\n",
    "print(train_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-05T07:54:46.176861Z",
     "start_time": "2021-08-05T07:54:45.284889Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
      "1646592/1641221 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "word_index = imdb.get_word_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-05T08:02:21.040738Z",
     "start_time": "2021-08-05T08:02:20.933442Z"
    }
   },
   "outputs": [],
   "source": [
    "# 一个映射单词到整数索引的词典\n",
    "word_index = imdb.get_word_index()\n",
    "\n",
    "# 保留第一个索引\n",
    "word_index = {k:(v+3) for k,v in word_index.items()}\n",
    "word_index[\"<PAD>\"] = 0\n",
    "word_index[\"<START>\"] = 1\n",
    "word_index[\"<UNK>\"] = 2  # unknown\n",
    "word_index[\"<UNUSED>\"] = 3\n",
    "\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "\n",
    "def decode_review(text):\n",
    "    return ' '.join([reverse_word_index.get(i, '?') for i in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-05T08:02:30.526007Z",
     "start_time": "2021-08-05T08:02:30.522645Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<START> this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert <UNK> is an amazing actor and now the same being director <UNK> father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for <UNK> and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also <UNK> to the two little boy's that played the <UNK> of norman and paul they were just brilliant children are often left out of the <UNK> list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\""
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_review(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-05T08:07:39.888517Z",
     "start_time": "2021-08-05T08:07:38.852668Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = keras.preprocessing.sequence.pad_sequences(train_data,\n",
    "                                                        value=word_index[\"<PAD>\"],\n",
    "                                                        padding='post',\n",
    "                                                        maxlen=256)\n",
    "\n",
    "test_data = keras.preprocessing.sequence.pad_sequences(test_data,\n",
    "                                                       value=word_index[\"<PAD>\"],\n",
    "                                                       padding='post',\n",
    "                                                       maxlen=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-05T08:07:59.008770Z",
     "start_time": "2021-08-05T08:07:59.004018Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   1,   14,   22,   16,   43,  530,  973, 1622, 1385,   65,  458,\n",
       "       4468,   66, 3941,    4,  173,   36,  256,    5,   25,  100,   43,\n",
       "        838,  112,   50,  670,    2,    9,   35,  480,  284,    5,  150,\n",
       "          4,  172,  112,  167,    2,  336,  385,   39,    4,  172, 4536,\n",
       "       1111,   17,  546,   38,   13,  447,    4,  192,   50,   16,    6,\n",
       "        147, 2025,   19,   14,   22,    4, 1920, 4613,  469,    4,   22,\n",
       "         71,   87,   12,   16,   43,  530,   38,   76,   15,   13, 1247,\n",
       "          4,   22,   17,  515,   17,   12,   16,  626,   18,    2,    5,\n",
       "         62,  386,   12,    8,  316,    8,  106,    5,    4, 2223, 5244,\n",
       "         16,  480,   66, 3785,   33,    4,  130,   12,   16,   38,  619,\n",
       "          5,   25,  124,   51,   36,  135,   48,   25, 1415,   33,    6,\n",
       "         22,   12,  215,   28,   77,   52,    5,   14,  407,   16,   82,\n",
       "          2,    8,    4,  107,  117, 5952,   15,  256,    4,    2,    7,\n",
       "       3766,    5,  723,   36,   71,   43,  530,  476,   26,  400,  317,\n",
       "         46,    7,    4,    2, 1029,   13,  104,   88,    4,  381,   15,\n",
       "        297,   98,   32, 2071,   56,   26,  141,    6,  194, 7486,   18,\n",
       "          4,  226,   22,   21,  134,  476,   26,  480,    5,  144,   30,\n",
       "       5535,   18,   51,   36,   28,  224,   92,   25,  104,    4,  226,\n",
       "         65,   16,   38, 1334,   88,   12,   16,  283,    5,   16, 4472,\n",
       "        113,  103,   32,   15,   16, 5345,   19,  178,   32,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0], dtype=int32)"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-05T08:09:58.924040Z",
     "start_time": "2021-08-05T08:09:58.885184Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, None, 16)          160000    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 160,289\n",
      "Trainable params: 160,289\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10000\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, 16))\n",
    "model.add(keras.layers.GlobalAveragePooling1D())\n",
    "model.add(keras.layers.Dense(16, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-05T08:10:16.735256Z",
     "start_time": "2021-08-05T08:10:16.724831Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-05T08:10:38.719039Z",
     "start_time": "2021-08-05T08:10:38.714664Z"
    }
   },
   "outputs": [],
   "source": [
    "x_val = train_data[:10000]\n",
    "partial_x_train = train_data[10000:]\n",
    "\n",
    "y_val = train_labels[:10000]\n",
    "partial_y_train = train_labels[10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-05T08:10:58.254012Z",
     "start_time": "2021-08-05T08:10:44.870280Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.6920 - accuracy: 0.5113 - val_loss: 0.6905 - val_accuracy: 0.5122\n",
      "Epoch 2/40\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.6869 - accuracy: 0.6621 - val_loss: 0.6836 - val_accuracy: 0.5767\n",
      "Epoch 3/40\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.6759 - accuracy: 0.6473 - val_loss: 0.6697 - val_accuracy: 0.6837\n",
      "Epoch 4/40\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.6559 - accuracy: 0.7303 - val_loss: 0.6470 - val_accuracy: 0.7337\n",
      "Epoch 5/40\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.6265 - accuracy: 0.7722 - val_loss: 0.6166 - val_accuracy: 0.7555\n",
      "Epoch 6/40\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.5887 - accuracy: 0.8007 - val_loss: 0.5787 - val_accuracy: 0.7975\n",
      "Epoch 7/40\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.5453 - accuracy: 0.8235 - val_loss: 0.5382 - val_accuracy: 0.8184\n",
      "Epoch 8/40\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.5008 - accuracy: 0.8443 - val_loss: 0.4982 - val_accuracy: 0.8301\n",
      "Epoch 9/40\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.4579 - accuracy: 0.8590 - val_loss: 0.4625 - val_accuracy: 0.8395\n",
      "Epoch 10/40\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.4191 - accuracy: 0.8691 - val_loss: 0.4299 - val_accuracy: 0.8500\n",
      "Epoch 11/40\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.3846 - accuracy: 0.8794 - val_loss: 0.4035 - val_accuracy: 0.8545\n",
      "Epoch 12/40\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.3555 - accuracy: 0.8868 - val_loss: 0.3816 - val_accuracy: 0.8612\n",
      "Epoch 13/40\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.3303 - accuracy: 0.8940 - val_loss: 0.3629 - val_accuracy: 0.8669\n",
      "Epoch 14/40\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.3083 - accuracy: 0.8993 - val_loss: 0.3480 - val_accuracy: 0.8718\n",
      "Epoch 15/40\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.2897 - accuracy: 0.9038 - val_loss: 0.3375 - val_accuracy: 0.8714\n",
      "Epoch 16/40\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.2733 - accuracy: 0.9091 - val_loss: 0.3261 - val_accuracy: 0.8762\n",
      "Epoch 17/40\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.2585 - accuracy: 0.9135 - val_loss: 0.3179 - val_accuracy: 0.8781\n",
      "Epoch 18/40\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.2452 - accuracy: 0.9188 - val_loss: 0.3112 - val_accuracy: 0.8794\n",
      "Epoch 19/40\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.2332 - accuracy: 0.9223 - val_loss: 0.3056 - val_accuracy: 0.8809\n",
      "Epoch 20/40\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.2219 - accuracy: 0.9259 - val_loss: 0.3009 - val_accuracy: 0.8822\n",
      "Epoch 21/40\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.2121 - accuracy: 0.9282 - val_loss: 0.2969 - val_accuracy: 0.8825\n",
      "Epoch 22/40\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.2027 - accuracy: 0.9315 - val_loss: 0.2941 - val_accuracy: 0.8835\n",
      "Epoch 23/40\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.1939 - accuracy: 0.9353 - val_loss: 0.2920 - val_accuracy: 0.8842\n",
      "Epoch 24/40\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.1860 - accuracy: 0.9385 - val_loss: 0.2899 - val_accuracy: 0.8842\n",
      "Epoch 25/40\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.1779 - accuracy: 0.9431 - val_loss: 0.2885 - val_accuracy: 0.8844\n",
      "Epoch 26/40\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.1709 - accuracy: 0.9462 - val_loss: 0.2873 - val_accuracy: 0.8852\n",
      "Epoch 27/40\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.1639 - accuracy: 0.9483 - val_loss: 0.2866 - val_accuracy: 0.8850\n",
      "Epoch 28/40\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.1574 - accuracy: 0.9510 - val_loss: 0.2876 - val_accuracy: 0.8840\n",
      "Epoch 29/40\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.1514 - accuracy: 0.9534 - val_loss: 0.2871 - val_accuracy: 0.8852\n",
      "Epoch 30/40\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.1458 - accuracy: 0.9565 - val_loss: 0.2882 - val_accuracy: 0.8842\n",
      "Epoch 31/40\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.1403 - accuracy: 0.9588 - val_loss: 0.2889 - val_accuracy: 0.8855\n",
      "Epoch 32/40\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.1347 - accuracy: 0.9605 - val_loss: 0.2897 - val_accuracy: 0.8859\n",
      "Epoch 33/40\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.1297 - accuracy: 0.9627 - val_loss: 0.2908 - val_accuracy: 0.8851\n",
      "Epoch 34/40\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.1251 - accuracy: 0.9647 - val_loss: 0.2918 - val_accuracy: 0.8849\n",
      "Epoch 35/40\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.1203 - accuracy: 0.9661 - val_loss: 0.2937 - val_accuracy: 0.8848\n",
      "Epoch 36/40\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.1160 - accuracy: 0.9674 - val_loss: 0.2964 - val_accuracy: 0.8848\n",
      "Epoch 37/40\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.1115 - accuracy: 0.9695 - val_loss: 0.2980 - val_accuracy: 0.8854\n",
      "Epoch 38/40\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.1078 - accuracy: 0.9700 - val_loss: 0.3013 - val_accuracy: 0.8832\n",
      "Epoch 39/40\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.1039 - accuracy: 0.9715 - val_loss: 0.3024 - val_accuracy: 0.8828\n",
      "Epoch 40/40\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.1000 - accuracy: 0.9738 - val_loss: 0.3052 - val_accuracy: 0.8834\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=40,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-05T08:11:12.310741Z",
     "start_time": "2021-08-05T08:11:11.692329Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 - 1s - loss: 0.3241 - accuracy: 0.8732\n",
      "[0.32414475083351135, 0.873199999332428]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(test_data,  test_labels, verbose=2)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### another example "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-05T10:09:49.532064Z",
     "start_time": "2021-08-05T10:09:49.402706Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:TFDS datasets with text encoding are deprecated and will be removed in a future version. Instead, you should use the plain text version and tokenize the text using `tensorflow_text` (See: https://www.tensorflow.org/tutorials/tensorflow_text/intro#tfdata_example)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "\n",
    "dataset, info = tfds.load('imdb_reviews/subwords8k', with_info=True,\n",
    "                          as_supervised=True)\n",
    "train_dataset, test_dataset = dataset['train'], dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-05T10:05:27.129685Z",
     "start_time": "2021-08-05T10:05:27.117003Z"
    }
   },
   "outputs": [],
   "source": [
    "filepath= '/home/jovyan/tensorflow_datasets/imdb_reviews/subwords8k/1.0.0/imdb_reviews-train.tfrecord-00000-of-00001'\n",
    "imdbdataset = tf.data.TFRecordDataset(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-05T10:06:09.558024Z",
     "start_time": "2021-08-05T10:06:09.228879Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features {\n",
      "  feature {\n",
      "    key: \"i\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 0\n",
      "        value: 1\n",
      "        value: 3\n",
      "        value: 4\n",
      "        value: 5\n",
      "        value: 6\n",
      "        value: 7\n",
      "        value: 8\n",
      "        value: 9\n",
      "        value: 10\n",
      "        value: 11\n",
      "        value: 12\n",
      "        value: 16\n",
      "        value: 17\n",
      "        value: 19\n",
      "        value: 20\n",
      "        value: 22\n",
      "        value: 23\n",
      "        value: 25\n",
      "        value: 26\n",
      "        value: 28\n",
      "        value: 29\n",
      "        value: 31\n",
      "        value: 32\n",
      "        value: 34\n",
      "        value: 35\n",
      "        value: 37\n",
      "        value: 38\n",
      "        value: 40\n",
      "        value: 41\n",
      "        value: 43\n",
      "        value: 44\n",
      "        value: 46\n",
      "        value: 47\n",
      "        value: 49\n",
      "        value: 50\n",
      "        value: 52\n",
      "        value: 53\n",
      "        value: 55\n",
      "        value: 56\n",
      "        value: 58\n",
      "        value: 59\n",
      "        value: 61\n",
      "        value: 62\n",
      "        value: 64\n",
      "        value: 65\n",
      "        value: 67\n",
      "        value: 68\n",
      "        value: 70\n",
      "        value: 71\n",
      "        value: 73\n",
      "        value: 74\n",
      "        value: 76\n",
      "        value: 77\n",
      "        value: 79\n",
      "        value: 80\n",
      "        value: 82\n",
      "        value: 83\n",
      "        value: 85\n",
      "        value: 86\n",
      "        value: 88\n",
      "        value: 89\n",
      "        value: 91\n",
      "        value: 92\n",
      "        value: 94\n",
      "        value: 95\n",
      "        value: 97\n",
      "        value: 98\n",
      "        value: 100\n",
      "        value: 101\n",
      "        value: 103\n",
      "        value: 104\n",
      "        value: 106\n",
      "        value: 107\n",
      "        value: 108\n",
      "        value: 109\n",
      "        value: 110\n",
      "        value: 111\n",
      "        value: 112\n",
      "        value: 113\n",
      "        value: 114\n",
      "        value: 115\n",
      "        value: 116\n",
      "        value: 117\n",
      "        value: 118\n",
      "        value: 119\n",
      "        value: 120\n",
      "        value: 121\n",
      "        value: 122\n",
      "        value: 123\n",
      "        value: 124\n",
      "        value: 125\n",
      "        value: 126\n",
      "        value: 127\n",
      "        value: 128\n",
      "        value: 129\n",
      "        value: 130\n",
      "        value: 131\n",
      "        value: 132\n",
      "        value: 133\n",
      "        value: 135\n",
      "        value: 136\n",
      "        value: 137\n",
      "        value: 138\n",
      "        value: 139\n",
      "        value: 140\n",
      "        value: 141\n",
      "        value: 142\n",
      "        value: 143\n",
      "        value: 144\n",
      "        value: 145\n",
      "        value: 146\n",
      "        value: 147\n",
      "        value: 148\n",
      "        value: 149\n",
      "        value: 150\n",
      "        value: 151\n",
      "        value: 152\n",
      "        value: 153\n",
      "        value: 154\n",
      "        value: 155\n",
      "        value: 156\n",
      "        value: 157\n",
      "        value: 158\n",
      "        value: 159\n",
      "        value: 160\n",
      "        value: 161\n",
      "        value: 162\n",
      "        value: 163\n",
      "        value: 164\n",
      "        value: 165\n",
      "        value: 166\n",
      "        value: 167\n",
      "        value: 169\n",
      "        value: 170\n",
      "        value: 172\n",
      "        value: 173\n",
      "        value: 174\n",
      "        value: 175\n",
      "        value: 176\n",
      "        value: 177\n",
      "        value: 178\n",
      "        value: 179\n",
      "        value: 180\n",
      "        value: 181\n",
      "        value: 182\n",
      "        value: 183\n",
      "        value: 184\n",
      "        value: 185\n",
      "        value: 186\n",
      "        value: 187\n",
      "        value: 188\n",
      "        value: 189\n",
      "        value: 190\n",
      "        value: 191\n",
      "        value: 192\n",
      "        value: 193\n",
      "        value: 194\n",
      "        value: 195\n",
      "        value: 196\n",
      "        value: 197\n",
      "        value: 198\n",
      "        value: 199\n",
      "        value: 200\n",
      "        value: 201\n",
      "        value: 202\n",
      "        value: 203\n",
      "        value: 204\n",
      "        value: 205\n",
      "        value: 206\n",
      "        value: 207\n",
      "        value: 208\n",
      "        value: 209\n",
      "        value: 210\n",
      "        value: 211\n",
      "        value: 212\n",
      "        value: 213\n",
      "        value: 214\n",
      "        value: 215\n",
      "        value: 216\n",
      "        value: 217\n",
      "        value: 219\n",
      "        value: 220\n",
      "        value: 222\n",
      "        value: 223\n",
      "        value: 224\n",
      "        value: 225\n",
      "        value: 226\n",
      "        value: 227\n",
      "        value: 228\n",
      "        value: 229\n",
      "        value: 230\n",
      "        value: 231\n",
      "        value: 232\n",
      "        value: 233\n",
      "        value: 234\n",
      "        value: 235\n",
      "        value: 236\n",
      "        value: 237\n",
      "        value: 238\n",
      "        value: 239\n",
      "        value: 240\n",
      "        value: 241\n",
      "        value: 242\n",
      "        value: 243\n",
      "        value: 244\n",
      "        value: 245\n",
      "        value: 246\n",
      "        value: 247\n",
      "        value: 248\n",
      "        value: 249\n",
      "        value: 250\n",
      "        value: 251\n",
      "        value: 252\n",
      "        value: 253\n",
      "        value: 254\n",
      "        value: 255\n",
      "        value: 256\n",
      "        value: 257\n",
      "        value: 258\n",
      "        value: 259\n",
      "        value: 260\n",
      "        value: 261\n",
      "        value: 262\n",
      "        value: 263\n",
      "        value: 264\n",
      "        value: 265\n",
      "        value: 266\n",
      "        value: 267\n",
      "        value: 268\n",
      "        value: 269\n",
      "        value: 270\n",
      "        value: 271\n",
      "        value: 272\n",
      "        value: 273\n",
      "        value: 274\n",
      "        value: 275\n",
      "        value: 276\n",
      "        value: 277\n",
      "        value: 278\n",
      "        value: 279\n",
      "        value: 280\n",
      "        value: 281\n",
      "        value: 282\n",
      "        value: 283\n",
      "        value: 284\n",
      "        value: 285\n",
      "        value: 286\n",
      "        value: 287\n",
      "        value: 288\n",
      "        value: 289\n",
      "        value: 290\n",
      "        value: 291\n",
      "        value: 292\n",
      "        value: 293\n",
      "        value: 294\n",
      "        value: 295\n",
      "        value: 296\n",
      "        value: 297\n",
      "        value: 298\n",
      "        value: 299\n",
      "        value: 300\n",
      "        value: 301\n",
      "        value: 302\n",
      "        value: 303\n",
      "        value: 304\n",
      "        value: 305\n",
      "        value: 306\n",
      "        value: 307\n",
      "        value: 308\n",
      "        value: 309\n",
      "        value: 310\n",
      "        value: 311\n",
      "        value: 312\n",
      "        value: 313\n",
      "        value: 314\n",
      "        value: 315\n",
      "        value: 316\n",
      "        value: 317\n",
      "        value: 318\n",
      "        value: 319\n",
      "        value: 320\n",
      "        value: 321\n",
      "        value: 322\n",
      "        value: 323\n",
      "        value: 324\n",
      "        value: 325\n",
      "        value: 326\n",
      "        value: 327\n",
      "        value: 328\n",
      "        value: 329\n",
      "        value: 330\n",
      "        value: 331\n",
      "        value: 332\n",
      "        value: 333\n",
      "        value: 334\n",
      "        value: 335\n",
      "        value: 336\n",
      "        value: 337\n",
      "        value: 338\n",
      "        value: 339\n",
      "        value: 340\n",
      "        value: 341\n",
      "        value: 342\n",
      "        value: 343\n",
      "        value: 344\n",
      "        value: 345\n",
      "        value: 346\n",
      "        value: 347\n",
      "        value: 348\n",
      "        value: 349\n",
      "        value: 350\n",
      "        value: 351\n",
      "        value: 352\n",
      "        value: 353\n",
      "        value: 354\n",
      "        value: 355\n",
      "        value: 356\n",
      "        value: 357\n",
      "        value: 358\n",
      "        value: 359\n",
      "        value: 360\n",
      "        value: 361\n",
      "        value: 362\n",
      "        value: 363\n",
      "        value: 364\n",
      "        value: 365\n",
      "        value: 366\n",
      "        value: 367\n",
      "        value: 368\n",
      "        value: 369\n",
      "        value: 372\n",
      "        value: 373\n",
      "        value: 374\n",
      "        value: 375\n",
      "        value: 378\n",
      "        value: 379\n",
      "        value: 380\n",
      "        value: 381\n",
      "        value: 382\n",
      "        value: 383\n",
      "        value: 384\n",
      "        value: 385\n",
      "        value: 386\n",
      "        value: 387\n",
      "        value: 408\n",
      "        value: 409\n",
      "        value: 412\n",
      "        value: 413\n",
      "        value: 414\n",
      "        value: 415\n",
      "        value: 423\n",
      "        value: 424\n",
      "        value: 427\n",
      "        value: 428\n",
      "        value: 429\n",
      "        value: 430\n",
      "        value: 432\n",
      "        value: 434\n",
      "        value: 435\n",
      "        value: 436\n",
      "        value: 437\n",
      "        value: 438\n",
      "        value: 439\n",
      "        value: 440\n",
      "        value: 441\n",
      "        value: 442\n",
      "        value: 443\n",
      "        value: 444\n",
      "        value: 445\n",
      "        value: 446\n",
      "        value: 447\n",
      "        value: 448\n",
      "        value: 449\n",
      "        value: 450\n",
      "        value: 451\n",
      "        value: 452\n",
      "        value: 453\n",
      "        value: 454\n",
      "        value: 455\n",
      "        value: 456\n",
      "        value: 457\n",
      "        value: 458\n",
      "        value: 459\n",
      "        value: 460\n",
      "        value: 461\n",
      "        value: 462\n",
      "        value: 463\n",
      "        value: 464\n",
      "        value: 465\n",
      "        value: 466\n",
      "        value: 467\n",
      "        value: 468\n",
      "        value: 469\n",
      "        value: 470\n",
      "        value: 471\n",
      "        value: 472\n",
      "        value: 473\n",
      "        value: 474\n",
      "        value: 475\n",
      "        value: 476\n",
      "        value: 477\n",
      "        value: 478\n",
      "        value: 479\n",
      "        value: 480\n",
      "        value: 481\n",
      "        value: 482\n",
      "        value: 483\n",
      "        value: 484\n",
      "        value: 485\n",
      "        value: 486\n",
      "        value: 487\n",
      "        value: 488\n",
      "        value: 489\n",
      "        value: 490\n",
      "        value: 491\n",
      "        value: 492\n",
      "        value: 493\n",
      "        value: 494\n",
      "        value: 495\n",
      "        value: 496\n",
      "        value: 497\n",
      "        value: 498\n",
      "        value: 499\n",
      "        value: 500\n",
      "        value: 501\n",
      "        value: 502\n",
      "        value: 503\n",
      "        value: 504\n",
      "        value: 505\n",
      "        value: 506\n",
      "        value: 507\n",
      "        value: 508\n",
      "        value: 509\n",
      "        value: 510\n",
      "        value: 511\n",
      "        value: 512\n",
      "        value: 513\n",
      "        value: 514\n",
      "        value: 515\n",
      "        value: 516\n",
      "        value: 517\n",
      "        value: 518\n",
      "        value: 519\n",
      "        value: 520\n",
      "        value: 521\n",
      "        value: 522\n",
      "        value: 523\n",
      "        value: 524\n",
      "        value: 525\n",
      "        value: 526\n",
      "        value: 530\n",
      "        value: 531\n",
      "        value: 532\n",
      "        value: 533\n",
      "        value: 534\n",
      "        value: 535\n",
      "        value: 537\n",
      "        value: 538\n",
      "        value: 540\n",
      "        value: 545\n",
      "        value: 546\n",
      "        value: 547\n",
      "        value: 548\n",
      "        value: 549\n",
      "        value: 550\n",
      "        value: 551\n",
      "        value: 552\n",
      "        value: 553\n",
      "        value: 554\n",
      "        value: 555\n",
      "        value: 556\n",
      "        value: 557\n",
      "        value: 558\n",
      "        value: 559\n",
      "        value: 560\n",
      "        value: 561\n",
      "        value: 562\n",
      "        value: 563\n",
      "        value: 564\n",
      "        value: 565\n",
      "        value: 566\n",
      "        value: 567\n",
      "        value: 568\n",
      "        value: 569\n",
      "        value: 570\n",
      "        value: 571\n",
      "        value: 572\n",
      "        value: 577\n",
      "        value: 582\n",
      "        value: 590\n",
      "        value: 591\n",
      "        value: 593\n",
      "        value: 598\n",
      "        value: 601\n",
      "        value: 606\n",
      "        value: 613\n",
      "        value: 614\n",
      "        value: 615\n",
      "        value: 616\n",
      "        value: 617\n",
      "        value: 618\n",
      "        value: 622\n",
      "        value: 631\n",
      "        value: 633\n",
      "        value: 634\n",
      "        value: 635\n",
      "        value: 636\n",
      "        value: 637\n",
      "        value: 638\n",
      "        value: 639\n",
      "        value: 640\n",
      "        value: 641\n",
      "        value: 642\n",
      "        value: 643\n",
      "        value: 644\n",
      "        value: 645\n",
      "        value: 646\n",
      "        value: 647\n",
      "        value: 648\n",
      "        value: 649\n",
      "        value: 650\n",
      "        value: 651\n",
      "        value: 652\n",
      "        value: 653\n",
      "        value: 654\n",
      "        value: 655\n",
      "        value: 656\n",
      "        value: 657\n",
      "        value: 658\n",
      "        value: 659\n",
      "        value: 660\n",
      "        value: 661\n",
      "        value: 662\n",
      "        value: 663\n",
      "        value: 664\n",
      "        value: 665\n",
      "        value: 666\n",
      "        value: 667\n",
      "        value: 668\n",
      "        value: 669\n",
      "        value: 670\n",
      "        value: 671\n",
      "        value: 672\n",
      "        value: 673\n",
      "        value: 674\n",
      "        value: 675\n",
      "        value: 676\n",
      "        value: 677\n",
      "        value: 678\n",
      "        value: 679\n",
      "        value: 680\n",
      "        value: 681\n",
      "        value: 682\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"l\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 1\n",
      "        value: 1\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"v\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 8222342.0\n",
      "        value: 804.0\n",
      "        value: 168.0\n",
      "        value: 557509.0\n",
      "        value: 390.0\n",
      "        value: 430927.0\n",
      "        value: 9847574.0\n",
      "        value: 4019294.0\n",
      "        value: 145099.0\n",
      "        value: 100011.0\n",
      "        value: 100054.0\n",
      "        value: 100242.0\n",
      "        value: 3369743.0\n",
      "        value: 66.0\n",
      "        value: 6930724.0\n",
      "        value: 457.0\n",
      "        value: 6158171.0\n",
      "        value: 901.0\n",
      "        value: 238618.0\n",
      "        value: 970.0\n",
      "        value: 538991.0\n",
      "        value: 655.0\n",
      "        value: 8399367.0\n",
      "        value: 664.0\n",
      "        value: 106953.0\n",
      "        value: 656.0\n",
      "        value: 7191000.0\n",
      "        value: 811.0\n",
      "        value: 106953.0\n",
      "        value: 656.0\n",
      "        value: 5089237.0\n",
      "        value: 504.0\n",
      "        value: 5746280.0\n",
      "        value: 303.0\n",
      "        value: 168634.0\n",
      "        value: 698.0\n",
      "        value: 6742011.0\n",
      "        value: 302.0\n",
      "        value: 1936536.0\n",
      "        value: 474.0\n",
      "        value: 8580863.0\n",
      "        value: 291.0\n",
      "        value: 2268042.0\n",
      "        value: 812.0\n",
      "        value: 1772115.0\n",
      "        value: 206.0\n",
      "        value: 6923356.0\n",
      "        value: 500.0\n",
      "        value: 6842744.0\n",
      "        value: 354.0\n",
      "        value: 6775477.0\n",
      "        value: 641.0\n",
      "        value: 1549222.0\n",
      "        value: 216.0\n",
      "        value: 2240049.0\n",
      "        value: 289.0\n",
      "        value: 1771666.0\n",
      "        value: 973.0\n",
      "        value: 8396765.0\n",
      "        value: 924.0\n",
      "        value: 3382315.0\n",
      "        value: 62.0\n",
      "        value: 6650993.0\n",
      "        value: 59.0\n",
      "        value: 9440216.0\n",
      "        value: 567.0\n",
      "        value: 3409095.0\n",
      "        value: 62.0\n",
      "        value: 3409095.0\n",
      "        value: 62.0\n",
      "        value: 3409095.0\n",
      "        value: 62.0\n",
      "        value: 11.0\n",
      "        value: 413837.0\n",
      "        value: 11.0\n",
      "        value: 413837.0\n",
      "        value: 11.0\n",
      "        value: 413837.0\n",
      "        value: 11.0\n",
      "        value: 413837.0\n",
      "        value: 280.0\n",
      "        value: 768787.0\n",
      "        value: 280.0\n",
      "        value: 768787.0\n",
      "        value: 6.0\n",
      "        value: 852976.0\n",
      "        value: 6.0\n",
      "        value: 852976.0\n",
      "        value: 6.0\n",
      "        value: 852976.0\n",
      "        value: 6.0\n",
      "        value: 852976.0\n",
      "        value: 20.0\n",
      "        value: 544865.0\n",
      "        value: 20.0\n",
      "        value: 544865.0\n",
      "        value: 20.0\n",
      "        value: 544865.0\n",
      "        value: 272.0\n",
      "        value: 426058.0\n",
      "        value: 920406.0\n",
      "        value: 50.0\n",
      "        value: 972887.0\n",
      "        value: 136.0\n",
      "        value: 945184.0\n",
      "        value: 136.0\n",
      "        value: 945184.0\n",
      "        value: 136.0\n",
      "        value: 945184.0\n",
      "        value: 136.0\n",
      "        value: 945184.0\n",
      "        value: 136.0\n",
      "        value: 945184.0\n",
      "        value: 136.0\n",
      "        value: 945184.0\n",
      "        value: 45.0\n",
      "        value: 495764.0\n",
      "        value: 45.0\n",
      "        value: 495764.0\n",
      "        value: 17.0\n",
      "        value: 566419.0\n",
      "        value: 16.0\n",
      "        value: 190837.0\n",
      "        value: 277.0\n",
      "        value: 260554.0\n",
      "        value: 17.0\n",
      "        value: 566419.0\n",
      "        value: 17.0\n",
      "        value: 566419.0\n",
      "        value: 17.0\n",
      "        value: 566419.0\n",
      "        value: 2153530.0\n",
      "        value: 841.0\n",
      "        value: 2153530.0\n",
      "        value: 841.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 237.0\n",
      "        value: 801529.0\n",
      "        value: 237.0\n",
      "        value: 801529.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 2153530.0\n",
      "        value: 841.0\n",
      "        value: 2153530.0\n",
      "        value: 841.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 10000000.0\n",
      "        value: 237.0\n",
      "        value: 801529.0\n",
      "        value: 237.0\n",
      "        value: 801529.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 1000000.0\n",
      "        value: 162.0\n",
      "        value: 117.0\n",
      "        value: 265.0\n",
      "        value: 218.0\n",
      "        value: 161.0\n",
      "        value: 110.0\n",
      "        value: 267.0\n",
      "        value: 214.0\n",
      "        value: 262.0\n",
      "        value: 215.0\n",
      "        value: 34.0\n",
      "        value: 5.0\n",
      "        value: 149.0\n",
      "        value: 110.0\n",
      "        value: 236.0\n",
      "        value: 209.0\n",
      "        value: 102.0\n",
      "        value: 102.0\n",
      "        value: 36.0\n",
      "        value: 73.0\n",
      "        value: 83.0\n",
      "        value: 99.0\n",
      "        value: 39.0\n",
      "        value: 64.0\n",
      "        value: 1.0\n",
      "        value: 0.20000000298023224\n",
      "        value: 0.00949000008404255\n",
      "        value: 0.28916457295417786\n",
      "        value: 0.28916457295417786\n",
      "        value: 0.28916457295417786\n",
      "        value: 0.04771212488412857\n",
      "        value: 0.18687649071216583\n",
      "        value: 0.07893134653568268\n",
      "        value: 0.03527971729636192\n",
      "        value: 0.029898857697844505\n",
      "        value: 0.08108308166265488\n",
      "        value: 0.04898178204894066\n",
      "        value: -0.01655319705605507\n",
      "        value: 0.0006667228881269693\n",
      "        value: -0.009364018216729164\n",
      "        value: 0.07987897098064423\n",
      "        value: -0.06798361241817474\n",
      "        value: 0.08175204694271088\n",
      "        value: -0.026881350204348564\n",
      "        value: -0.015727069228887558\n",
      "        value: -0.008201665244996548\n",
      "        value: 0.05083167925477028\n",
      "        value: 0.03144090995192528\n",
      "        value: 0.8999999761581421\n",
      "        value: 0.10000000149011612\n",
      "        value: 0.27535831928253174\n",
      "        value: 0.3820595443248749\n",
      "        value: 0.025728987529873848\n",
      "        value: 0.9708404541015625\n",
      "        value: 0.9549828171730042\n",
      "        value: 0.24440447986125946\n",
      "        value: 0.4708446264266968\n",
      "        value: 0.3852967619895935\n",
      "        value: 0.13648957014083862\n",
      "        value: 0.43176454305648804\n",
      "        value: 0.3453165292739868\n",
      "        value: 0.13197806477546692\n",
      "        value: 0.4001084268093109\n",
      "        value: 0.1274501383304596\n",
      "        value: 0.36440443992614746\n",
      "        value: 0.11410680413246155\n",
      "        value: 0.6377732753753662\n",
      "        value: 0.5123364925384521\n",
      "        value: 0.05538075789809227\n",
      "        value: 0.49121636152267456\n",
      "        value: 0.04898495227098465\n",
      "        value: 0.605477511882782\n",
      "        value: 0.4719206988811493\n",
      "        value: 0.0457921102643013\n",
      "        value: 0.4375736713409424\n",
      "        value: 0.044896114617586136\n",
      "        value: 0.6343784928321838\n",
      "        value: 0.5041976571083069\n",
      "        value: 0.0496235117316246\n",
      "        value: 0.5981580018997192\n",
      "        value: 0.46745580434799194\n",
      "        value: 0.04888223111629486\n",
      "        value: 0.5673280954360962\n",
      "        value: 0.4371917247772217\n",
      "        value: 0.04934122785925865\n",
      "        value: 0.5323781967163086\n",
      "        value: 0.04944075271487236\n",
      "        value: 0.4025960862636566\n",
      "        value: 0.8478445410728455\n",
      "        value: 0.992749810218811\n",
      "        value: 0.0355549156665802\n",
      "        value: 0.8144431710243225\n",
      "        value: 0.9604353308677673\n",
      "        value: 0.03467431664466858\n",
      "        value: 0.7573500871658325\n",
      "        value: 0.900134265422821\n",
      "        value: 0.037326883524656296\n",
      "        value: 0.5468329787254333\n",
      "        value: 0.41772767901420593\n",
      "        value: 0.05036814138293266\n",
      "        value: 0.5465898513793945\n",
      "        value: 0.4176322817802429\n",
      "        value: 0.050538938492536545\n",
      "        value: 0.5463558435440063\n",
      "        value: 0.4175221920013428\n",
      "        value: 0.05068238452076912\n",
      "        value: 0.1623249351978302\n",
      "        value: 0.005568529013544321\n",
      "        value: 0.004243576433509588\n",
      "        value: 1.0\n",
      "        value: 0.1840577870607376\n",
      "        value: 0.006369345355778933\n",
      "        value: 0.040498122572898865\n",
      "        value: 0.31781134009361267\n",
      "        value: 0.29813656210899353\n",
      "        value: 0.31159430742263794\n",
      "        value: 0.006762887816876173\n",
      "        value: 0.29020029306411743\n",
      "        value: 0.006840972695499659\n",
      "        value: 0.005422570277005434\n",
      "        value: 0.21875207126140594\n",
      "        value: 0.005500686354935169\n",
      "        value: 0.5014258027076721\n",
      "        value: 0.00016576572670601308\n",
      "        value: 0.06326674669981003\n",
      "        value: 0.054148945957422256\n",
      "        value: 0.023642636835575104\n",
      "        value: 0.02195098251104355\n",
      "        value: 0.8999999761581421\n",
      "        value: 0.33083510398864746\n",
      "        value: 0.12041199952363968\n",
      "        value: 0.2845357358455658\n",
      "        value: 1.0\n",
      "        value: 0.36492374539375305\n",
      "        value: 0.30182844400405884\n",
      "        value: 0.16020600497722626\n",
      "        value: 0.07781512290239334\n",
      "        value: 0.9447887539863586\n",
      "        value: 0.4711334705352783\n",
      "        value: 0.38543060421943665\n",
      "        value: 0.13600704073905945\n",
      "        value: 0.43214741349220276\n",
      "        value: 0.345499724149704\n",
      "        value: 0.40041062235832214\n",
      "        value: 0.3129367530345917\n",
      "        value: 0.12685392796993256\n",
      "        value: 0.364952951669693\n",
      "        value: 0.1128835529088974\n",
      "        value: 0.6553401350975037\n",
      "        value: 0.5341590642929077\n",
      "        value: 0.0611543245613575\n",
      "        value: 0.6404645442962646\n",
      "        value: 0.51646888256073\n",
      "        value: 0.05726355314254761\n",
      "        value: 0.6239129900932312\n",
      "        value: 0.05428585410118103\n",
      "        value: 0.5902683138847351\n",
      "        value: 0.053290486335754395\n",
      "        value: 0.2733999192714691\n",
      "        value: 0.06346438825130463\n",
      "        value: 0.05427323281764984\n",
      "        value: 1.0\n",
      "        value: 1.0\n",
      "        value: 1.0\n",
      "        value: 0.41057485342025757\n",
      "        value: 1.0\n",
      "        value: 1.0\n",
      "        value: 1.0\n",
      "        value: 1.0\n",
      "        value: 0.09030900150537491\n",
      "        value: 0.09030900150537491\n",
      "        value: 0.08450980484485626\n",
      "        value: 0.32352757453918457\n",
      "        value: 0.19138137996196747\n",
      "        value: 0.038095757365226746\n",
      "        value: 0.08450980484485626\n",
      "        value: 0.10000000149011612\n",
      "        value: 0.01141068059951067\n",
      "        value: 0.21071171760559082\n",
      "        value: 0.3072909116744995\n",
      "        value: 0.47340771555900574\n",
      "        value: 0.46989700198173523\n",
      "        value: 0.2507426142692566\n",
      "        value: 0.3622504770755768\n",
      "        value: 0.30678144097328186\n",
      "        value: 0.1832980215549469\n",
      "        value: 0.06616131961345673\n",
      "        value: 0.06438598781824112\n",
      "        value: 0.42142343521118164\n",
      "        value: 0.00033798249205574393\n",
      "        value: 0.002414338756352663\n",
      "        value: 0.002605876885354519\n",
      "        value: 0.00033798249205574393\n",
      "        value: 9.872547525446862e-05\n",
      "        value: 0.002414338756352663\n",
      "        value: 0.002605876885354519\n",
      "        value: 0.023629751056432724\n",
      "        value: 0.00033798249205574393\n",
      "        value: 9.872547525446862e-05\n",
      "        value: 0.002414338756352663\n",
      "        value: 0.002605876885354519\n",
      "        value: 0.023629751056432724\n",
      "        value: 0.00033798249205574393\n",
      "        value: 9.872547525446862e-05\n",
      "        value: 0.002414338756352663\n",
      "        value: 0.002605876885354519\n",
      "        value: 0.023629751056432724\n",
      "        value: 0.01068063173443079\n",
      "        value: 2.9393875593086705e-05\n",
      "        value: 0.0006155047449283302\n",
      "        value: 0.03547753393650055\n",
      "        value: 0.01310634147375822\n",
      "        value: 0.03547753393650055\n",
      "        value: 0.6060442924499512\n",
      "        value: 0.22124934196472168\n",
      "        value: 0.0003367942408658564\n",
      "        value: 0.02296740934252739\n",
      "        value: 0.029525170102715492\n",
      "        value: 0.04642750695347786\n",
      "        value: 0.04719500243663788\n",
      "        value: 0.8182253241539001\n",
      "        value: 0.8757087588310242\n",
      "        value: 0.001960023306310177\n",
      "        value: 0.03010299988090992\n",
      "        value: 0.005435766186565161\n",
      "        value: 0.03010299988090992\n",
      "        value: 0.4728896915912628\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for raw_record in rankData.take(1):  # 从dataset中取一个样本进行查看即可\n",
    "    example = tf.train.Example()\n",
    "    example.ParseFromString(raw_record.numpy())\n",
    "    print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-05T10:10:00.352154Z",
     "start_time": "2021-08-05T10:10:00.349173Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 8185\n"
     ]
    }
   ],
   "source": [
    "encoder = info.features['text'].encoder\n",
    "print('Vocabulary size: {}'.format(encoder.vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-05T10:10:02.707806Z",
     "start_time": "2021-08-05T10:10:02.704316Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded string is [4025, 222, 6307, 2327, 4043, 2120, 7975]\n",
      "The original string: \"Hello TensorFlow.\"\n"
     ]
    }
   ],
   "source": [
    "sample_string = 'Hello TensorFlow.'\n",
    "\n",
    "encoded_string = encoder.encode(sample_string)\n",
    "print('Encoded string is {}'.format(encoded_string))\n",
    "\n",
    "original_string = encoder.decode(encoded_string)\n",
    "print('The original string: \"{}\"'.format(original_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-05T10:10:44.291031Z",
     "start_time": "2021-08-05T10:10:44.285781Z"
    }
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 10000\n",
    "BATCH_SIZE = 64\n",
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE)\n",
    "train_dataset = train_dataset.padded_batch(BATCH_SIZE)\n",
    "\n",
    "test_dataset = test_dataset.padded_batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-05T10:10:46.636869Z",
     "start_time": "2021-08-05T10:10:46.223927Z"
    }
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(encoder.vocab_size, 64),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-05T10:10:46.650327Z",
     "start_time": "2021-08-05T10:10:46.641483Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-05T10:20:51.159337Z",
     "start_time": "2021-08-05T10:14:07.162381Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 403s 1s/step - loss: 0.4802 - accuracy: 0.7440 - val_loss: 0.3855 - val_accuracy: 0.8339\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_dataset, epochs=1,\n",
    "                    validation_data=test_dataset, \n",
    "                    validation_steps=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-05T10:25:31.374343Z",
     "start_time": "2021-08-05T10:25:31.343678Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.09515222]], dtype=float32)"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# difference between mask or not mask\n",
    "sample_pred_text = ('The movie was cool. The animation and the graphics '\n",
    "                    'were out of this world. I would recommend this movie.')\n",
    "encoded_sample_pred_text = encoder.encode(sample_pred_text)\n",
    "\n",
    "encoded_sample_pred_text = tf.cast(encoded_sample_pred_text, tf.float32)\n",
    "encoded_sample_pred_text\n",
    "\n",
    "predictions = model.predict(tf.expand_dims(encoded_sample_pred_text, 0))\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-05T10:25:26.177342Z",
     "start_time": "2021-08-05T10:25:25.642433Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01193168]], dtype=float32)"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pad_to_size(vec, size):\n",
    "  zeros = [0] * (size - len(vec))\n",
    "  vec.extend(zeros)\n",
    "  return vec\n",
    "\n",
    "sample_pred_text = ('The movie was cool. The animation and the graphics '\n",
    "                    'were out of this world. I would recommend this movie.')\n",
    "encoded_sample_pred_text = encoder.encode(sample_pred_text)\n",
    "encoded_sample_pred_text = pad_to_size(encoded_sample_pred_text, 64)\n",
    "encoded_sample_pred_text = tf.cast(encoded_sample_pred_text, tf.float32)\n",
    "\n",
    "predictions = model.predict(tf.expand_dims(encoded_sample_pred_text, 0))\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
